{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мешок слов и классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из базовых задач машинного обучения - это классификация (отнесение объекта к одному из заранее заданных классов). Классификация очень хорошо подходит для задач NLP, так как многие практические задачи можно свести к классификации (определение спама, определение тональности, определение намерения пользователя и т.п.).\n",
    "\n",
    "Есть очень много алгоритмов МО, которые применимы к NLP. У каждого свои плюсы, минусы и особенности, которые по-разному проявляются на практике. \n",
    "\n",
    "За одно занятие разобрать все важные алгоритмы не получится, поэтому сегодня поговорим про алгоритмы, которые из-за простоты использования удобно применять в качестве начальной базовой (baseline) модели. Более сложные алгоритмы (бустинги, lstm, трансформеры), практически всегда, будут работать лучше, НО помимо качества в практических задачах часто есть много других требований и ограничений (скорость, память, интерпретируемость и тп), которые могут перевесить разницу в точности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке мы рассмотрим задачу определения токсичных твитов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В определении тональности токсичных текстов обычно значительно меньше. Но даже сильный дисбаланс классов (99 к 1,например) - это часто не проблема для алгоритма/модели, нужно лишь быть аккуратным с оцениванием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы понять качество обученной модели нам нужно разделить данные на обучающую и тестовую выборку. Оценивать модель нужно всегда на данных, которые модель еще не видела! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как рассматривать алгоритмы классификации, нужно разобраться с тем, как мы будем подавать наши тексты на вход разным алгоритмам. Все они работают с числами, и текст, соответственно, тоже нужно превратить в число. А точнее в набор чисел - вектор. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ векторного представления текста называется \"мешком слов\" (bag-of-words). Мешок тут не какой-то технический термин, а метафора. В таком способе векторизации никак не учитывается порядок. Слова как бы складываются в \"мешок\" и перемешиваются. \n",
    "\n",
    "Если более формально, то для того, чтобы векторизовать некоторый набор документов (=текстов) мешком слов нужно:  \n",
    "а) составить словарь всех уникальных слов, встречаемых в этих документах \n",
    "б) зафиксировать порядок слов в словаре и сопоставить каждому из них порядковый индекс\n",
    "б) составить для каждого документа вектор размерности N (N - равен размеру словаря), где по индексу i стоит частота слова w_i в этом документе. \n",
    "\n",
    "Вот картинка для наглядности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/r5Nc2HC/abs-bow.jpg\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/r5Nc2HC/abs-bow.jpg\",\n",
    "     width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, что порядок колонок (слов в словаре) в этой таблице не соответствует порядку слов в текстах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На картинке выше частотность записана в абсолютных значениях. Лучше использовать относительную частоту, чтобы тексты разной длины были сопоставимы друг с другом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/47bRcVy/bow-normalized.jpg\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/47bRcVy/bow-normalized.jpg\",\n",
    "     width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer в sklearn векторизует как раз таким образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# в векторайзер нужно засовывать тексты строками (токенизация там встроена)\n",
    "X = vectorizer.fit_transform(train.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще вместо частот можно использовать tf-idf (term frequency - inverse document frequency). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кратко про tfidf на картинке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg\" width=\"600\" height=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg\",\n",
    "     width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf позвозволяет оштрафовать слова, которые встречаются в большом количестве документов (грубо говоря это стоп-слова, но специфичные для корпуса) и поднять важность слов, которые встречаются часто в небольшом количестве документов. Если слово встречается во всех документах, то соотношение $N/df_x$ будет равно 1, а логарифм от 1 - 0. Чем меньше $df_x$, тем больше будет $log(N/df_x)$\n",
    "\n",
    "А в вектор таким образом добавляется информация обо всем корпусе. Обычно для модели это оказывается полезно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(train.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторайзер возвращает результат в виде матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 64042)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# первая размерность - количество документов\n",
    "# вторая размерность - количесто слов в словаре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слов получается в 5 раз больше, чем документов. Некоторые алгоритмы не смогут так обучиться (нужно чтобы признаки <= документы), а те что смогут будут обучаться сильно дольше. И учитывая, что большая часть слов встретились по 1 разу, они все равно никак не помогут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.4)\n",
    "X = vectorizer.fit_transform(train.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 7568)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В словаре у нас 7,5 тысяч слов  и каждый документ мы описываем вектором такого размера. В этом векторе положительными будут значения, соответствующие словам, которые есть в этом тексте, а нулевыми - те значения, которые соответствуют словам, которых в тексте нет.\n",
    "\n",
    "**Нулевых значения будет значительно больше!**\n",
    "Поэтому для эффективности в sklearn такие матрицы хранятся в специальном sparse (разреженном) формате.\n",
    "\n",
    "Просто взять и посмотреть на матрицу не получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12970x7568 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 201572 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # 202052 из 98027260 позиций в матрице ненулевые (это меньше 1 процента)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые алгоритмы не умеют работать с разреженным векторами и такую матрицу можно привести в обычный dense формат (X.todense()) НО будьте острожны с большими матрицами - они будут занимать в памяти ОЧЕНЬ много места."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Косинусная близость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Между получившимеся векторами можно посчитать близость используя косинусное расстояние. \n",
    "\n",
    "Подробное описание того, как работает косинусное расстояние есть в [3-ем подготовительном семинаре](https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/first_module_intro/03_lexical_disambiguation.ipynb)\n",
    "\n",
    "Для bow-векторов косинусное расстояние главным образом будет зависеть от количества общих слов в двух документах. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на настоящих текстах текстами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вся соль в деталях, чтобы людям хотелось рассматривать работу\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[3, 'comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть косинусное расстояние и косинусная близость. Расстояние это просто единица минус близость (и наоборот), то есть расстояние между близкими векторами должно быть маленькое (0 если совпадают 1 - если вообще не совпадают), а близость наоборот (1 если совпадают 0 если не совпадают совсем)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расстояние удобнее использовать, когда нужно отсортировать по близости, т.к в numpy по умолчанию сортируется по возрастанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3, 5093, 2435])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# функция предназначена для расчета близости между массивами векторов\n",
    "# и возвращает она тоже массив где каждая строчка это объект и первого массива, \n",
    "# а каждая колонка это близость до объекта во втором массиве\n",
    "\n",
    "# в нашем случае в первом массиве у нас только 1 вектор\n",
    "# поэтому мы можем взять первую строчку из получившегося массива\n",
    "# метод .argsort вернет список индексов по возрастанию \n",
    "# возьмем первые три индекса и посмотрим что там за тексты\n",
    "top_idx = cosine_distances(X[3], X).argsort()[0,:3]\n",
    "top_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Вся соль в деталях, чтобы людям хотелось рассматривать работу\\n',\n",
       "       'А соль соседу для ванны. )\\n',\n",
       "       'В заливе соль есть, концентрация 3-5 процентов. Когда долго дует западный ветер, то соль чувствуется.\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# первым нашелся этот же вектор\n",
    "# а дальше уже не настолько близкие но все равно есть сходство\n",
    "train.loc[top_idx, 'comment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы векторизовали обучающую выборку, осталось векторизовать тестовую"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторайзеры в sklearn имеют три основных метода **fit**, **transform** и **fit_transform**. \n",
    "\n",
    "**fit** - собирает словарь и статистики по текстам,   \n",
    "**transform** - преобразует тексты в векторы, на основе уже собранного словаря.  \n",
    "**fit_transform** - делает сразу и первое и второе (быстре чем 1 и 2 по очереди).\n",
    "\n",
    "Для теста нам нужно векторизовать тексты тем же словарем, для этого вызовем метод .transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим еще раз векторизацию и достанем отдельно целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, max_df=0.3)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12970, 3370), (1442, 3370))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Называть матрицу с признаками X, а вектор с целевой переменной y - стандартная практика. \n",
    "# ! Если вы сделаете наоборот, то сильно запутаете меня в домашке "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Интуитивно кажется, что bag-of-words сильно упрощает - порядок слов ведь очень важен для текста (целое больше суммы отдельных элементов, синергия, эмерджентность и все такое)! Однако на практике BOW работает удивительно хорошо. Начать решать практически любую классификационную нлп задачу лучше всего с мешка слов и простого алгоритма классификации. Это хорошее базовое решение, с которым удобно сравнивать более сложные решения и к тому же есть шанс, что уже такого базового решения будет достаточно для практического применения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритмы классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем обучить модель. Рассмотрим 5 алгоритма, которые можно попробовать прежде чем переходить к чему-то более сложному: KNN, Logistic Regression, Decision Trees, Naive Bayes, RandomForest.\n",
    "\n",
    "Кратко идея этих алгоритмов:\n",
    "\n",
    "1) **KNN** - это предсказания класса текста по близости к другим текстам, для которых известен класс. Выше мы считали близость между текстами косинусным расстоянием - в KNN делается то же самое (но метрика может быть другая), только рассматривается топ-K ближайших текстов. В KNN таким образом нет никакого обучения - просто запоминание тестовой выборки и сравнение с ней при предсказании.\n",
    "\n",
    "На графике можно нарисовать зоны, которые будут соответствовать классам для выбраного параметра K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/SXOQd.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.stack.imgur.com/SXOQd.png\",\n",
    "     width=500, height=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Логистическая регрессия.** Предсказание с помощью обученной модели логистической регрессии - это по сути взвешенное средние чисел во входном векторе и приведение получившегося числа в интервал от 0 до 1 с помощью специальной функции (сигмоиды). Если получившееся значение больше 0.5, то считаем, что этот текст \"токсичный\", а если нет, то \"нейтральный\" (но можем подобрать и другие пороги).\n",
    "\n",
    "Коэффициенты подбираются на обучающих данных (это и есть обучение). Можно сказать, что в итоге для каждого слова находится показатель токсичности. Если в тексте будет много слов с высоким показателем токсичности, то весь текст будет отнесен к токсичному классу. Однако показатель токсичности не равно вероятность токсичности - он может быть равен любому числу (например, 0.282, -4815162342, 666.13) Интерпретировать значение показателя можно только по отношению к другим значениям.\n",
    "\n",
    "Коэффициенты обученной модели будут являться уравнением прямой, которая разделяет объекты на классы. И эту прямую можно нарисовать, но с оговорками. Во-первых, больше 2 признаков нарисовать не получится, а во вторых, так как это не линейная регрессия, где на выходе мы получаем число, прямая для логистической регрессии находится в другом пространстве, из которого можно перейти к классовым вероятностям с помощью сигмоиды. (можно посмотреть серию видео вот тут, чтобы копнуть поглубже - https://www.youtube.com/watch?v=yIYKR4sgzI8&list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://scipython.com/static/media/uploads/blog/logistic_regression/decision-boundary.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# так примерно выглядит прямая регрессии для двух признаков (класс показан цветом точек)\n",
    "# прямая тут показывает разделяющую поверхность\n",
    "# можно взять какой-то x1 и x2 и посмотреть с какой стороны от разделяющей поверхности находится точка \n",
    "# и понять какой класс будет предсказан\n",
    "Image(url=\"https://scipython.com/static/media/uploads/blog/logistic_regression/decision-boundary.png\",\n",
    "     width=700, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Легче не пытаться визуализировать логистическую регресиию, а посмотреть как она рассчитывается и что на что в итоге влияет.\n",
    "\n",
    "Каждый признак в inputs умножается на свой коэффициент, они складываются и пропускаются через сигмоиду, которая преобразует сумму в вероятность от 0 до 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://deeplearningmath.org/images/shallow_NN.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://deeplearningmath.org/images/shallow_NN.png\",\n",
    "     width=700, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) **Дерево решений** - это просто много вложенных if else. В процессе обучения подбирается такая серия условий типа \"тфидф этого слова больше 1.23\" или \"частотность слова_а больше частотности слова_б\", чтобы в итоге получалось предсказать правильный класс текста. Плюсом деревьев решений является их интерпретируемость - для каждого предсказания можно вывести цепочку условий, которая привела к такому выводу. \n",
    "\n",
    "Каждое условие в дереве разделяет пространство пополам, поэтому график решающего дерева будет состоять из четырехугольников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://paulvanderlaken.files.wordpress.com/2020/03/readme-titanic_plot-11.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://paulvanderlaken.files.wordpress.com/2020/03/readme-titanic_plot-11.png\",\n",
    "     width=700, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **Наивный байесовский классификатор**. НБ классификатор принимает решение по вероятностям, рассчитаным на обучающем корпусе. В частности нужно три вероятности:  \n",
    "а) вероятность встретить конкретное слово в классе А и Б (токсик и нетоксик в нашем случае);   \n",
    "б) вероятность каждого класса.\n",
    "в) вероятность каждого слова.\n",
    "\n",
    "Эти вероятности расчитываются по частностям. Например, количество токсичных документов со словом, поделенное на общее количество документов с этим словом - это вероятность встретить слово в токсичном классе, а количество токсичных документов, поделенное на общее количество документов - это вероятность токсичного класса, а количество вхождений слова, поделенное на общее количество слов - вероятность слова.\n",
    "\n",
    "Эти вероятности перемножаются по формеле Баеса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://media.proglib.io/posts/2021/10/18/4956938de749b78809ab37725a14cb52.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(B|A) - вероятность встретить конкретное слово B в классе A\n",
    "# P(A) - вероятность класса А\n",
    "# P(B) - вероятность слова B\n",
    "Image(url=\"https://media.proglib.io/posts/2021/10/18/4956938de749b78809ab37725a14cb52.png\",\n",
    "     width=500, height=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сказать, что в наивном байесе ничего и не обучается, а просто считаются статистики. При предсказании для каждого класса перемножаются соответствующие вероятности слов, присуствующих в тексте, и класс набравший большую оценку выбирается. \n",
    "\n",
    "Наивным такой классификатор называется, потому что делается предположение, что слова в документе не зависят друг от друга. Это конечно не так, многие слова появляются в тексте вместе не случайно. Допустим, мы рассматриваем тексты на английском. У нас могут быть тексты про яблоки (apples), про компанию Apple, и тексты про Нью-Йорк (Big Apple). После нормализации в словарь во всех трех случаях попадет \"apple\" и вероятность будет считаться по всем типам текстов. Но возможна такая ситуация, что тексты про яблоки нейтральные, про компанию - негативные, а про Нью-Йорк - положительные. Если бы мы считали совместные вероятности слов, то мы смогли разделить эти типы и делать более точные предсказания. Но это сильно сложнее, а наивный байес работает достаточно хорошо и так. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) **RandomForest** - это N деревьев решений, объединенных в один большой классификатор (лес). Такие классификаторы называются ансамблями. Ставить RF в один ряд с алгоритмами выше наверное не очень корректно - RF сильно сложнее и мощнее, но на практике его использование в sklearn никак не отличается, нужно только немного разобраться с основыми параметрами. \n",
    "\n",
    "Для каждого отдельного дерева в RF используется случайная подвыборка обьектов (текстов) и признаков (слов), чтобы деревья не получались одинаковыми. Поэтому алгоритм и называется случайным лесом. Отдельные деревья решений могут быть очень слабыми, если пробовать применить их самостоятельно, но вместе они дают очень хороший результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.meme-arsenal.com/memes/b21eaf3fcba087cc3dc2e6c43eaa7eeb.jpg\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# суть Random Forest\n",
    "Image(url=\"https://www.meme-arsenal.com/memes/b21eaf3fcba087cc3dc2e6c43eaa7eeb.jpg\",\n",
    "     width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У алгоритмов в sklearn стандартный интерфейс - есть функции fit, predict и predict_proba (если классификатор выдает вероятности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit обучает модель\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предикт предсказывает классы\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzeRtqt2tBTt",
    "nbpresent": {
     "id": "63107774-a12e-4893-af45-2353b2299d0a"
    }
   },
   "source": [
    "#### Меры качества бинарной классификации \n",
    "\n",
    "При сопоставлении предсказаний модели с правильными (истинными) ответами составляют вот такую таблицу\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"4\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>positive</td>\n",
    "    <td>negative</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>positive</td>\n",
    "    <td><span style=\"color:green\">$tp$</span></td>\n",
    "    <td><span style=\"color:red\">$fp$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>negative</td>\n",
    "    <td><span style=\"color:red\">$fn$</span></td>\n",
    "    <td><span style=\"color:green\">$tn$</span></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$tp$ - это $true\\_positive$, количество истинно положительных предсказаний модели (т.е. модель считает, что текст токсичный и он на самом деле токсичный)\n",
    "\n",
    "$fp$ - это $true\\_positive$, количество ложно положительных предсказаний модели (т.е. модель считает, что текст токсичный, а он на самом деле НЕ токсичный)\n",
    "\n",
    "$tn$ - это $true\\_positive$, количество истинно отрицательных предсказаний модели (т.е. модель считает, что текст нетоксичный и он на самом деле нетоксичный)\n",
    "\n",
    "$fn$ - это $true\\_positive$, количество ложно отрицательных предсказаний модели (т.е. модель считает, что текст нетоксичный и он на самом деле токсичный)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зеленым в таблице выделены правильные ответы, а красным - ошибки. Часто их называют ошибка первого (false positive) и второго рода (false negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки моделей эти значений обычно не используются. На их основе считаются другие метрики. Основные для нас это: accuracy, точность, полнота и f-мера:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MeIEVS9tBTu",
    "nbpresent": {
     "id": "67e4f042-0f46-4a15-98a6-5865a35685bf"
    }
   },
   "source": [
    "$precision = Pr =  \\frac{tp}{tp+fp} $ – точность (показывает, какая доля положительных предсказаний является правильными)\n",
    "\n",
    "$recall = R = \\frac{tp}{tp+fn} $ – полнота (показывает, насколько полно предсказывается положительный класс)\n",
    "\n",
    "$F_1 = \\frac{2 Pr * R}{Pr + R}$ – $F$-мера (объединяет точность и полноту в одно число)\n",
    "\n",
    "$accuracy = \\frac{tp + tn}{tp + fp + fn + tn}$ –  по-русски это тоже точность, поэтому иногда возникает путаница; лучше всего говорить accuracy (это просто доля правильных ответов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy хоть и самая простая и логичная, но используется редко. Эта метрика не устойчива к дисбалансу классов, а он почти всегда есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию лучше всего смотреть на F-меру. Но бывают задачи, где важнее точность, а бывают - где важнее полнота. Например, если на основе предсказания токсичности автору сразу дается бан, то нам нужно быть увереным, что эти предсказания являются очень точными. А если мы хотим снизить количество токсичности на платформе до минимума, то нам будет важнее полнота."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть отдельные функции для каждой из метрик, а есть удобная функция classification_report, которая считает все сразу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.82      0.84       952\n",
      "         1.0       0.68      0.75      0.71       490\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.77      0.78      0.78      1442\n",
      "weighted avg       0.80      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba возвращает вероятности классов\n",
    "# это полезно когда нужно подобрать порог например\n",
    "probas = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80526376, 0.19473624],\n",
       "       [0.10602066, 0.89397934],\n",
       "       [0.50724877, 0.49275123],\n",
       "       ...,\n",
       "       [0.62165136, 0.37834864],\n",
       "       [0.52490349, 0.47509651],\n",
       "       [0.29114768, 0.70885232]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в левой колонке вероятность 0 (нетокстичности)\n",
    "# в правой - вероятность 1 (токсичности)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем вторую колонку\n",
    "# проверим что она больше 0,85\n",
    "# заменим True и False на 0 и 1 чтобы получить предсказания\n",
    "preds = (probas[:,1]>0.85).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80       952\n",
      "         1.0       0.95      0.04      0.07       490\n",
      "\n",
      "    accuracy                           0.67      1442\n",
      "   macro avg       0.81      0.52      0.44      1442\n",
      "weighted avg       0.76      0.67      0.55      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# точность по токсичному классу сильно выросла но при этом упала полнота\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем другие классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.97      0.88       952\n",
      "         1.0       0.89      0.54      0.67       490\n",
      "\n",
      "    accuracy                           0.82      1442\n",
      "   macro avg       0.85      0.75      0.77      1442\n",
      "weighted avg       0.83      0.82      0.81      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1.)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.37      0.51       952\n",
      "         1.0       0.41      0.84      0.55       490\n",
      "\n",
      "    accuracy                           0.53      1442\n",
      "   macro avg       0.61      0.61      0.53      1442\n",
      "weighted avg       0.68      0.53      0.53      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.85      0.82       952\n",
      "         1.0       0.67      0.60      0.63       490\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.73      0.72      0.73      1442\n",
      "weighted avg       0.76      0.76      0.76      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Меры качества многоклассовой классификации \n",
    "Если количество классов больше, то расчет метрик становится немного сложнее. Можно свести все к бинарной оценке, если рассматривать каждый класс по отношению ко всем другим классам. Т.е. считать текущий класс положительным, а все другие классы отрицательным классом. Для трех классов у нас получится три таблицы:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"4\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>class 1</td>\n",
    "    <td>(class 2, class 3)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>class 1</td>\n",
    "    <td><span style=\"color:green\">$tp_1$</span></td>\n",
    "    <td><span style=\"color:red\">$fp_1$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>(class 2, class 3)</td>\n",
    "    <td><span style=\"color:red\">$fn_1$</span></td>\n",
    "    <td><span style=\"color:green\">$tn_1$</span></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"4\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>class 2</td>\n",
    "    <td>(class 1, class 3)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>class 2</td>\n",
    "    <td><span style=\"color:green\">$tp_2$</span></td>\n",
    "    <td><span style=\"color:red\">$fp_2$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>(class 1, class 3)</td>\n",
    "    <td><span style=\"color:red\">$fn_2$</span></td>\n",
    "    <td><span style=\"color:green\">$tn_2$</span></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"4\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>class 3</td>\n",
    "    <td>(class 1, class 2)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>class 3</td>\n",
    "    <td><span style=\"color:green\">$tp_3$</span></td>\n",
    "    <td><span style=\"color:red\">$fp_3$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>(class 1, class 2)</td>\n",
    "    <td><span style=\"color:red\">$fn_3$</span></td>\n",
    "    <td><span style=\"color:green\">$tn_3$</span></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответственно для каждого класса мы можем отдельно посчитать точность, полноту и F-меру. \n",
    "А если мы хотим найти общие метрики, то у нас есть два варианта: \n",
    "\n",
    "1) усреднить отдельные точности, полноты, F-меры по количеству классов (макро усреднение)\n",
    "\n",
    "$macro\\ Precision = \\frac{\\sum Pr_c}{|C|}$  \n",
    "$macro\\ Recall = \\frac{\\sum R_c}{|C|}$  \n",
    "$macro\\ F1\\_measure = \\frac{\\sum F1_c}{|C|}$  \n",
    "\n",
    "2) рассчитать общие tp, tn, fp, fn и вычислить точность, полноту по ним (микро усреднение)\n",
    "\n",
    "\n",
    "$micro\\ Precision =  \\frac{\\sum tp_c}{\\sum tp_c+fp_c} $ – точность (показывает, какая доля положительных предсказаний является правильными)\n",
    "\n",
    "$micro\\ Recall = \\frac{\\sum tp_c}{\\sum tp_c+fn_c} $ – полнота (показывает, насколько полно предсказывается положительный класс)\n",
    "\n",
    "Микро усреднение зависит от баланса классов - доминирующие классы будут перетягивать метрику на себя, за счет того, что их tp,fp,tn,fn будут иметь больший вклад в результат. Макро усреднение не учитывает размер классов, что может привезти к тому, что мелкие классы, плохо классифицируемые моделью, будут непропорционально занижать общий результат. \n",
    "\n",
    "Макро усреднение можно улучшить дополнительным взвешиванием каждого класса. Можно взвесить на частотность (тогда это будет практически микро среднее), а можно придумать каждому классу свой вес, в зависимости от задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем данные с несколькими классами и попробуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiclass = pd.read_csv('tweet_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_multiclass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data_multiclass.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       0.215950\n",
       "worry         0.211475\n",
       "happiness     0.130225\n",
       "sadness       0.129125\n",
       "love          0.096050\n",
       "surprise      0.054675\n",
       "fun           0.044400\n",
       "relief        0.038150\n",
       "hate          0.033075\n",
       "empty         0.020675\n",
       "enthusiasm    0.018975\n",
       "boredom       0.004475\n",
       "anger         0.002750\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть совсем маленькие классы, заменим их на 1 общий класс other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiclass.loc[data_multiclass.sentiment.isin(counts[counts<0.05].index), 'sentiment'] = 'other' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_multiclass, \n",
    "                               test_size=0.1, \n",
    "                               stratify=data_multiclass.sentiment,\n",
    "                               shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.sentiment.values\n",
    "y_test = test.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем какой-нибудь классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.4)\n",
    "X = vectorizer.fit_transform(train.content)\n",
    "X_test = vectorizer.transform(test.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20, )\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.42      0.15      0.22       521\n",
      "        love       0.53      0.33      0.41       384\n",
      "     neutral       0.29      0.72      0.42       864\n",
      "       other       0.40      0.06      0.11       650\n",
      "     sadness       0.50      0.10      0.17       516\n",
      "    surprise       0.00      0.00      0.00       219\n",
      "       worry       0.32      0.48      0.39       846\n",
      "\n",
      "    accuracy                           0.33      4000\n",
      "   macro avg       0.35      0.26      0.24      4000\n",
      "weighted avg       0.37      0.33      0.28      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мешок нграмм "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы учесть информацию о порядке слов и при этом остаться в рамках простой мешкословной модели, можно использовать небольшой трюк - добавить в словарь нграммы.\n",
    " \n",
    "О том, как найти хорошие нграммы, мы поговорим позже, а пока воспользуемся встроенными возможностями sklearn. У векторайзеров есть параметр ngram_range, который по умолчанию задан как (1,1). Мы можем изменить его на (1,2) или (1,3), чтобы в словаре появились еще биграммы и триграммы, соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, min_df=10, max_df=0.1, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие нграммы попали в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 лет',\n",
       " 'больше чем',\n",
       " 'бы не',\n",
       " 'было бы',\n",
       " 'во время',\n",
       " 'вообще не',\n",
       " 'вот это',\n",
       " 'все же',\n",
       " 'все равно',\n",
       " 'все таки',\n",
       " 'все это',\n",
       " 'вы не',\n",
       " 'где то',\n",
       " 'да не',\n",
       " 'даже если',\n",
       " 'даже не',\n",
       " 'для меня',\n",
       " 'для того',\n",
       " 'для этого',\n",
       " 'до сих',\n",
       " 'до сих пор',\n",
       " 'думаю что',\n",
       " 'если бы',\n",
       " 'если не',\n",
       " 'если ты',\n",
       " 'если это',\n",
       " 'же как',\n",
       " 'же не',\n",
       " 'за это',\n",
       " 'зависит от']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizer.get_feature_names() показывает словарь, индексы в списке соответствуют колонкам в матрице\n",
    "# нграмы склеиваются через пробел в sklearn\n",
    "[x for x in vectorizer.get_feature_names() if ' ' in x][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12970, 1000), (12970,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1442, 1000), (1442,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83       944\n",
      "         1.0       0.88      0.29      0.43       498\n",
      "\n",
      "    accuracy                           0.74      1442\n",
      "   macro avg       0.80      0.63      0.63      1442\n",
      "weighted avg       0.78      0.74      0.69      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
