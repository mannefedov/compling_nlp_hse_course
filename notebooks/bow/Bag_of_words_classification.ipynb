{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мешок слов и классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из базовых задач машинного обучения - это классификация (отнесение объекта к одному из заранее заданных классов). Классификация очень хорошо подходит для задач NLP, так как многие практические задачи можно свести к классификации (определение спама, определение тональности, определение намерения пользователя и т.п.).\n",
    "\n",
    "Есть очень много алгоритмов МО, которые применимы к NLP. У каждого свои плюсы, минусы и особенности, которые по-разному проявляются на практике. \n",
    "\n",
    "За одно занятие разобрать все важные алгоритмы не получится, поэтому сегодня поговорим про алгоритмы, которые из-за простоты использования удобно применять в качестве начальной базовой (baseline) модели. Более сложные алгоритмы (бустинги, lstm, трансформеры), практически всегда, будут работать лучше, НО помимо качества в практических задачах часто есть много других требований и ограничений (скорость, память, интерпретируемость и тп), которые могут перевесить разницу в точности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке мы рассмотрим задачу определения токсичных твитов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14412 entries, 0 to 14411\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   comment  14412 non-null  object \n",
      " 1   toxic    14412 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 225.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В определении тональности токсичных текстов обычно значительно меньше. Но даже сильный дисбаланс классов (99 к 1,например) - это часто не проблема для алгоритма/модели, нужно лишь быть аккуратным с оцениванием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы понять качество обученной модели нам нужно разделить данные на обучающую и тестовую выборку. Оценивать модель нужно всегда на данных, которые модель еще не видела! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как рассматривать алгоритмы классификации, нужно разобраться с тем, как мы будем подавать наши тексты на вход разным алгоритмам. Все они работают с числами, и текст, соответственно, тоже нужно превратить в число. А точнее в набор чисел - вектор. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ векторного представления текста называется \"мешком слов\" (bag-of-words). Мешок тут не какой-то технический термин, а метафора. В таком способе векторизации никак не учитывается порядок. Слова как бы складываются в \"мешок\" и перемешиваются. \n",
    "\n",
    "Если более формально, то для того, чтобы векторизовать некоторый набор документов (=текстов) мешком слов нужно:  \n",
    "а) составить словарь всех уникальных слов, встречаемых в этих документах \n",
    "б) зафиксировать порядок слов в словаре и сопоставить каждому из них порядковый индекс\n",
    "б) составить для каждого документа вектор размерности N (N - равен размеру словаря), где по индексу i стоит частота слова w_i в этом документе. \n",
    "\n",
    "Вот картинка для наглядности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/r5Nc2HC/abs-bow.jpg\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/r5Nc2HC/abs-bow.jpg\",\n",
    "     width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, что порядок колонок (слов в словаре) в этой таблице не соответствует порядку слов в текстах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На картинке выше частотность записана в абсолютных значениях. Лучше использовать относительную частоту, чтобы тексты разной длины были сопоставимы друг с другом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/47bRcVy/bow-normalized.jpg\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/47bRcVy/bow-normalized.jpg\",\n",
    "     width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer в sklearn векторизует как раз таким образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# в векторайзер нужно засовывать тексты строками (токенизация там встроена)\n",
    "X = vectorizer.fit_transform(train.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще вместо частот можно использовать tf-idf (term frequency - inverse document frequency). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кратко про tfidf на картинке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg\" width=\"600\" height=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg\",\n",
    "     width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf позвозволяет оштрафовать слова, которые встречаются в большом количестве документов (грубо говоря это стоп-слова, но специфичные для корпуса) и поднять важность слов, которые встречаются часто в небольшом количестве документов. Если слово встречается во всех документах, то соотношение $N/df_x$ будет равно 1, а логарифм от 1 - 0. Чем меньше $df_x$, тем больше будет $log(N/df_x)$\n",
    "\n",
    "А в вектор таким образом добавляется информация обо всем корпусе. Обычно для модели это оказывается полезно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(train.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторайзер возвращает результат в виде матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 64361)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# первая размерность - количество документов\n",
    "# вторая размерность - количесто слов в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слов получается в 5 раз больше, чем документов. Некоторые алгоритмы не смогут так обучиться (нужно чтобы признаки <= документы), а те что смогут будут обучаться сильно дольше. И учитывая, что большая часть слов встретились по 1 разу, они все равно никак не помогут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.4)\n",
    "X = vectorizer.fit_transform(train.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 7640)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В словаре у нас 7,5 тысяч слов  и каждый документ мы описываем вектором такого размера. В этом векторе положительными будут значения, соответствующие словам, которые есть в этом тексте, а нулевыми - те значения, которые соответствуют словам, которых в тексте нет.\n",
    "\n",
    "**Нулевых значения будет значительно больше!**\n",
    "Поэтому для эффективности в sklearn такие матрицы хранятся в специальном sparse (разреженном) формате.\n",
    "\n",
    "Просто взять и посмотреть на матрицу не получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12970x7640 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 202989 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # 202052 из 98027260 позиций в матрице ненулевые (это меньше 1 процента)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые алгоритмы не умеют работать с разреженным векторами и такую матрицу можно привести в обычный dense формат (X.todense()) НО будьте острожны с большими матрицами - они будут занимать в памяти ОЧЕНЬ много места."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Косинусная близость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Между получившимеся векторами можно посчитать близость используя косинусное расстояние. \n",
    "\n",
    "Подробное описание того, как работает косинусное расстояние есть в [3-ем подготовительном семинаре](https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/first_module_intro/03_lexical_disambiguation.ipynb)\n",
    "\n",
    "Для bow-векторов косинусное расстояние главным образом будет зависеть от количества общих слов в двух документах. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на настоящих текстах текстами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Получается, у вас либеральное обострение?\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[3, 'comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть косинусное расстояние и косинусная близость. Расстояние это просто единица минус близость (и наоборот), то есть расстояние между близкими векторами должно быть маленькое (0 если совпадают 1 - если вообще не совпадают), а близость наоборот (1 если совпадают 0 если не совпадают совсем)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расстояние удобнее использовать, когда нужно отсортировать по близости, т.к в numpy по умолчанию сортируется по возрастанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    3, 12387,  4296])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# функция предназначена для расчета близости между массивами векторов\n",
    "# и возвращает она тоже массив где каждая строчка это объект и первого массива, \n",
    "# а каждая колонка это близость до объекта во втором массиве\n",
    "\n",
    "# в нашем случае в первом массиве у нас только 1 вектор\n",
    "# поэтому мы можем взять первую строчку из получившегося массива\n",
    "# метод .argsort вернет список индексов по возрастанию \n",
    "# возьмем первые три индекса и посмотрим что там за тексты\n",
    "top_idx = cosine_distances(X[3], X).argsort()[0,:3]\n",
    "top_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Получается, у вас либеральное обострение?\\n',\n",
       "       'У вас что, ночное большевистское обострение?',\n",
       "       'У вас что, ночное большевистское обострение?\\n'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# первым нашелся этот же вектор\n",
    "# а дальше уже не настолько близкие но все равно есть сходство\n",
    "train.loc[top_idx, 'comment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы векторизовали обучающую выборку, осталось векторизовать тестовую"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторайзеры в sklearn имеют три основных метода **fit**, **transform** и **fit_transform**. \n",
    "\n",
    "**fit** - собирает словарь и статистики по текстам,   \n",
    "**transform** - преобразует тексты в векторы, на основе уже собранного словаря.  \n",
    "**fit_transform** - делает сразу и первое и второе (быстре чем 1 и 2 по очереди).\n",
    "\n",
    "Для теста нам нужно векторизовать тексты тем же словарем, для этого вызовем метод .transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим еще раз векторизацию и достанем отдельно целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, max_features=100, max_df=0.3)\n",
    "\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12970, 100), (1442, 100))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<12970x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 70698 stored elements in Compressed Sparse Row format>,\n",
       " array([1., 1., 0., ..., 1., 0., 1.]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Называть матрицу с признаками X, а вектор с целевой переменной y - стандартная практика. \n",
    "# ! Если вы сделаете наоборот, то сильно запутаете меня в домашке "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Интуитивно кажется, что bag-of-words сильно упрощает - порядок слов ведь очень важен для текста (целое больше суммы отдельных элементов, синергия, эмерджентность и все такое)! Однако на практике BOW работает удивительно хорошо. Начать решать практически любую классификационную нлп задачу лучше всего с мешка слов и простого алгоритма классификации. Это хорошее базовое решение, с которым удобно сравнивать более сложные решения и к тому же есть шанс, что уже такого базового решения будет достаточно для практического применения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритмы классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем обучить модель. Рассмотрим 5 алгоритма, которые можно попробовать прежде чем переходить к чему-то более сложному: KNN, Logistic Regression, Decision Trees, Naive Bayes, RandomForest.\n",
    "\n",
    "Кратко идея этих алгоритмов:\n",
    "\n",
    "1) **KNN** - это предсказания класса текста по близости к другим текстам, для которых известен класс. Выше мы считали близость между текстами косинусным расстоянием - в KNN делается то же самое (но метрика может быть другая), только рассматривается топ-K ближайших текстов. В KNN таким образом нет никакого обучения - просто запоминание тестовой выборки и сравнение с ней при предсказании.\n",
    "\n",
    "На графике можно нарисовать зоны, которые будут соответствовать классам для выбраного параметра K. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![источник:https://mlarchive.com/machine-learning/k-nearest-neighbor-knn-explained/](https://mlarchive.com/wp-content/uploads/2022/09/img2-3-1024x585.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Логистическая регрессия.** Предсказание с помощью обученной модели логистической регрессии - это по сути взвешенное средние чисел во входном векторе и приведение получившегося числа в интервал от 0 до 1 с помощью специальной функции (сигмоиды). Если получившееся значение больше 0.5, то считаем, что этот текст \"токсичный\", а если нет, то \"нейтральный\" (но можем подобрать и другие пороги).\n",
    "\n",
    "Коэффициенты подбираются на обучающих данных (это и есть обучение). Можно сказать, что в итоге для каждого слова находится показатель токсичности. Если в тексте будет много слов с высоким показателем токсичности, то весь текст будет отнесен к токсичному классу. Однако показатель токсичности не равно вероятность токсичности - он может быть равен любому числу (например, 0.282, -4815162342, 666.13) Интерпретировать значение показателя можно только по отношению к другим значениям.\n",
    "\n",
    "Коэффициенты обученной модели будут являться уравнением прямой, которая разделяет объекты на классы. И эту прямую можно нарисовать, но с оговорками. Во-первых, больше 2 признаков нарисовать не получится, а во вторых, так как это не линейная регрессия, где на выходе мы получаем число, прямая для логистической регрессии находится в другом пространстве, из которого можно перейти к классовым вероятностям с помощью сигмоиды. (можно посмотреть серию видео вот тут, чтобы копнуть поглубже - https://www.youtube.com/watch?v=yIYKR4sgzI8&list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# так примерно выглядит прямая регрессии для двух признаков (класс показан цветом точек)\n",
    "# прямая тут показывает разделяющую поверхность\n",
    "# можно взять какой-то x1 и x2 и посмотреть с какой стороны от разделяющей поверхности находится точка \n",
    "# и понять какой класс будет предсказан"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scipython.com/static/media/uploads/blog/logistic_regression/decision-boundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Легче не пытаться визуализировать логистическую регресиию, а посмотреть как она рассчитывается и что на что в итоге влияет.\n",
    "\n",
    "Каждый признак в inputs умножается на свой коэффициент, они складываются и пропускаются через сигмоиду, которая преобразует сумму в вероятность от 0 до 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://deeplearningmath.org/images/shallow_NN.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://deeplearningmath.org/images/shallow_NN.png\",\n",
    "     width=700, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) **Дерево решений** - это просто много вложенных if else. В процессе обучения подбирается такая серия условий типа \"тфидф этого слова больше 1.23\" или \"частотность слова_а больше частотности слова_б\", чтобы в итоге получалось предсказать правильный класс текста. Плюсом деревьев решений является их интерпретируемость - для каждого предсказания можно вывести цепочку условий, которая привела к такому выводу. \n",
    "\n",
    "Каждое условие в дереве разделяет пространство пополам, поэтому график решающего дерева будет состоять из четырехугольников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://paulvanderlaken.files.wordpress.com/2020/03/readme-titanic_plot-11.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://paulvanderlaken.files.wordpress.com/2020/03/readme-titanic_plot-11.png\",\n",
    "     width=700, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **Наивный байесовский классификатор**. НБ классификатор принимает решение по вероятностям, рассчитаным на обучающем корпусе. В частности нужно три вероятности:  \n",
    "а) вероятность встретить конкретное слово в классе А и Б (токсик и нетоксик в нашем случае);   \n",
    "б) вероятность каждого класса.\n",
    "в) вероятность каждого слова.\n",
    "\n",
    "Эти вероятности расчитываются по частностям. Например, количество токсичных документов со словом, поделенное на общее количество документов с этим словом - это вероятность встретить слово в токсичном классе, а количество токсичных документов, поделенное на общее количество документов - это вероятность токсичного класса, а количество вхождений слова, поделенное на общее количество слов - вероятность слова.\n",
    "\n",
    "Эти вероятности перемножаются по формеле Баеса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://media.proglib.io/posts/2021/10/18/4956938de749b78809ab37725a14cb52.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(B|A) - вероятность встретить конкретное слово B в классе A\n",
    "# P(A) - вероятность класса А\n",
    "# P(B) - вероятность слова B\n",
    "Image(url=\"https://media.proglib.io/posts/2021/10/18/4956938de749b78809ab37725a14cb52.png\",\n",
    "     width=500, height=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сказать, что в наивном байесе ничего и не обучается, а просто считаются статистики. При предсказании для каждого класса перемножаются соответствующие вероятности слов, присуствующих в тексте, и класс набравший большую оценку выбирается. \n",
    "\n",
    "Наивным такой классификатор называется, потому что делается предположение, что слова в документе не зависят друг от друга. Это конечно не так, многие слова появляются в тексте вместе не случайно. Допустим, мы рассматриваем тексты на английском. У нас могут быть тексты про яблоки (apples), про компанию Apple, и тексты про Нью-Йорк (Big Apple). После нормализации в словарь во всех трех случаях попадет \"apple\" и вероятность будет считаться по всем типам текстов. Но возможна такая ситуация, что тексты про яблоки нейтральные, про компанию - негативные, а про Нью-Йорк - положительные. Если бы мы считали совместные вероятности слов, то мы смогли разделить эти типы и делать более точные предсказания. Но это сильно сложнее, а наивный байес работает достаточно хорошо и так. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) **RandomForest** - это N деревьев решений, объединенных в один большой классификатор (лес). Такие классификаторы называются ансамблями. Ставить RF в один ряд с алгоритмами выше наверное не очень корректно - RF сильно сложнее и мощнее, но на практике его использование в sklearn никак не отличается, нужно только немного разобраться с основыми параметрами. \n",
    "\n",
    "Для каждого отдельного дерева в RF используется случайная подвыборка обьектов (текстов) и признаков (слов), чтобы деревья не получались одинаковыми. Поэтому алгоритм и называется случайным лесом. Отдельные деревья решений могут быть очень слабыми, если пробовать применить их самостоятельно, но вместе они дают очень хороший результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.meme-arsenal.com/memes/b21eaf3fcba087cc3dc2e6c43eaa7eeb.jpg\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# суть Random Forest\n",
    "Image(url=\"https://www.meme-arsenal.com/memes/b21eaf3fcba087cc3dc2e6c43eaa7eeb.jpg\",\n",
    "     width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У алгоритмов в sklearn стандартный интерфейс - есть функции fit, predict и predict_proba (если классификатор выдает вероятности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit обучает модель\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предикт предсказывает классы\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.710124826629681"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzeRtqt2tBTt",
    "nbpresent": {
     "id": "63107774-a12e-4893-af45-2353b2299d0a"
    }
   },
   "source": [
    "#### Меры качества бинарной классификации \n",
    "\n",
    "При сопоставлении предсказаний модели с правильными (истинными) ответами составляют вот такую таблицу\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\"</th>\n",
    "    <th colspan=\"2\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>positive</td>\n",
    "    <td>negative</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>positive</td>\n",
    "    <td><span style=\"color:green\">$tp$</span></td>\n",
    "    <td><span style=\"color:red\">$fp$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>negative</td>\n",
    "    <td><span style=\"color:red\">$fn$</span></td>\n",
    "    <td><span style=\"color:green\">$tn$</span></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$tp$ - это $true\\_positive$, количество истинно положительных предсказаний модели (т.е. модель считает, что текст токсичный и он на самом деле токсичный)\n",
    "\n",
    "$fp$ - это $false\\_positive$, количество ложно положительных предсказаний модели (т.е. модель считает, что текст токсичный, а он на самом деле НЕ токсичный)\n",
    "\n",
    "$tn$ - это $true\\_negative$, количество истинно отрицательных предсказаний модели (т.е. модель считает, что текст нетоксичный и он на самом деле нетоксичный)\n",
    "\n",
    "$fn$ - это $false\\_negative$, количество ложно отрицательных предсказаний модели (т.е. модель считает, что текст нетоксичный и он на самом деле токсичный)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зеленым в таблице выделены правильные ответы, а красным - ошибки. Часто их называют ошибка первого (false positive) и второго рода (false negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки моделей эти значений обычно не используются. На их основе считаются другие метрики. Основные для нас это: accuracy, точность, полнота и f-мера:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MeIEVS9tBTu",
    "nbpresent": {
     "id": "67e4f042-0f46-4a15-98a6-5865a35685bf"
    }
   },
   "source": [
    "$precision = Pr =  \\frac{tp}{tp+fp} $ – точность (показывает, какая доля положительных предсказаний является правильными)\n",
    "\n",
    "$recall = R = \\frac{tp}{tp+fn} $ – полнота (показывает, насколько полно предсказывается положительный класс)\n",
    "\n",
    "$F_1 = \\frac{2 Pr * R}{Pr + R}$ – $F$-мера (объединяет точность и полноту в одно число)\n",
    "\n",
    "$accuracy = \\frac{tp + tn}{tp + fp + fn + tn}$ –  по-русски это тоже точность, поэтому иногда возникает путаница; лучше всего говорить accuracy (это просто доля правильных ответов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy хоть и самая простая и логичная, но используется редко. Эта метрика не устойчива к дисбалансу классов, а он почти всегда есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию лучше всего смотреть на F-меру. Но бывают задачи, где важнее точность, а бывают - где важнее полнота. Например, если на основе предсказания токсичности автору сразу дается бан, то нам нужно быть увереным, что эти предсказания являются очень точными. А если мы хотим снизить количество токсичности на платформе до минимума, то нам будет важнее полнота."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть отдельные функции для каждой из метрик, а есть удобная функция classification_report, которая считает все сразу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.82      0.84       952\n",
      "         1.0       0.68      0.75      0.71       490\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.77      0.78      0.78      1442\n",
      "weighted avg       0.80      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba возвращает вероятности классов\n",
    "# это полезно когда нужно подобрать порог например\n",
    "probas = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80526376, 0.19473624],\n",
       "       [0.10602066, 0.89397934],\n",
       "       [0.50724877, 0.49275123],\n",
       "       ...,\n",
       "       [0.62165136, 0.37834864],\n",
       "       [0.52490349, 0.47509651],\n",
       "       [0.29114768, 0.70885232]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в левой колонке вероятность 0 (нетокстичности)\n",
    "# в правой - вероятность 1 (токсичности)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем вторую колонку\n",
    "# проверим что она больше 0,85\n",
    "# заменим True и False на 0 и 1 чтобы получить предсказания\n",
    "preds = (probas[:,1]>0.85).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80       952\n",
      "         1.0       0.95      0.04      0.07       490\n",
      "\n",
      "    accuracy                           0.67      1442\n",
      "   macro avg       0.81      0.52      0.44      1442\n",
      "weighted avg       0.76      0.67      0.55      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# точность по токсичному классу сильно выросла но при этом упала полнота\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем другие классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.97      0.88       952\n",
      "         1.0       0.89      0.54      0.67       490\n",
      "\n",
      "    accuracy                           0.82      1442\n",
      "   macro avg       0.85      0.75      0.77      1442\n",
      "weighted avg       0.83      0.82      0.81      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1.)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.37      0.51       952\n",
      "         1.0       0.41      0.84      0.55       490\n",
      "\n",
      "    accuracy                           0.53      1442\n",
      "   macro avg       0.61      0.61      0.53      1442\n",
      "weighted avg       0.68      0.53      0.53      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.85      0.82       952\n",
      "         1.0       0.67      0.60      0.63       490\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.73      0.72      0.73      1442\n",
      "weighted avg       0.76      0.76      0.76      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Меры качества многоклассовой классификации \n",
    "Если количество классов больше, то расчет метрик становится немного сложнее. Можно свести все к бинарной оценке, если рассматривать каждый класс по отношению ко всем другим классам. Т.е. считать текущий класс положительным, а все другие классы отрицательным классом. Для трех классов у нас получится три таблицы:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"4\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>class 1</td>\n",
    "    <td>(class 2, class 3)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>class 1</td>\n",
    "    <td><span style=\"color:green\">$tp_1$</span></td>\n",
    "    <td><span style=\"color:red\">$fp_1$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>(class 2, class 3)</td>\n",
    "    <td><span style=\"color:red\">$fn_1$</span></td>\n",
    "    <td><span style=\"color:green\">$tn_1$</span></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"4\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>class 2</td>\n",
    "    <td>(class 1, class 3)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>class 2</td>\n",
    "    <td><span style=\"color:green\">$tp_2$</span></td>\n",
    "    <td><span style=\"color:red\">$fp_2$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>(class 1, class 3)</td>\n",
    "    <td><span style=\"color:red\">$fn_2$</span></td>\n",
    "    <td><span style=\"color:green\">$tn_2$</span></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"4\">правильные <br>ответы</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>class 3</td>\n",
    "    <td>(class 1, class 2)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">предсказания <br>модели</td>\n",
    "    <td>class 3</td>\n",
    "    <td><span style=\"color:green\">$tp_3$</span></td>\n",
    "    <td><span style=\"color:red\">$fp_3$</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>(class 1, class 2)</td>\n",
    "    <td><span style=\"color:red\">$fn_3$</span></td>\n",
    "    <td><span style=\"color:green\">$tn_3$</span></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответственно для каждого класса мы можем отдельно посчитать точность, полноту и F-меру. \n",
    "А если мы хотим найти общие метрики, то у нас есть два варианта: \n",
    "\n",
    "1) усреднить отдельные точности, полноты, F-меры по количеству классов (макро усреднение)\n",
    "\n",
    "$macro\\ Precision = \\frac{\\sum Pr_c}{|C|}$  \n",
    "$macro\\ Recall = \\frac{\\sum R_c}{|C|}$  \n",
    "$macro\\ F1\\_measure = \\frac{\\sum F1_c}{|C|}$  \n",
    "\n",
    "2) рассчитать общие tp, tn, fp, fn и вычислить точность, полноту по ним (микро усреднение)\n",
    "\n",
    "\n",
    "$micro\\ Precision =  \\frac{\\sum tp_c}{\\sum tp_c+fp_c} $ \n",
    "\n",
    "$micro\\ Recall = \\frac{\\sum tp_c}{\\sum tp_c+fn_c} $ \n",
    "\n",
    "Микро усреднение зависит от баланса классов - доминирующие классы будут перетягивать метрику на себя, за счет того, что их tp,fp,tn,fn будут иметь больший вклад в результат. Макро усреднение не учитывает размер классов, что может привезти к тому, что мелкие классы, плохо классифицируемые моделью, будут непропорционально занижать общий результат. \n",
    "\n",
    "Макро усреднение можно улучшить дополнительным взвешиванием каждого класса. Можно взвесить на частотность (тогда это будет практически микро среднее), а можно придумать каждому классу свой вес, в зависимости от задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем данные с несколькими классами и попробуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiclass = pd.read_csv('tweet_emotions.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_multiclass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data_multiclass.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       0.215950\n",
       "worry         0.211475\n",
       "happiness     0.130225\n",
       "sadness       0.129125\n",
       "love          0.096050\n",
       "surprise      0.054675\n",
       "fun           0.044400\n",
       "relief        0.038150\n",
       "hate          0.033075\n",
       "empty         0.020675\n",
       "enthusiasm    0.018975\n",
       "boredom       0.004475\n",
       "anger         0.002750\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть совсем маленькие классы, заменим их на 1 общий класс other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiclass.loc[data_multiclass.sentiment.isin(counts[counts<0.05].index), 'sentiment'] = 'other' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_multiclass, \n",
    "                               test_size=0.1, \n",
    "                               stratify=data_multiclass.sentiment,\n",
    "                               shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.sentiment.values\n",
    "y_test = test.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем какой-нибудь классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.4)\n",
    "X = vectorizer.fit_transform(train.content)\n",
    "X_test = vectorizer.transform(test.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20, )\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.42      0.15      0.22       521\n",
      "        love       0.53      0.33      0.41       384\n",
      "     neutral       0.29      0.72      0.42       864\n",
      "       other       0.40      0.06      0.11       650\n",
      "     sadness       0.50      0.10      0.17       516\n",
      "    surprise       0.00      0.00      0.00       219\n",
      "       worry       0.32      0.48      0.39       846\n",
      "\n",
      "    accuracy                           0.33      4000\n",
      "   macro avg       0.35      0.26      0.24      4000\n",
      "weighted avg       0.37      0.33      0.28      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мешок нграмм "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы учесть информацию о порядке слов и при этом остаться в рамках простой мешкословной модели, можно использовать небольшой трюк - добавить в словарь нграммы.\n",
    " \n",
    "О том, как найти хорошие нграммы, мы поговорим позже, а пока воспользуемся встроенными возможностями sklearn. У векторайзеров есть параметр ngram_range, который по умолчанию задан как (1,1). Мы можем изменить его на (1,2) или (1,3), чтобы в словаре появились еще биграммы и триграммы, соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, min_df=10, max_df=0.1, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие нграммы попали в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 лет',\n",
       " 'больше чем',\n",
       " 'бы не',\n",
       " 'было бы',\n",
       " 'во время',\n",
       " 'вообще не',\n",
       " 'вот это',\n",
       " 'все же',\n",
       " 'все равно',\n",
       " 'все таки',\n",
       " 'все это',\n",
       " 'вы не',\n",
       " 'где то',\n",
       " 'да не',\n",
       " 'даже если',\n",
       " 'даже не',\n",
       " 'для меня',\n",
       " 'для того',\n",
       " 'для этого',\n",
       " 'до сих',\n",
       " 'до сих пор',\n",
       " 'думаю что',\n",
       " 'если бы',\n",
       " 'если не',\n",
       " 'если ты',\n",
       " 'если это',\n",
       " 'же как',\n",
       " 'же не',\n",
       " 'за это',\n",
       " 'зависит от']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizer.get_feature_names() показывает словарь, индексы в списке соответствуют колонкам в матрице\n",
    "# нграмы склеиваются через пробел в sklearn\n",
    "[x for x in vectorizer.get_feature_names() if ' ' in x][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83       944\n",
      "         1.0       0.88      0.29      0.43       498\n",
      "\n",
      "    accuracy                           0.74      1442\n",
      "   macro avg       0.80      0.63      0.63      1442\n",
      "weighted avg       0.78      0.74      0.69      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стандартные датасеты для классификации\n",
    "\n",
    "Выше все примеры были на датасете с анализом тональности. Давайте посмотрим на несколько других типичных датасетов для задачи классификации\n",
    "\n",
    "\n",
    "Одним из самых широко используемых датасетов являются отзывы на imdb. Это тоже датасет для анализа тональности с бинарной классификацией, но его стоит упомянуть отдельно потому что он очень популярный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998e5b0d2f554ebfa4870a03f4ef6f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab556bc1b5bf4311ac2d24902117e820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ebc441c371427ba938a1d1f5845d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38123527cd1b422b806dae079d50871e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6503b2bd4bc445c2aad4ecbd6a046dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e269abceed7f4d1ba0d37f8d96e9bdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf0ac6db7a94250b927adafbca2bf1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"stanfordnlp/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to expand on that I don't know. This is already a waste of my time. I just wanted to warn others. Avoid this movie. The acting sucks and the writing is just moronic. Bad in every way. The only nice thing about the movie are Deniz Akkaya's breasts. Even that was ruined though by a terrible and unneeded rape scene. The movie is a poorly contrived and totally unbelievable piece of garbage.<br /><br />OK now I am just going to rag on IMDb for this stupid rule of 10 lines of text minimum. First I waste my time watching this offal. Then feeling compelled to warn others I create an account with IMDb only to discover that I have to write a friggen essay on the film just to express how bad I think it is. Totally unnecessary.\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасеты с отзывами вообще популярны. Часто в них еще бывает не бинарная классификация тональности, а категории (1-5 ил 1-10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ тональности еще тесно связан с анализом токсичности. В таких текстах негативная тональность подразделяется на определенные типы (hateful, violence, harassment и т.д). Это немного разные задачи, так как негативная тональность не обязательно означает токсичность, но у этих задач есть большое пересечение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77eab324fe1e43d2900b34c3f1887ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hatecheck = load_dataset('mteb/multi-hatecheck', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['functionality', 'text', 'is_hateful', 'lang'],\n",
       "        num_rows: 40310\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatecheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'functionality': 'derog_neg_emote_h',\n",
       " 'text': 'انا بكره النساء.',\n",
       " 'is_hateful': 'hateful',\n",
       " 'lang': 'ara'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatecheck['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ab07e39aaa4c3ca442adf5ad73e732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/40310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eng_hatecheck = hatecheck.filter(lambda e: e[\"lang\"] == 'eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'functionality': 'ref_subs_clause_h',\n",
       " 'text': \"Disabled people are nothing like us and that's why they deserve to die. \",\n",
       " 'is_hateful': 'hateful',\n",
       " 'lang': 'eng'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_hatecheck[\"test\"][1423]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другая типичная классификационная задача - анализ грамматичности текста. Есть стандартный датасет Cola, который очень часто используется для бенчмарка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336d77101c064a04b0b761c8a6c6b55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ccd7a059d74c07bea1ebad0fbdd51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/37.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06473a08977c476ea5200ec01097881a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/37.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a756c62db88e49c2a59dd5139e0c8b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dcb89225df47c09de646ff21d5f35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3bc486667a4be9859b151bfd54fd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cola = load_dataset('nyu-mll/glue', 'cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Fred watered the plants flat.', 'label': 1, 'idx': 6}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola['train'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также типичная классификационная задача - предсказание намерения пользователя (intent detection). Она немного устарела с появлением хороших языковых моделей, но все равно хорошо подходит для бенчмарков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5b74eff2014d9b83602a5d54c8051c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04af6f19244487b9c50559efece7315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28948dfb2c1746a388e9d03126a527d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b87328ec49b431cbb494f33aae4f016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a05ce36e0344997a22c25ac6b0e33a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/262k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f004aaf0a7004a3f9c6c1461e6e92cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/73.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb32cf3f2aa44e6a926c69cea261e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950cfad99c044284b6c087eb62e3d814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cbe0e54ad04f9588e92c6ad0e4fc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba4a587a1fc485a8d60b2c3cb1847f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intent = load_dataset('mteb/amazon_massive_intent', \"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'label': 'alarm_set',\n",
       " 'label_text': 'alarm_set',\n",
       " 'text': 'разбуди меня в девять утра в пятницу',\n",
       " 'lang': 'ru'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще много классификационных датасетов можно найти тут например - \n",
    "https://embeddings-benchmark.github.io/mteb/overview/available_tasks/classification/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасеты для парной классификации\n",
    "\n",
    "И последнее о чем хочется сказать - это парная классификация. Это очень популярный тип датасетов, которые используются в том числе и в актуальных бенчмарках для языковых моделей. В таких датасетах вместо классификации одного текста нужно классифицировать пару текстов. Классическая задача для парной классификации - NLI (natural language entailment), где нужно предсказать следует ли второе предложение из второго или противоречит ему. \n",
    "\n",
    "Для такой задачи кончно нужны более серьезные модели, но и простой мешок слов тут тоже можно применить\n",
    "\n",
    "Можно сделать два отдельных векторайзера для каждого из текстов в паре и перед обучением модели конкатенировать две матрицы в одну. Давайте попробуем это сделать на датасете MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli = cola = load_dataset('nyu-mll/glue', 'mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'The extent of the behavioral effects would depend in part on the structure of the individual account program and any limits on accessing the funds.',\n",
       " 'hypothesis': 'Many people would be very unhappy to loose control over their own money.',\n",
       " 'label': -1,\n",
       " 'idx': 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli['test_matched'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_train = nli['train'].select([i for i in range(5000)])\n",
    "nli_test = nli['validation_matched'].select([i for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_premise = TfidfVectorizer(max_features=1000, min_df=10, max_df=0.1, ngram_range=(1, 3))\n",
    "vectorizer_hypothesis = TfidfVectorizer(max_features=1000, min_df=10, max_df=0.1, ngram_range=(1, 3))\n",
    "\n",
    "X_premises = vectorizer_premise.fit_transform(nli_train['premise'])\n",
    "X_hypothesis = vectorizer_hypothesis.fit_transform(nli_train['hypothesis'])\n",
    "\n",
    "\n",
    "X_premises_test = vectorizer_premise.transform(nli_test['premise'])\n",
    "X_hypothesis_test = vectorizer_hypothesis.transform(nli_test['hypothesis'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X = hstack([X_premises, X_hypothesis])\n",
    "X_test = hstack([X_premises_test, X_hypothesis_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nli_train['label']\n",
    "y_test = nli_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50       341\n",
      "           1       0.53      0.15      0.23       319\n",
      "           2       0.50      0.50      0.50       340\n",
      "\n",
      "    accuracy                           0.45      1000\n",
      "   macro avg       0.48      0.44      0.41      1000\n",
      "weighted avg       0.47      0.45      0.42      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.41      0.40       341\n",
      "           1       0.40      0.42      0.41       319\n",
      "           2       0.51      0.46      0.48       340\n",
      "\n",
      "    accuracy                           0.43      1000\n",
      "   macro avg       0.43      0.43      0.43      1000\n",
      "weighted avg       0.43      0.43      0.43      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
