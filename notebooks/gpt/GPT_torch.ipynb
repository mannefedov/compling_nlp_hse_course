{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8079d2e-dfd2-4cd4-bc7c-9691fe354900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rusenttokenize\n",
    "# !pip install tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a071746-6010-412c-8e38-72553da0d780",
   "metadata": {},
   "source": [
    "В этом семинаре мы попробуем натренировать простую версию GPT. Код в очень большой части основан на вот этот туториале от Andrey Karpathy - https://www.youtube.com/watch?v=kCc8FmEb1nY . Я добавил более объемный датасет, BPE токенизацию, а также некоторые дополнительные пояснения, но основной код практически точно такой же, потому что сложно придумать что-то лучше.\n",
    "\n",
    "Помимо собственно разбора GPT модели, в этом семинаре также разбирается pytorch. \n",
    "Но прежде чем переходить к этому, давайте загрузим данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048732b-470d-433b-ad3d-57505ad08075",
   "metadata": {},
   "source": [
    "## Данные и токенизация\n",
    "\n",
    "Для обучения GPT нужен текст. Чем больше, тем лучше. В туториале использовался просто корпус текстов Шекспира, но я решил взять чуть более реалистичный и объемный текст - новостные тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730cc70e-2db8-4f7b-94e5-c787a0005fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rusenttokenize import ru_sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eed8939-d01a-456d-996c-9101ff9aef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://github.com/mannefedov/compling_nlp_hse_course/raw/refs/heads/master/data/lenta_40k.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df3b0e0-f454-4142-8640-81b78f47c142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия должна сотрудничать с Всемирным антидоп...</td>\n",
       "      <td>Спорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Уголовный суд Кувейта 28 июня освободил под за...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Французский журнал Charlie Hebdo опубликовал н...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Петербурге в доме № 53 по улице Лени Голиков...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В московском аэропорту \"Домодедово\" задержан г...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           topic\n",
       "0  Россия должна сотрудничать с Всемирным антидоп...           Спорт\n",
       "1  Уголовный суд Кувейта 28 июня освободил под за...             Мир\n",
       "2  Французский журнал Charlie Hebdo опубликовал н...  Интернет и СМИ\n",
       "3  В Петербурге в доме № 53 по улице Лени Голиков...          Россия\n",
       "4  В московском аэропорту \"Домодедово\" задержан г...          Россия"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cca75f-26f8-4b2a-928e-dd5ecb0e3a51",
   "metadata": {},
   "source": [
    "Нам понадобятся только тексты. Также трансформеры очень чувствительны к длине текста, поэтому для простоты разделим все тексты на предложения и будем считать каждое предложение одним текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab05863b-2763-4f56-9d68-ecdf7817d673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for text in data.text.values:\n",
    "    sentences.extend(ru_sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "869eb55d-6618-468e-8489-c71f9afa914e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489727"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# почти 500 тыс предложений\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0921762d-81ff-467b-82b2-a8c993d6ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cохраним в отдельный файл чтобы больше не тратить время на токенизацию,\n",
    "# также файл понадобится дальше для обучения токенизатора\n",
    "f = open('corpus.txt', 'w')\n",
    "for sent in sentences:\n",
    "    f.write(sent + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe17b21-d744-41ee-9440-e45f88d16bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = open('corpus.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af103e-460a-452d-9ae1-44e3f2402e73",
   "metadata": {},
   "source": [
    "Теперь нам нужно обучить токенизатор. В туториале Karpathy обучал GPT на символах, но обычно используется subword токенизация. Чтобы сделать эту модель чуть менее игрушечной, давайте добавим такую токенизацию. На саму модель это никак не повлияет, так как она в любом случае ожидает список индексов как input. С символьной токенизацией такие списки будут очень длинным, а subword токенизация группирует символы в нграммы (или даже целые слова) и таким образом длина последовательности сокращается.\n",
    "\n",
    "Мы не будем писать алгоритм токенизации с нуля, а воспользуемся готовым решением от huggingface - библиотекой tokenizers. Она написана на Rust и поэтому достаточно быстрая. \n",
    "Токенизация будет основана на алгоритме Byte-Pair-Encoding. В нем строки сначала кодируются как байты, которые представляют индекс символа в таблице Юникода. И в процессе обучения отдельные байты группируются по частотности в нграммы до тех пор, пока размер словаря не достигнет заданого лимита. \n",
    "По умолчанию это значение - 30 тысяч. Также в словаре также обычно добавляют какие-то специальные токены, которых нет в текстах, но которые будут добавляться, чтобы передать в модели какие-то дополнительные параметры. Мы добавим три токена - паддинг, токен начала текста, токена конца текста. Паддинг будет использоваться чтобы сравнять все тексты до одной длины при передаче в модель, но мы не хотим, чтобы эти токены как-то влияли на обучение, поэтому их нужно будет замаскировать. А BOS и EOS мы уже использовали в простых языковых моделях. Тут они нужны для тех же целей. В реальных моделях также в специальные токены входят токены разделяющие части промпта - системное сообщение, сообщение пользователя, сообщение модели и т.п. Про них мы поговорим в следующих семинарах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d93e18-9e45-4d5b-9a99-8e32042bc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(BPE()) \n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(special_tokens=[\"[PAD]\", \"[BOS]\", \"[EOS]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c0b5bd5-6d8e-46cf-bdd0-1d6d4c6e274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# токенайзер обучается на файле а не на питоновских списках\n",
    "tokenizer.train(files=[\"corpus.txt\"], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdc103d1-12af-4cd2-8f83-08f448f4da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним токенизатор\n",
    "tokenizer.save('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55469115-3a7a-4f64-9261-d0b6e0b8fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# при перезапуске можно просто перезагрузить готовый токенизатор\n",
    "# также он понадобится если мы решим сохранить модель\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a16f80-2a4c-4e1e-a792-9e8638e1103b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8772a7-3ce8-4580-b7fe-7fd0ab00a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b73b1-d06e-4e80-9084-0ce9c578dcaa",
   "metadata": {},
   "source": [
    "Посмотрим что получается в результате токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8928e36f-6212-4b9d-9538-e30e14fe5dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[702, 660, 15, 393, 7975]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Какой-то текст').ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2943f-de0d-432f-8225-fc6e6aab622b",
   "metadata": {},
   "source": [
    "Напишем еще функцию которая будет подставлять BOS и EOS токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "222326c4-25e9-4326-a968-971830028a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, tokenizer):\n",
    "    return [tokenizer.token_to_id('[BOS]')] + tokenizer.encode(text).ids + [tokenizer.token_to_id('[EOS]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a4f46-8c5b-432d-9ea3-52b4707cd56c",
   "metadata": {},
   "source": [
    "Индекс паддинг токена пригодится позже для маскинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa00ab64-24fa-4b8d-9fa6-e465c01377ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = tokenizer.token_to_id('[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0adae-2bea-482e-82f1-f00af092c01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebffabc4-1301-41a9-a79a-f56756aec49e",
   "metadata": {},
   "source": [
    "Теперь токенизируем все предложения и создадим датасет, который будет передавать в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "210f8c8e-75aa-4e31-8e36-cc2d1099518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4b703a-2229-451d-b5eb-6b236d17addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, sentences, tokenizer, max_len=32):\n",
    "        # каждое предложение преобразуется в последовательность индексов \n",
    "        # а списки преобразуются в тензоры\n",
    "        self.encoded_texts = [torch.LongTensor(encode(sent, tokenizer)[-max_len:]) for sent in sentences]\n",
    "        # чтобы составить один общий обучающий тензор нужно сравнять длины последовательностей отдельных текстов\n",
    "        # в торче не такая удобная функция паддинга, поэтому транкация (отрезание лишнего) происходит уже выше\n",
    "        self.X = torch.nn.utils.rnn.pad_sequence(self.encoded_texts, padding_value=PAD_IDX, batch_first=True)\n",
    "        self.length = len(self.encoded_texts)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # обучающий пример для GPT составляется из одного текста\n",
    "        # x - это все токены кроме последнего\n",
    "        # y - это все токены кроме первого\n",
    "        # другими словами, y это x со сдвигом вправо\n",
    "        # каждый отдельный элемент в y - следующий токен для соответствующего элемента в x\n",
    "        # tokens = [1,2,3,4,5]\n",
    "        # x = [1,2,3,4]\n",
    "        # y = [2,3,4,5]\n",
    "        \n",
    "        x = self.X[index][:-1]\n",
    "        y = self.X[index][1:]\n",
    "        \n",
    "        # чтобы не учитывать паддинг нам нужно создать маску\n",
    "        mask = x!=PAD_IDX\n",
    "\n",
    "        return x, y, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018b73c-f17a-48ba-a56f-8a5fc363fc29",
   "metadata": {},
   "source": [
    "Разделим данные на обучающие и валидационные (90% и 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52547eac-519a-498a-84ae-3f97dd5e0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(sentences)) # first 90% will be train, rest val\n",
    "sentences_train = sentences[:n]\n",
    "sentences_val = sentences[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6904ab1e-44b5-44f7-b073-dc53227573e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "622c6e30-6c24-4ee8-abad-b381e7958426",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(sentences_train, tokenizer, MAX_LEN)\n",
    "val_set = Dataset(sentences_val, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d924ff1b-039e-4a21-9183-a11dedd8390d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    1,  1481,  2499, 13595,   226,  4896,   533, 12335, 26891, 14188,\n",
       "            10, 14988,   807,  1045,   774, 19648,  3317,  4676, 11158,   389,\n",
       "          8412,  9819,  1984,   521,   211,  9880,    15,   422,    15, 12185,\n",
       "            16,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0]),\n",
       " tensor([ 1481,  2499, 13595,   226,  4896,   533, 12335, 26891, 14188,    10,\n",
       "         14988,   807,  1045,   774, 19648,  3317,  4676, 11158,   389,  8412,\n",
       "          9819,  1984,   521,   211,  9880,    15,   422,    15, 12185,    16,\n",
       "             2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0]),\n",
       " tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96703f1e-6ab4-4b57-8084-8ce50668a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=True, )\n",
    "val_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b693c-e415-417a-b1ec-22810d3198ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35cb8123-b7a8-4146-8168-83e05ad73d63",
   "metadata": {},
   "source": [
    "Теперь можно переходить к обучению. Сначала давайте посмотрим на отдельные инструменты pytorch, которые будут использовать в моделях\n",
    "\n",
    "#### torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6b9c361-5816-4c80-af90-9298b891a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в коде часто встречается вот такой импорт\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd441795-65cd-423c-ab65-facd0b2f8c8a",
   "metadata": {},
   "source": [
    "Торч во многом похож на numpy и в нем есть те же стандартные функции "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9899af-9cc2-47fc-a2db-b483406ac79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создает тензор заданного размера и заполняет его нулями\n",
    "torch.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dafd7975-6707-4bf2-a009-2e7579d60a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создает тензор заданного размера и заполняет его единицами\n",
    "torch.ones((2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bea528b0-de82-4d89-bc91-c524eb4d4767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8246, 0.7336]],\n",
       "\n",
       "        [[0.0444, 0.0924]],\n",
       "\n",
       "        [[0.5371, 0.2244]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создает тензор заданного размера и заполняет его случайными числами 0-1\n",
    "torch.rand((3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28ac28d6-0dcb-4a57-a89a-5fe6a2a01bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размерность можно получить также как в numpy\n",
    "t = torch.rand((3, 1, 2))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27221fc1-3616-462b-8391-cb464cc5fff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8901, 0.6534],\n",
       "        [0.3813, 0.0028],\n",
       "        [0.2018, 0.4946]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтобы изменить размерность можно использовать .view\n",
    "t.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17ff6995-5c89-4ee4-95c8-5037bf9d8d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8901, 0.6534, 0.3813, 0.0028, 0.2018, 0.4946])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b824238b-0f60-4ebc-9bc4-7c4182e282e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 4]' is invalid for input of size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# изменение размерности не добавляет и не удаляет данные из изначального тензора\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# поэтому размеры должны совпадать\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 4]' is invalid for input of size 6"
     ]
    }
   ],
   "source": [
    "# изменение размерности не добавляет и не удаляет данные из изначального тензора\n",
    "# поэтому размеры должны совпадать\n",
    "t.view(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50381f52-3b1a-4810-8d99-43385f4d8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если размерности нужно поменять местами то для этого используется transpose\n",
    "# размерность dim1 меняется местами с размерностью dim2\n",
    "t.transpose(-2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0569260-a9d9-430b-a496-124608787fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как и в numpy у тензоров есть специальный атрибут .T который возвращает транспонированный тензор\n",
    "# но при обучении моделей мы обычно работает с тензорами, где первая размерность это batch_size и ее нужно оставить на своей месте\n",
    "# поэтому используется transpose c указанием конкретных размерностей а batch размерность остается на своем месте\n",
    "t.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f3ae5-b058-4663-80ba-1c03a00a06b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "880bb83f-bf67-419f-b20f-a6945fef6007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 3]), torch.Size([4, 3, 3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# с помощью транспонирования можно рассчитать dot product (=близость) между\n",
    "# векторами в последовательности в батче\n",
    "# t размерности (4,3,2) и напрямую умножить его на себя нельзя потому что размерности 1,2 и 1,2 не подходят (нужно чтобы внутрение сходились)\n",
    "# transpose(-2, -1) или transpose(2, 1) что то же самое \n",
    "# позволят рассчитать dot product чем простое умножение @\n",
    "# оно тоже уже умеет работать с батчами поэтому первая разверность не изменится\n",
    "# в результате размерность будет 4,3,3\n",
    "# то есть для каждого примера в батче размером 4\n",
    "# между всеми элементами последовательности размером 3\n",
    "# будет рассчита dot product между отдельными векторами размерности 2\n",
    "# близость считается между парами в последовательности поэтому в результате для каждого будет 3 близости\n",
    "t = torch.rand((4, 3, 2))\n",
    "(t @ t.transpose(-2, -1)).shape, (t @ t.transpose(2, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755d7dc-31c7-4420-b818-9fecdbae1605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec448a4b-a210-4d86-b36e-23050c666aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8008, 0.9708]],\n",
       " \n",
       "         [[0.1924, 0.2296]],\n",
       " \n",
       "         [[0.1065, 0.2852]],\n",
       " \n",
       "         [[0.8307, 0.0645]]]),\n",
       " tensor([[0.8008, 0.9708],\n",
       "         [0.1924, 0.2296],\n",
       "         [0.1065, 0.2852],\n",
       "         [0.8307, 0.0645]]),\n",
       " torch.Size([4, 2]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# если одна из размерностей единичная то ее можно схлопнуть \n",
    "t = torch.rand((4, 1, 2))\n",
    "t, t.squeeze(1), t.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fefe5056-dca7-4a0e-92ae-6425669bf893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8008, 0.9708]],\n",
       " \n",
       "         [[0.1924, 0.2296]],\n",
       " \n",
       "         [[0.1065, 0.2852]],\n",
       " \n",
       "         [[0.8307, 0.0645]]]),\n",
       " tensor([[[[0.8008],\n",
       "           [0.9708]]],\n",
       " \n",
       " \n",
       "         [[[0.1924],\n",
       "           [0.2296]]],\n",
       " \n",
       " \n",
       "         [[[0.1065],\n",
       "           [0.2852]]],\n",
       " \n",
       " \n",
       "         [[[0.8307],\n",
       "           [0.0645]]]]),\n",
       " torch.Size([4, 1, 2, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# также можно добавить единичную размерность \n",
    "t, t.unsqueeze(3), t.unsqueeze(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518de6e9-6b93-4bbd-8640-6681d38e9c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a9584d2-afc0-4553-a579-237254e6732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand((1,3,4))\n",
    "t2 = torch.rand((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8018059c-d96d-4d76-8d45-62a9ab58ed8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cat конкатенирует тензоры по заданной размерности (по умолчанию первой - то есть батч размерности)\n",
    "torch.cat([t1, t2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49c717-9d93-4cf5-93a0-87b0865daea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "750903ca-ba86-414e-be47-b427853c0d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для создания масок для attention понадобится функция tril которая зануляет элементы выше диагонали \n",
    "torch.tril(torch.ones((2,3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7da5d949-fc75-4c17-805a-6a448f4c0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c помощью tril и функции masked_fill можно заменять значения в тензоре по диагональному паттерну"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b40a33b-bf99-43e9-a1e0-6e5aa8fc0cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7635, 0.4642, 0.7521],\n",
       "         [0.4594, 0.7915, 0.5790],\n",
       "         [0.0320, 0.3731, 0.9466]],\n",
       "\n",
       "        [[0.6682, 0.3126, 0.8954],\n",
       "         [0.9256, 0.7902, 0.4135],\n",
       "         [0.1221, 0.3147, 0.1836]],\n",
       "\n",
       "        [[0.2292, 0.6574, 0.7839],\n",
       "         [0.2278, 0.7917, 0.1904],\n",
       "         [0.9878, 0.6356, 0.5606]],\n",
       "\n",
       "        [[0.7482, 0.4246, 0.8443],\n",
       "         [0.9940, 0.1193, 0.7985],\n",
       "         [0.0143, 0.4395, 0.3698]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((4, 3, 3))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1129b831-ceee-4a8b-a6f5-411c25b138ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7635,   -inf,   -inf],\n",
       "         [0.4594, 0.7915,   -inf],\n",
       "         [0.0320, 0.3731, 0.9466]],\n",
       "\n",
       "        [[0.6682,   -inf,   -inf],\n",
       "         [0.9256, 0.7902,   -inf],\n",
       "         [0.1221, 0.3147, 0.1836]],\n",
       "\n",
       "        [[0.2292,   -inf,   -inf],\n",
       "         [0.2278, 0.7917,   -inf],\n",
       "         [0.9878, 0.6356, 0.5606]],\n",
       "\n",
       "        [[0.7482,   -inf,   -inf],\n",
       "         [0.9940, 0.1193,   -inf],\n",
       "         [0.0143, 0.4395, 0.3698]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в тезоре t значения которые соответствуют нулю в треугольной маске заменяются на минус бесконечность\n",
    "t.masked_fill(torch.tril(torch.ones((3,3)))==0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f99660e6-5a50-46a5-9a95-3ec1a7cb81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с помощью такой операции в GPT реализован механизм внимания где каждый токен общается только с токенами до него"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad05e6-dcd5-446d-b5a9-2aa5eeb5956d",
   "metadata": {},
   "source": [
    "### deep learning layers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9d530e09-718a-4d9d-b0af-28f8c995f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding слой сопоставляет вектор индексу\n",
    "# первый аргумент - размерность словаря\n",
    "# второй - размерность вектора\n",
    "embed = nn.Embedding(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f79157b0-d0a9-4905-8638-f253072515b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# два текста по 4 токена в каждом\n",
    "t = torch.LongTensor([[1,3,4,5], [3,4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c96ba82-b2b6-4ba8-a01c-5403f7c6a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "714ae7e7-54cb-4e95-8d00-445f1151e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 20])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в результате каждому токену сопоставляется вектор 20\n",
    "embed(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d51f1-c181-4e56-8b00-a7715e891436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "31d51b4b-bf34-4a6c-9560-ef639ed707bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# полносвязный слой или линейной преобразование\n",
    "# первый аргумент изначальная размерность\n",
    "# второй - выходная размерность\n",
    "linear = nn.Linear(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eb8055bf-af97-44ca-931e-a8f3375ec0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изначально у нас есть batch с двумя примерами где каждый состоит из трех токенов и у каждого токена вектор 2\n",
    "t = torch.rand((2, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e3ef39b9-81e3-47e5-abb5-016c2154d695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# применив полносвязный слой мы получим то же самое только размерность векторов теперь 10\n",
    "linear(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "66a7f391-a159-430f-a500-9649f8769144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция активации которая зануляет отрицательные значения\n",
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c8e2c0f9-75d1-4532-9eb4-eece1b479c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5116, -0.5753,  0.1465,  0.1994,  0.5395, -0.0600, -0.0829,\n",
       "            0.0278, -0.5628, -0.5003],\n",
       "          [-0.5552, -1.0051,  0.1534,  0.2507,  0.2597, -0.3272, -0.2982,\n",
       "           -0.0311, -0.2502, -0.2841],\n",
       "          [-0.5205, -0.9500,  0.2155,  0.4156,  0.2760, -0.3582, -0.4242,\n",
       "            0.1563, -0.2666, -0.1669]],\n",
       " \n",
       "         [[-0.5201, -0.6877,  0.1545,  0.2296,  0.4644, -0.1363, -0.1543,\n",
       "            0.0301, -0.4787, -0.4296],\n",
       "          [-0.4676, -0.5273,  0.2303,  0.4240,  0.5444, -0.1179, -0.2653,\n",
       "            0.2761, -0.5658, -0.3297],\n",
       "          [-0.5000, -0.8396,  0.2337,  0.4569,  0.3417, -0.3102, -0.4177,\n",
       "            0.2286, -0.3394, -0.1764]]], grad_fn=<ViewBackward0>),\n",
       " tensor([[[0.0000, 0.0000, 0.1465, 0.1994, 0.5395, 0.0000, 0.0000, 0.0278,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1534, 0.2507, 0.2597, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2155, 0.4156, 0.2760, 0.0000, 0.0000, 0.1563,\n",
       "           0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.1545, 0.2296, 0.4644, 0.0000, 0.0000, 0.0301,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2303, 0.4240, 0.5444, 0.0000, 0.0000, 0.2761,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2337, 0.4569, 0.3417, 0.0000, 0.0000, 0.2286,\n",
       "           0.0000, 0.0000]]], grad_fn=<ReluBackward0>))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(t), relu(linear(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c88bfd5b-2ad3-4d3e-bf01-05c1d56c3a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5116, -0.5753,  0.1465,  0.1994,  0.5395, -0.0600, -0.0829,\n",
       "            0.0278, -0.5628, -0.5003],\n",
       "          [-0.5552, -1.0051,  0.1534,  0.2507,  0.2597, -0.3272, -0.2982,\n",
       "           -0.0311, -0.2502, -0.2841],\n",
       "          [-0.5205, -0.9500,  0.2155,  0.4156,  0.2760, -0.3582, -0.4242,\n",
       "            0.1563, -0.2666, -0.1669]],\n",
       " \n",
       "         [[-0.5201, -0.6877,  0.1545,  0.2296,  0.4644, -0.1363, -0.1543,\n",
       "            0.0301, -0.4787, -0.4296],\n",
       "          [-0.4676, -0.5273,  0.2303,  0.4240,  0.5444, -0.1179, -0.2653,\n",
       "            0.2761, -0.5658, -0.3297],\n",
       "          [-0.5000, -0.8396,  0.2337,  0.4569,  0.3417, -0.3102, -0.4177,\n",
       "            0.2286, -0.3394, -0.1764]]], grad_fn=<ViewBackward0>),\n",
       " tensor([[[0.0643, 0.0603, 0.1242, 0.1309, 0.1840, 0.1010, 0.0987, 0.1103,\n",
       "           0.0611, 0.0650],\n",
       "          [0.0663, 0.0423, 0.1348, 0.1485, 0.1499, 0.0833, 0.0858, 0.1121,\n",
       "           0.0900, 0.0870],\n",
       "          [0.0647, 0.0421, 0.1350, 0.1649, 0.1434, 0.0761, 0.0712, 0.1272,\n",
       "           0.0834, 0.0921]],\n",
       " \n",
       "         [[0.0650, 0.0550, 0.1276, 0.1376, 0.1740, 0.0954, 0.0937, 0.1127,\n",
       "           0.0678, 0.0712],\n",
       "          [0.0627, 0.0591, 0.1260, 0.1530, 0.1726, 0.0890, 0.0768, 0.1320,\n",
       "           0.0569, 0.0720],\n",
       "          [0.0639, 0.0455, 0.1332, 0.1664, 0.1483, 0.0773, 0.0694, 0.1325,\n",
       "           0.0751, 0.0884]]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax - функция активации которая нормализует значения в векторе так что они лежат в интервале от 0-1 и суммируются в 1\n",
    "linear(t), F.softmax(linear(t), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4fc17f33-013f-4b62-b5b6-fc9a6ed1a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNorm нормализует значения в векторах так что среднее равно 0 а стандартное отклонение 1\n",
    "ln = nn.LayerNorm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "38afd361-193b-447f-a8a7-7757398ef775",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0d63588b-636f-4536-b5b5-25c9300bcc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1457, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3879, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.mean(), out.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2a9c9ead-afd7-4722-af4b-862765d01f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.9473e-09, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0084, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln(out).mean(), ln(out).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ff506604-d2cd-4201-a0ce-414ae43c7891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5116, -0.5753,  0.1465,  0.1994,  0.5395, -0.0600, -0.0829,\n",
       "            0.0278, -0.5628, -0.5003],\n",
       "          [-0.5552, -1.0051,  0.1534,  0.2507,  0.2597, -0.3272, -0.2982,\n",
       "           -0.0311, -0.2502, -0.2841],\n",
       "          [-0.5205, -0.9500,  0.2155,  0.4156,  0.2760, -0.3582, -0.4242,\n",
       "            0.1563, -0.2666, -0.1669]],\n",
       " \n",
       "         [[-0.5201, -0.6877,  0.1545,  0.2296,  0.4644, -0.1363, -0.1543,\n",
       "            0.0301, -0.4787, -0.4296],\n",
       "          [-0.4676, -0.5273,  0.2303,  0.4240,  0.5444, -0.1179, -0.2653,\n",
       "            0.2761, -0.5658, -0.3297],\n",
       "          [-0.5000, -0.8396,  0.2337,  0.4569,  0.3417, -0.3102, -0.4177,\n",
       "            0.2286, -0.3394, -0.1764]]], grad_fn=<ViewBackward0>),\n",
       " tensor([[[-1.0233, -1.1978,  0.7791,  0.9240,  1.8556,  0.2135,  0.1508,\n",
       "            0.4542, -1.1635, -0.9925],\n",
       "          [-0.9336, -2.1461,  0.9759,  1.2380,  1.2624, -0.3192, -0.2410,\n",
       "            0.4787, -0.1118, -0.2032],\n",
       "          [-0.8853, -1.9469,  0.9337,  1.4283,  1.0833, -0.4841, -0.6473,\n",
       "            0.7875, -0.2578, -0.0113]],\n",
       " \n",
       "         [[-1.0351, -1.5074,  0.8659,  1.0777,  1.7393,  0.0465, -0.0042,\n",
       "            0.5154, -0.9183, -0.7799],\n",
       "          [-0.9843, -1.1357,  0.7873,  1.2793,  1.5849, -0.0964, -0.4708,\n",
       "            0.9038, -1.2337, -0.6343],\n",
       "          [-0.9111, -1.7522,  0.9065,  1.4594,  1.1741, -0.4410, -0.7071,\n",
       "            0.8939, -0.5131, -0.1094]]], grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, ln(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "83ffa21a-8b9e-4cf2-a698-c73a9511a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout зануляет случайные значения в векторах\n",
    "# параметр задает вероятность зануления\n",
    "dropout = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "325e0f4f-46e5-4333-bc48-428126f608d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0232, -1.1506,  0.0000,  0.0000,  0.0000, -0.1201, -0.1659,\n",
       "           0.0000, -1.1255, -1.0007],\n",
       "         [-0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000],\n",
       "         [-1.0410, -0.0000,  0.4310,  0.8312,  0.5521, -0.7164, -0.0000,\n",
       "           0.0000, -0.5332, -0.3338]],\n",
       "\n",
       "        [[-1.0403, -1.3754,  0.3089,  0.0000,  0.9288, -0.0000, -0.0000,\n",
       "           0.0602, -0.0000, -0.8591],\n",
       "         [-0.0000, -0.0000,  0.0000,  0.8481,  0.0000, -0.0000, -0.0000,\n",
       "           0.5523, -1.1317, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.6205, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(linear(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4737440d-0499-4612-997d-78eafaceac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential позволяет соединить несколько слоев в одно последовательное преобразование\n",
    "net = nn.Sequential(\n",
    "            nn.Linear(2, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2),\n",
    "            nn.Dropout(0.5),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "46d58324-7417-4e2e-aa8b-e23f9cccee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cb6dbc45-cec3-48c2-893c-5b09c12425df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f848c5b5-ece6-4b27-be37-47fb2faa2b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2389,  0.0000],\n",
       "         [-0.0000,  0.8493],\n",
       "         [-0.4012,  0.0000]],\n",
       "\n",
       "        [[-0.0000,  0.7760],\n",
       "         [-0.2761,  0.8136],\n",
       "         [-0.3664,  0.8802]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ce406-6acf-48de-8b7e-4918c6d16722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16b10878-286a-4294-8546-54b822d3a66d",
   "metadata": {},
   "source": [
    "## GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8f9ad-f7f5-41f3-acc9-234a2e509b23",
   "metadata": {},
   "source": [
    "Теперь давайте разберем код Karpath в котором он собирает GPT и обучим ее на наших данных.\n",
    "\n",
    "\n",
    "GPT это трансформерная модель. Она реализована также как это описано в статье Attention is all you need, за исключением того, что в GPT есть только decoder (правый столб). Статья AIAYN изначально про машинный перевод и поэтому в ней используется encoder-decoder архитектура. \n",
    "Декодером GPT делает то, что в ней используется causual attention, где каждый токен общается только с предыдущими. В encoder все токены взаимодействуют со всеми.\n",
    "Также небольшое отличие состоит в порядке применения layerNorm (сейчас его перенесли до MHA и до FF)\n",
    "\n",
    "\n",
    "\n",
    "![](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0235fd2f-26f4-47ff-b95e-eddf6a4593b0_782x1152.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbf47d-54b7-402d-acab-f39f9ff46d42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92250369-8e18-4fea-87bd-002441a67ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "block_size = MAX_LEN # what is the maximum context length for predictions?\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_embd = 64 # размерность эмбеддингов и векторов внутри трансформера\n",
    "#ffn_hid_dim = n_embd * 4\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abdaaf64-9e4f-4b17-bd09-14e822b67546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        if mask is not None:\n",
    "            wei.masked_fill(~mask.unsqueeze(1), float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        out = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # print(inp)\n",
    "        x, mask = inp\n",
    "        x = x + self.sa(self.ln1(x), mask)\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return (x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1bedbe1-9c19-420f-aa3b-a801ef3b9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None, mask=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x, mask = self.blocks((x, mask)) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets, ignore_index=PAD_IDX)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens, stop_token):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)# (B, 1)\n",
    "            if idx_next == stop_token:\n",
    "                break\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d41a0d8-9c0a-406c-bcf3-75a45227c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.073392 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70cae839-8596-4316-9018-a9918cf95aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d46ac9a-80b8-41fe-91ac-833010507844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f9a29-e78a-4d22-9354-985c48748e1f",
   "metadata": {},
   "source": [
    "Код обучения просто передает в модель батчи из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d011245-1be5-4169-abff-f6b4690cb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, print_every=10):\n",
    "    epoch_loss = []\n",
    "    model.train()  \n",
    "\n",
    "    for i, (xs, ys, mask) in enumerate(iterator):\n",
    "        optimizer.zero_grad()   \n",
    "        logits, loss = model(xs.to(device), ys.to(device), mask.to('cuda')) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(f'Loss: {torch.Tensor(epoch_loss).mean(-1)}')\n",
    "        \n",
    "    return torch.Tensor(epoch_loss).mean(-1)\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    epoch_loss = []\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for xs, ys, mask in iterator:   \n",
    "            logits, loss = model(xs.to(device), ys.to(device), mask.to('cuda'))     \n",
    "            epoch_loss.append(loss.item())  \n",
    "            \n",
    "    return torch.Tensor(epoch_loss).mean(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b45064-e0a7-4c89-80a8-19cc86ed76b2",
   "metadata": {},
   "source": [
    "При обучении после каждой эпохи генерируется текст чтобы видеть прогресс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2e1de-b36d-4a18-96a6-2f0f371995ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loss: 8.453104019165039\n",
      "Loss: 8.051098823547363\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "for i in range(30):\n",
    "    print(i)\n",
    "    train_losses.append(train(model, training_generator, optimizer, 100))\n",
    "    eval_loss = evaluate(model, val_generator)\n",
    "    print('Eval - ', eval_loss.item())\n",
    "    eval_losses.append(eval_loss)\n",
    "    pred = model.generate(torch.LongTensor([[tokenizer.token_to_id('[BOS]')]]).to('cuda'), 200, tokenizer.token_to_id('[EOS]'))\n",
    "    print(tokenizer.decode_batch(pred.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba714072-1d7d-4c3b-a770-209da0a5373a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
