{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13efba76",
   "metadata": {},
   "source": [
    "# –î–∏—Å–∫–ª–µ–π–º–µ—Ä\n",
    "–≠—Ç—É —Ç–µ—Ç—Ä–∞–¥–∫—É –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –≤ –∫–æ–ª–∞–±–µ –∏–ª–∏ –≤ vast.ai. –ù–µ –º—É—á–∞—Ç–µ—Å—å —Å —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ —Å –æ–±—É—á–µ–Ω–∏–µ–º –Ω–∞ cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d650e9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tokenizers matplotlib scikit-learn\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126 -U\n",
    "# !pip install torchtune torchao\n",
    "# !pip install --upgrade 'optree>=0.13.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d338ab5-79fd-43f3-9c8d-ebb6a67f7f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b03d3b-5816-4830-b69e-f3ea4a826e17",
   "metadata": {},
   "source": [
    "–ü–æ–º–∏–º–æ —Å–∞–º–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –¥–∞–≤–∞–π—Ç–µ —Ç–∞–∫–∂–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–µ—Ä–≤–∏—Å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ W & B (weights and biases). \n",
    "–î–æ —ç—Ç–æ–≥–æ –º—ã –æ–±—Ö–æ–¥–∏–ª–∏—Å—å –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–æ–º –º–µ—Ç—Ä–∏–∫ –≤ —Ç–µ—Ç—Ä–∞–¥–∫–µ, –Ω–æ —ç—Ç–æ –Ω–µ —Å–µ—Ä—å–µ–∑–Ω–æ. –¢–∞–∫ –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –ø–æ—Ç–µ—Ä—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ—à–ª—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ —Å–¥–µ–ª–∞—Ç—å –æ—à–∏–±–∫—É –ø—Ä–∏ –ø–µ—Ä–µ–±–æ—Ä–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "W&B –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–∞–∫–æ–π —Å–µ—Ä–≤–∏—Å, –Ω–æ –æ–Ω –±–µ—Å–ø–ª–∞—Ç–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é, –ø–æ—ç—Ç–æ–º—É –ø–æ–ø—Ä–æ–±—É–µ–º –µ–≥–æ. \n",
    "–ß—Ç–æ–±—ã –∑–∞–ª–æ–≥–∏–Ω–∏—Ç—å—Å—è –≤ w&b –≤ —Ç–µ—Ç—Ä–∞–¥–∫–µ, –≤–∞–º –Ω—É–∂–Ω–æ –ø–æ–π—Ç–∏ –Ω–∞ —Å–∞–π—Ç wandb.ai –∏ –∑–∞–ª–æ–≥–∏–Ω–∏—Ç—å—Å—è —Ç–∞–º, –∞ –ø–æ—Ç–æ–º —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –∏ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á –≤ —è—á–µ–π–∫—É –Ω–∏–∂–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf913f78-c71a-4dcf-abf2-a0cc12daeef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login YOUR_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931eb4c6-eb25-48ff-b363-ff234da53e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d23c5-55a9-493c-a1e8-8798f0969bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035afaed-45ca-4dee-a200-67357b0f4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (run)\n",
    "run = wandb.init(\n",
    "    project=\"course\",\n",
    "    name=\"test_run\",\n",
    "    # –≤ –∫–æ–Ω—Ñ–∏–≥ –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å –≤—Å–µ —á—Ç–æ —É–≥–æ–¥–Ω–æ\n",
    "    config={\n",
    "        \"test\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a48668-cb5d-4475-955a-16e61d2bb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¥–∞–ª–µ–µ –º–æ–∂–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ (–æ–¥–∏–Ω –∏–ª–∏ –º–Ω–æ–≥–æ —Ä–∞–∑)\n",
    "wandb.log({\"accuracy\": 1.0, \"loss\": 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "505ef7f6-0bb9-41ad-9903-d45bfd7804ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ç–∞–∫ –º–æ–∂–Ω–æ –∑–∞–∫–æ–Ω—á–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384bd5c",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69baacc",
   "metadata": {},
   "source": [
    "–≠—Ç–æ —É–∂–µ 3-–π —Å–µ–º–∏–Ω–∞—Ä –ø—Ä–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –∏ —Ç–æ–ª—å–∫–æ —Å–µ–π—á–∞—Å –º—ã –ø–æ–ø—Ä–æ–±—É–µ–º —Å–¥–µ–ª–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –∏ –±—ã–ª–∞ –æ–ø–∏—Å–∞–Ω–∞ –≤ Attention is all you need. –ú—ã —É–∂–µ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ –Ω–∞ BERT (encoder only transformer) –∏ GPT (decoder only transformer), –Ω–æ –æ–Ω–∏ –≤—ã—à–ª–∏ –ø–æ–∑–∂–µ. –í Attention is all you need –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å Encoder-Decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è sequence-to-sequence –∑–∞–¥–∞—á. –î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å —Ç–∞–∫—É—é –º–æ–¥–µ–ª—å. \n",
    "–í —ç—Ç–æ—Ç –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≥–æ—Ç–æ–≤—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ –∫–ª–∞—Å—Å—ã –≤ torch, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–±–æ–ª—å—à–µ –≥–æ—Ç–æ–≤–æ–≥–æ –∏ –Ω–µ –ø–∏—Å–∞—Ç—å –≤—Å–µ —Å –Ω—É–ª—è –∫–∞–∂–¥—ã–π —Ä–∞–∑."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c794a6",
   "metadata": {},
   "source": [
    "–ë—É–¥–µ–º –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –∑–∞–¥–∞—á–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å–∞–º–∞—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞ –≤ NLP). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "947b3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers import decoders\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from torchtune.modules import RotaryPositionalEmbeddings\n",
    "from torch.nn import Transformer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "307b759c-fee4-41e8-8b90-0355911abd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
    "# !wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
    "# !wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
    "# !wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415f5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å \\xa0 –≤–º–µ—Å—Ç–æ –ø—Ä–æ–±–µ–ª–æ–≤, –æ–Ω –º–æ–∂–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º\n",
    "text = open('opus.en-ru-train.ru').read().replace('\\xa0', ' ')\n",
    "f = open('opus.en-ru-train.ru', 'w')\n",
    "f.write(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d83aa",
   "metadata": {},
   "source": [
    "–î–∞–Ω–Ω—ã–µ –≤–∑—è—Ç—ã –≤–æ—Ç –æ—Ç—Å—é–¥–∞ - https://opus.nlpl.eu/opus-100.php (—Ä–∞–∑–¥–µ–ª —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e110ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sents = open('opus.en-ru-train.en').read().lower().splitlines()\n",
    "ru_sents = open('opus.en-ru-train.ru').read().lower().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009c96e",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eb9b498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('so what are you thinking?', '–Ω—É –∏ —á—Ç–æ —Ç—ã –¥—É–º–∞–µ—à—å?')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sents[-1], ru_sents[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39921c4",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –æ–±—ã—á–Ω–æ –Ω–∞–º –Ω—É–∂–µ–Ω —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, –∞ —Ç–æ—á–Ω–µ–µ –¥–∞–∂–µ 2, —Ç.–∫. —É –Ω–∞—Å –¥–≤–∞ –∫–æ—Ä–ø—É—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b79b4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = Tokenizer(BPE())\n",
    "tokenizer_en.pre_tokenizer = Whitespace()\n",
    "trainer_en = BpeTrainer(special_tokens=[\"[PAD]\"], end_of_word_suffix='</w>')\n",
    "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en)\n",
    "\n",
    "tokenizer_ru = Tokenizer(BPE())\n",
    "tokenizer_ru.pre_tokenizer = Whitespace()\n",
    "trainer_ru = BpeTrainer(special_tokens=[\"[PAD]\", \"[BOS]\", \"[EOS]\"], end_of_word_suffix='</w>')\n",
    "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009e0125-67df-4a3e-ab9e-26d1f78183e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en.decoder = decoders.BPEDecoder()\n",
    "tokenizer_ru.decoder = decoders.BPEDecoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48780b24",
   "metadata": {},
   "source": [
    "### –í–ê–ñ–ù–û!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b56d3b",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä - —ç—Ç–æ –Ω–µ–æ—Ç—ä–µ–º–ª–∏–º–∞—è —á–∞—Å—Ç—å –º–æ–¥–µ–ª–∏, –ø–æ—ç—Ç–æ–º—É –Ω–µ –∑–∞–±—ã–≤–∞–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤–º–µ—Å—Ç–µ —Å –º–æ–¥–µ–ª—å—é. –ï—Å–ª–∏ –≤—ã –∑–∞–±—É–¥–µ—Ç–µ –ø—Ä–æ —ç—Ç–æ –∏ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, —Ç–æ –∏–Ω–¥–µ–∫—Å—ã —Ç–æ–∫–µ–Ω–æ–≤ —Ä–∞–∑–æ–π–¥—É—Ç—Å—è –∏ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dd90665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ä–∞—Å–∫–æ–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "# –∞ –ø–æ—Ç–æ–º —Å–Ω–æ–≤–∞ –∑–∞–∫–æ–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —á—Ç–æ–±—ã –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã\n",
    "tokenizer_en.save('tokenizer_en')\n",
    "tokenizer_ru.save('tokenizer_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e0f7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
    "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fecf3",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç –≤ –∏–Ω–¥–µ–∫—Å—ã –≤–æ—Ç —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º. –í –Ω–∞—á–∞–ª–æ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω '[CLS]', –∞ –≤ –∫–æ–Ω–µ—Ü '[SEP]'. –ï—Å–ª–∏ –≤—Å–ø–æ–º–Ω–∏—Ç–µ –∑–∞–Ω—è—Ç–∏–µ –ø–æ —è–∑—ã–∫–æ–≤–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é, —Ç–æ —Ç–∞–º –º—ã –¥–æ–±–∞–≤–ª—è–ª–∏ \"\\<start>\" –∏ \"\\<end>\" - cls –∏ sep –ø–æ —Å—É—Ç–∏ —Ç–æ–∂–µ —Å–∞–º–æ–µ. –í—ã –ø–æ–π–º–µ—Ç–µ –ø–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ cls –∏ sep, –∞ –Ω–µ start –∏ end, –µ—Å–ª–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –ø–æ—Ä–∞–∑–±–∏—Ä–∞–µ—Ç–µ—Å—å —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc003758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, tokenizer, max_len, encoder=False):\n",
    "    if encoder:\n",
    "        return tokenizer.encode(text).ids[:max_len]\n",
    "    else:\n",
    "        return [tokenizer.token_to_id('[BOS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[EOS]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96920fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –≤–∞–∂–Ω–æ —Å–ª–µ–¥–∏—Ç—å —á—Ç–æ–±—ã –∏–Ω–¥–µ–∫—Å –ø–∞–¥–¥–∏–Ω–≥–∞ —Å–æ–≤–ø–∞–¥–∞–ª –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–µ —Å value –≤ pad_sequences\n",
    "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cc0a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –æ–≥—Ä–∞–Ω–∏—á–∏–º—Å—è –¥–ª–∏–Ω–Ω–æ–π –≤ 30 –∏ 35 (—Ä–∞–∑–Ω—ã–µ —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –≤ seq2seq –Ω–µ –Ω—É–∂–Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è –¥–ª–∏–Ω–∞)\n",
    "max_len_en, max_len_ru = 47, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2dae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68091524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a52c2902-54fe-46d0-8661-667dda80d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOMPUTE = False\n",
    "if os.path.exists('X_en.pkl') and not RECOMPUTE:\n",
    "    X_en = pickle.load(open('X_en.pkl', 'rb'))\n",
    "    X_ru = pickle.load(open('X_ru.pkl', 'rb'))\n",
    "\n",
    "else:\n",
    "    X_en = [encode(t, tokenizer_en, max_len_en, encoder=True) for t in en_sents]\n",
    "    X_ru = [encode(t, tokenizer_ru, max_len_ru) for t in ru_sents]\n",
    "    pickle.dump(X_en, open('X_en.pkl', 'wb'))\n",
    "    pickle.dump(X_ru, open('X_ru.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cc48199-c1d6-4217-898a-c12a244779c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1000000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –º–∏–ª–ª–∏–æ–Ω –ø—Ä–∏–º–µ—Ä–æ–≤ \n",
    "len(X_en), len(X_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52abe22b-35b2-4153-aac0-048528a1068c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4799, 1753, 2568, 1841, 1671, 2633, 5473, 2657], [1799]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_en[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655a4ea",
   "metadata": {},
   "source": [
    "–ü–∞–¥–¥–∏–Ω–≥ –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Å–∞ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞. –ï—â–µ –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Ç—É—Ç –Ω–µ —Å—Ç–æ–∏—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä batch_first=True –∫–∞–∫ —Ä–∞–Ω—å—à–µ\n",
    "\n",
    "–í —Ç–æ—Ä—á–µ –ø—Ä–∏–Ω—è—Ç–æ, —á—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞ –∏–¥–µ—Ç –≤ –∫–æ–Ω—Ü–µ –∏ –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞ —Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–º —Ä–∞—Å—á–∏—Ç–∞–Ω –Ω–∞ —ç—Ç–æ. –ö–æ–Ω–µ—á–Ω–æ –º–æ–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å —Å–∞–º –∫–æ–¥ –º–æ–¥–µ–ª–∏, –Ω–æ —ç—Ç–æ —Å–ª–æ–∂–Ω–µ–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–Ω–∑–æ—Ä —Å –¥–∞–Ω–Ω—ã–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7634853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, texts_en, texts_ru):\n",
    "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
    "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, batch_first=True, padding_value=PAD_IDX)\n",
    "        \n",
    "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
    "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "        self.length = len(texts_en)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        ids_en = self.texts_en[index]\n",
    "        ids_ru = self.texts_ru[index]\n",
    "\n",
    "        return ids_en, ids_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec889a8d",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c9eaf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_train, X_en_valid, X_ru_train, X_ru_valid = train_test_split(X_en, X_ru, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb0e70",
   "metadata": {},
   "source": [
    "# –ö–æ–¥ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞\n",
    "\n",
    "–°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º `nn.MultiheadAttention`, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, —á—Ç–æ–±—ã —Å–æ–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –Ω—É–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –≤—Å—é –ª–æ–≥–∏–∫—É –≤–æ–∫—Ä—É–≥ (–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, –¥—Ä–æ–ø–∞—É—Ç—ã –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –±–ª–æ–∫–æ–≤). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc00b06-2ae0-4880-a270-e29cc2ba3ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aca04f07-728d-41e9-8747-add7dfc84cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
    "        src = self.norm1(src + self.dropout(src2))\n",
    "\n",
    "        src2 = self.ff(src)\n",
    "        src = self.norm2(src + self.dropout(src2))\n",
    "\n",
    "        return src\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        tgt2, _ = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask)\n",
    "        tgt = self.norm1(tgt + self.dropout(tgt2))\n",
    "\n",
    "        tgt2, _ = self.cross_attn(tgt, memory, memory, key_padding_mask=memory_key_padding_mask)\n",
    "        tgt = self.norm2(tgt + self.dropout(tgt2))\n",
    "\n",
    "        tgt2 = self.ff(tgt)\n",
    "        tgt = self.norm3(tgt + self.dropout(tgt2))\n",
    "\n",
    "        return tgt\n",
    "\n",
    "\n",
    "class EncoderDecoderTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size_enc, vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.embedding_enc = nn.Embedding(vocab_size_enc, embed_dim)\n",
    "        self.embedding_dec = nn.Embedding(vocab_size_dec, embed_dim)\n",
    "\n",
    "        self.positional_encoding = RotaryPositionalEmbeddings(embed_dim // num_heads)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size_dec)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        src_embedded = self.embedding_enc(src)\n",
    "        B, S, E = src_embedded.shape\n",
    "        src_embedded = self.positional_encoding(src_embedded.view(B, S, self.num_heads, E // self.num_heads)).view(B, S, E)\n",
    "\n",
    "        tgt_embedded = self.embedding_dec(tgt)\n",
    "        B, T, E = tgt_embedded.shape\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded.view(B, T, self.num_heads, E // self.num_heads)).view(B, T, E)\n",
    "\n",
    "        memory = src_embedded\n",
    "        for layer in self.encoder_layers:\n",
    "            memory = layer(memory, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        tgt_mask = (~torch.tril(torch.ones((T, T), dtype=torch.bool))).to(tgt.device)\n",
    "\n",
    "        output = tgt_embedded\n",
    "        for layer in self.decoder_layers:\n",
    "            output = layer(\n",
    "                output,\n",
    "                memory,\n",
    "                tgt_mask=tgt_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_key_padding_mask\n",
    "            )\n",
    "\n",
    "        output = self.output_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c804881-7189-4ad4-9876-b67463689dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_enc = tokenizer_en.get_vocab_size()\n",
    "vocab_size_dec = tokenizer_ru.get_vocab_size()\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "ff_dim = 64*4\n",
    "num_layers = 4\n",
    "batch_size = 200\n",
    "\n",
    "model = EncoderDecoderTransformer(vocab_size_enc,vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "119a373a-fdc3-4661-9199-a5ed007edd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(X_en_train, X_ru_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, )\n",
    "\n",
    "valid_set = Dataset(X_en_valid, X_ru_valid)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e3506-b50f-4ff0-807c-c86629687c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "542f5264-a991-4fe6-93a8-6f3292b3f762",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –ø–æ —à–∞–≥–∞–º —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a68518fc-99f1-4295-9cb5-52dbb9255215",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_en, texts_ru = training_set[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80c1c5c4-d10b-43f3-8a63-f98a4e1fa110",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_en = texts_en#.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "texts_ru = texts_ru#.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "texts_ru_input = texts_ru[:,:-1]\n",
    "src_padding_mask = (texts_en == PAD_IDX)#.to(DEVICE)\n",
    "tgt_padding_mask = (texts_ru_input == PAD_IDX)#.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97f1a32e-552f-4aa2-bb59-a510971fa935",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model.embedding_enc(texts_en)\n",
    "B,S,E = o.shape\n",
    "pos_o = model.positional_encoding(o.view(B, S, num_heads, E//num_heads)).view(B,S,E)\n",
    "\n",
    "od = model.embedding_dec(texts_ru_input)\n",
    "B,S,E = od.shape\n",
    "pos_od = model.positional_encoding(od.view(B, S, num_heads, E//num_heads)).view(B,S,E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43011071-9608-460e-b83c-df3e9e77f941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 47, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22be0867-4080-4dfd-b53a-10fe3ca3f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = o\n",
    "for layer in model.encoder_layers:\n",
    "    memory = layer(memory, src_key_padding_mask=src_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef591428-1c40-454d-9fb2-f6ccb183d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 47, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9cf6a3-8f6b-4a11-b748-b7d5c7990854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "192695de-3b71-4983-80ca-c2329ea16658",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask = ~torch.tril(torch.ones((S, S), dtype=torch.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96f343eb-3486-463e-aefa-e211ada70eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = od\n",
    "for layer in model.decoder_layers:\n",
    "    output = layer(\n",
    "        output,\n",
    "        memory,\n",
    "        tgt_mask=tgt_mask,\n",
    "        tgt_key_padding_mask=tgt_padding_mask,\n",
    "        memory_key_padding_mask=src_padding_mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97bfe455-ff87-424e-a4be-786e74f663c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = model.output_layer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f55b50d-96cc-4447-8eda-b4a673e475f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,S,C = co.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f3f4f33-b678-4f5c-846d-f3581616d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a69aa50-168c-44f5-a787-46c80af7fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ru_out = texts_ru[:, 1:]\n",
    "loss = loss_fn(co.reshape(B*S, C), texts_ru_out.reshape(B*S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eae26e13-c79d-47bb-b73a-0c3e06f7b005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.4501, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2b892a1-072b-4592-8298-2f9fc6d25ebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1211, -1.1054,  0.0365,  ..., -0.7738,  0.2809, -0.0083],\n",
       "         [-0.8993, -0.3074,  0.6926,  ...,  0.4524, -0.2804,  0.6690],\n",
       "         [-0.2734, -0.4618,  0.7733,  ..., -0.2761,  0.1719,  0.2239],\n",
       "         ...,\n",
       "         [ 0.2154, -0.7626, -0.3399,  ...,  0.2307, -0.1454,  0.0309],\n",
       "         [ 0.5153,  1.6255,  0.0403,  ...,  0.5083, -0.0844,  0.3925],\n",
       "         [ 0.5018, -1.1236, -0.8984,  ...,  0.3347,  0.1549, -1.6311]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(texts_en, texts_ru_input, src_padding_mask, tgt_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc6e21-e14e-4e17-bddc-2f372f4850b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dedf9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, iterator, optimizer, criterion, run, print_every=500):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    ac = []\n",
    "    \n",
    "    model.train()  \n",
    "\n",
    "    for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "        texts_en = texts_en.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "        texts_ru = texts_ru.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "        texts_ru_input = texts_ru[:,:-1].to(DEVICE)\n",
    "        texts_ru_out = texts_ru[:, 1:].to(DEVICE)\n",
    "        src_padding_mask = (texts_en == PAD_IDX).to(DEVICE)\n",
    "        tgt_padding_mask = (texts_ru_input == PAD_IDX).to(DEVICE)\n",
    "\n",
    "        \n",
    "        logits = model(texts_en, texts_ru_input, src_padding_mask, tgt_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "        B,S,C = logits.shape\n",
    "        loss = loss_fn(logits.reshape(B*S, C), texts_ru_out.reshape(B*S))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(f'Loss: {np.mean(epoch_loss)};')\n",
    "        run.log({\"loss\": loss.item()})\n",
    "    \n",
    "    run.log({\"epoch_loss\": np.mean(epoch_loss)})\n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, run):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_f1 = []\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "            texts_en = texts_en.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "            texts_ru = texts_ru.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "            texts_ru_input = texts_ru[:,:-1].to(DEVICE)\n",
    "            texts_ru_out = texts_ru[:, 1:].to(DEVICE)\n",
    "            src_padding_mask = (texts_en == PAD_IDX).to(DEVICE)\n",
    "            tgt_padding_mask = (texts_ru_input == PAD_IDX).to(DEVICE)\n",
    "\n",
    "            logits = model(texts_en, texts_ru_input, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "            B,S,C = logits.shape\n",
    "            loss = loss_fn(logits.reshape(B*S, C), texts_ru_out.reshape(B*S))\n",
    "            epoch_loss.append(loss.item())\n",
    "            run.log({\"val_loss\": loss.item()})\n",
    "    run.log({\"epoch_val_loss\": np.mean(epoch_loss)})\n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "@torch.no_grad\n",
    "def translate(text):\n",
    "\n",
    "\n",
    "    input_ids = tokenizer_en.encode(text).ids[:max_len_en]\n",
    "    output_ids = [tokenizer_ru.token_to_id('[BOS]')]\n",
    "    \n",
    "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(input_ids)], batch_first=True).to(DEVICE)\n",
    "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
    "    \n",
    "    src_padding_mask = (input_ids_pad == PAD_IDX).to(DEVICE)\n",
    "    tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
    "    \n",
    "    logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "    pred = logits.argmax(2).item()\n",
    "\n",
    "    while pred not in [tokenizer_ru.token_to_id('[EOS]'), tokenizer_ru.token_to_id('[PAD]')] and len(output_ids) < 100:\n",
    "        output_ids.append(pred)\n",
    "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
    "        tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
    "\n",
    "        logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
    "        pred = logits.argmax(2).view(-1)[-1].item()\n",
    "\n",
    "    return tokenizer_ru.decoder.decode([tokenizer_ru.id_to_token(i) for i in output_ids[1:]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc7975-b4b7-4f9d-8df8-d65afe9e7587",
   "metadata": {},
   "source": [
    "#### –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b697183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4ea391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a33716e-6a7e-46fa-a733-3d73e244ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.256944 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07f5b3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250313_143204-m742v1fu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/manefedov26/course/runs/m742v1fu' target=\"_blank\">encoder_decoder_transformer_mha</a></strong> to <a href='https://wandb.ai/manefedov26/course' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/manefedov26/course' target=\"_blank\">https://wandb.ai/manefedov26/course</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/manefedov26/course/runs/m742v1fu' target=\"_blank\">https://wandb.ai/manefedov26/course/runs/m742v1fu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "run = wandb.init(\n",
    "    project=\"course\",\n",
    "    name=\"encoder_decoder_transformer_mha\",\n",
    "    # –≤ –∫–æ–Ω—Ñ–∏–≥ –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å –≤—Å–µ —á—Ç–æ —É–≥–æ–¥–Ω–æ\n",
    "    config={\n",
    "        \"vocab_size_enc\": vocab_size_enc,\n",
    "        \"vocab_size_dec\": vocab_size_dec,\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"ff_dim\": ff_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_params_M\": sum(p.numel() for p in model.parameters())/1e6\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2070ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–Ω–µ–ª–Çindex –ø—É–Ω–∫—Ç—ã ‚îê –£–∫—Ä–∞–ó–∞—è–≤–ª–µ–Ω–∏–µ „Éü–ñ–µ–ª–∞—Å–µ–Ω—å–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–π –≤–∑–∞–∏–º–°–µ—Ä–±–∏—è –û–±—Å—É–∂–¥–µ–Ω–∏–µ –£–∫—Ä–∞—Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤—ã—Ö–æ–¥—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏ —Å—Ç–∏–ª ƒª —Ä–æ–≤ —ú–Ω –≤–æ–ª—å‚Ä∞‚îê –£–∫—Ä–∞–ü–µ–∫–∏–Ω—Å–∫–æ–π –¢–∞–πÔÄ™–í–æ–∑–≤—Ä–∞—â–∞—Å–æ–±—Ä–∞–Ω–∏–π —É–±–µ–¥–£–∫—Ä–∞Œ© –ü–†–ï–î–°–ï–î–ê–¢—Å–æ–æ–±—â–∏—Ç—å –£–∫—Ä–∞–∫–∞–∫—É—é –æ–∫–µ–Ω–∞–ø–∞–¥–µ–Ω–∏–µ —É–≥–ª—É –°–µ—Ä–±–∏—è –±–æ–∏—Ç—Å—è –ø—Ä–æ–µ–∫—Ç–∏–≤—ã—Ö–æ–¥–≤—ã—Ä–∞–±–æ—Ç–∫–∏ –Ç–∫–æ–Ω—Ñ–ª–∏–∫—Ç –∫–∞—Å–∞—é—â—É—é—Å—è –æ–ø—É–±–ª–∏–∫–æ—â–∏—Ö—Å—è –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–≥–æ ium –≤–µ–¥—É—â–∏–π –î–µ –¢–æ–±–∏ / —Å–æ—Å–ª–∞—Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ–∫–∞–∑–∞—Ç—å—Å—è our–∑–∞–≥—Ä—è–∑–Ω–∏—Ç–µ–ª–µ–π –ü–æ–º–æ—â–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—É–Ω–∫—Ç—ã –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –î–æ—Å—Ç–∏–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–∫–µ–ü–∞–Ω–∞–º–∞ –≤–∏–∑–∏—Ç–∞ „ÇÆ—Å–µ–∫—Ä–µ—Ç–∞—Ä–∏–∞—Ç–∞ –∫—Ä—É–≥–æ–º „ÇÆ–†–æ—Å—Å —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ò—Å–ª–∞–Ω–¥–∏—è —Å–æ–æ–±—â–∏—Ç—å –ø—Ä–æ–≤–æ—Ü–∏—Å—ç–∫–æ–Ω–æ–º–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –û–í–û–†–æ—Å—Å –¥–æ—Å—Ç—É–ø–µ –∏–∑–º–µ–Ω–µ–Ω–∏—é –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–∏ ado –∫–æ–≤–∞—è √¥ —Å–µ–≤–µ—Ä–Ω–æ–π „Éí–æ–∫–µ–ü–∞–ª–µ—Å—Ç–∏–Ω—ã Âºè—É–±–µ–¥\n",
      "–õ—ç–Ω–≥—É–∞ –æ—Ç–æ–º—Å—Ç–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –ª–µ–Ω—å–¥–æ–ø—Ä–∞—à–∏–ü–† —Å–∞–Ω–∫–í—Å–µ–º–∏—Ä–Ω—ã–º –æ—Å–∞–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ–≥—Ä–∞–Ω–∏–±–ª–∞–≥–æ–¥–∞—Äre TexÌÄÄ–º–∏–ª—å ‚â° –ø–æ—Å—Ç—É–ø–∏–ª —Ä–∞–π–±–ª–∞–≥–æ–¥–∞—Ä–ø—É–Ω–∫—Ç—ã –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞–µ–º—ã–µ —á–∞—Å—Ç–µ–π —Ç—É—Ä–Ω–∏—Ä–∞–∑—É –∏—Å–ø–æ–ª—å–∑—É—é—Ç tis—Å—ë–Ω–µ–¥–æ—Å—É–¥–æ—Ö–æ–¥–ø–æ–∫—Ä—ã–∫–ª–∞—Å—Å–∏–°–µ–∫—Ü–∏—è af–ª–∏—Ü–∞ –§–∞–∫—É–ª—å—Ç–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Å–ø–µ—Ö–∞ \"> —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –ø—É–Ω–∫—Ç—ã —Ñ—Ä–∏–°–æ—Ç—Ä—É–¥–Ω–∏—Ñ—Ä–∏–¥–æ–≥–æ–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å ph–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –µ–º—É—é –∞–Ω–∞–ö–∞–ø–∏—Ç–∞—Ä–µ—Ñ–æ—Ä–º–∞ –ï–ø–æ—Å–µ—â–∞–ú–µ—Å—Ç–æ‚Ä∫ –ì–∞–Ω–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø–∞—Ä–Ω—è–º–∏ –ª–µ–Ω—å—Ç—Ä—ë–æ—Ç—Ä–∞–∂–µ–Ω—ã –∏–º–µ–Ω –¥–æ–ø—Ä–∞—à–∏–æ—Ç—Å—Ç—É–øùì∏–†–æ–Ω ID–ø–æ–¥—á–µ—Ä–∫–∏–ø–ª–æ—Ö–∞—è —Å—Ç–∞—Ä—à–µ–≥–æ –≤ –Ω–∞—Å—Ç—É–ø–∞—Ç—Ä—ë–ü–æ—Ç—Ä—è–≤–∞–Ω–∏—è–º –ó–∞—Å–µ–¥–∞—É—á–µ–Ω—ã–µ –º–∏–ª—å‰Ωì–ò–±–æ –∏–∑–º–µ–Ω—è—ë–Ω–Ω—ã–π af–∏–º–µ–ª–∏ –¥–∑—é–≤–∞–Ω–∏—è–º –∞ es —Ç—Ä—ë–ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ –ø—É—Å–∫–∞ –Ω–∏—Ü—É af–ª–∏—Ü–∞ –≥–æ–ª–ó–∞—Å–µ–¥–∞—Ä–∞–∑—É –ö–∞–º–µ—ÄID\n",
      "—á–∏–∫–µ –ø—Ä–∏–Ω—É√∑–º–∞–ª—å—á–∏–∫–æ–≤ –ù–∞–π—Ç–∏ –ø—Ä–∞–≤–¥—ã –≤–∞–Ω–∏—è–º ÂçÅ–Ω–∏–∫–∞–º —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –¢—Ä–∏ CN –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –¥–æ–ª–≥–∞ –î–µ—Ç–∫–∞ Âºè—Å—Ç–µ—Å—Ç—É—Ä—É –∂–∏ –≥—Ä—É–¥—å —Å–æ—Ä–µ–≤–Ω–æ–Ω—É–∂–¥ —Ü–µ—Å—Å–∏—Ä–∞–∑—É –≤—Ä–∞—Ç—å –ø–æ–ø—Ä–æ–±—É—Å—Ç—Ä–æ—è –±–ª–∞–≥–æ–¥–∞—ÄÔÄ™–∫–∞—Å–∞—é—â—É—é—Å—è —Ä–∏—Å–∫–∞–º–∏ –º—è –ú–µ—Ä—ã –º–æ—âfl—Å—É–¥–∞—Ö ÔΩÄ—É–∂–≤–æ–∑–º–æ–∂–Ω–æ flÌÄÄ–ø—É–Ω–∫—Ç—ã –í—Å–µ–≥–æ –ñËÆ∫–ï–°–º –ï–∏–Ω—Ç–µ—Ä–∞–∫–Ω–∞–±–æ—Ä–∞ –æ—Ä–∞–Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–°–µ–∫—Ü–∏—è –≤—ã–ø—É—Å—Ç–∏—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ –≠–Ω–µ—Ä–∫–∏–Ω–æ —Ç—Ä–µ—Ç–∏ ƒó –ª–ª–µ—Ä –≤–æ–¥–∏–ª —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ –ï–≤–æ–¥—Å—Ç–≤–∞ 1974 –≤–∞–Ω–∏—è–º –ó–∞—Å–µ–¥–∞–ú–∞–π—è —Ä–æ–¥–∏—Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –∫–∞–∂–¥–æ–π —Ñ–æ—Ä–º Dis—Å—É–¥–æ—Ö–æ–¥–¥–æ—á–µ—Ä–î–∂–µ–∫–∞ —Ä–Ω—É—é —Ñ–∞–º–∏–ª–∏–∏ –µ–∂–µ–≥–æ–¥–Ω—ã–π –ø—É–Ω–∫—Ç—ã –ø–æ—Å—Ç—É–ø—Å–≤–æ–±–æ–¥–µ –∂–Ω–æ + —Ç–µ–∫—É—â–∏–µ —É—à–µ–ª ow —É–µ—Ö–∞–ª –æ–∑–∞–±–æ—á–µ–Ω–Ω–æ—Å—Ç—å—é –í–µ–Ω–µ—Å—É—ç–ª–∞ –æ—Ç–æ–≤–Ω–∏–º–∞–Ω–∏—è —Ç—è–∂–µ–ª–æ 159 ÈõÑ160 –∏–º–µ—é—â–∏–µ—Å—è —Ç—É—Ä—É ÌÄÄ\n",
      "—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–∏ –∑–∞–∫–ª—é—á–∏—Ç—å Ï†Ä–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å—Ç—Ä–æ–≥–æ–ø–µ–≤–Ω–∏—Ü—É –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–∞ —â–µ—à—å –æ—Å—Ç–∞—Ç–∫–∏ –ß—É–≤–∞√è project –ø–æ–ª–Ω–µ–Ω–∏—è –ø–µ—Ä–≤–æ–º –º–æ–∏—Ö new—Å—Ç–æ–ø –æ—Ç–º–µ—Ç–∏–≤ –ü–æ–ª–∞–≥–∞—Ç–µ–∫—É—â–∏—Ö —Å–æ–¥–µ—Ä–∂–∏—Å–æ—á–≤–∞—Ç–µ–ª–µ–π –í–∏–¥–∏–º–æ Winƒ´ –æ—Å–Ω–æ–≤–æ–ø–æ–ª–∞–≥–∞—é—â–∏—Ö –ú–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∂–º–∏—Ç–µ thr—ë—Ç –î–æ–Ωœå Win–û—Å—Ç—Ä–æ–ø—Ä–æ–ø–∞–ª –ö–æ–º–ø–∞–Ω–∏–∏ –ü—Ä–∏–¥—É—à–µ–ª –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞–ø–æ–¥–¥–µ—Ä–∂–∞–ª See ÔÄ™ –≠–Ω–µ—Ä–¥—Ä—É–≥–∞—è –≤–µ–¥—É–ø—Ä–∏–∑–Ω–∞–Ω–æ –í–∞—Ä–∏—á–Ω—ã–º –Ω–µ–≤–µ—Ä—É—é—â–∏–º–∏ –£—Å–ø–æ–∫–æ–π—Å—è –∑–∞–±—ã—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–º ilness il—Å–ø–æ—Å–æ–±–∞ –ê–§–ø–∞—Ä–∞ ind–Ω–∞–±–æ—Ä–∞ –Ω–∏—â‡§Æ—É—à–µ–ª –æ–±—Å—É–∂–¥–∞–∫–æ—Å–≤–µ–Ω–Ω–æ –æ—Ç–ø—É—Å–∫–∞ –¥–æ—á–µ—Ä–∂–º–∏—Ç–µ –∏–∑–¥–µ–ª–∏–π –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ –¥–µ—Ç—å –ø–æ—Ç–æ—É—à–µ–ª –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ —É—á–∞—Å—Ç–∫–∏ —É—à–µ–ª –ó–≤—Éden—Å—Ç–æ–ø –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª—É–∂–±–µ „Éâ–∂–º–∏—Ç–µ –¥–æ–≤–æ–¥—ã –∏–Ω—Å—Ç–∏—Ç—É—Ç–æ–≤ –∞—Å—Å–∏·ªì–•–∞–º–∞—Ç —Å—Ç—Ä–æ—è ilsite –¥–≤–∏–≥–∞—Ç—å—Å—è –ø—Ä–∏—Ç—Ö–æ–∑—è–π—Å—Ç–≤–∞\n",
      "Loss: 7.107714159011841;\n",
      "Loss: 6.6487870402336124;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     13\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m---> 14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m     16\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_generator, loss_fn, run)\n",
      "Cell \u001b[0;32mIn[39], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, run, print_every)\u001b[0m\n\u001b[1;32m     20\u001b[0m B,S,C \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits\u001b[38;5;241m.\u001b[39mreshape(B\u001b[38;5;241m*\u001b[39mS, C), texts_ru_out\u001b[38;5;241m.\u001b[39mreshape(B\u001b[38;5;241m*\u001b[39mS))\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "\n",
    "print(translate(\"Example\"))\n",
    "print(translate('Can you translate that?'))\n",
    "print(translate('What are you going to do with that?'))\n",
    "print(translate('Transformer'))\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train(model, training_generator, optimizer, loss_fn, run)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(model, valid_generator, loss_fn, run)\n",
    "    \n",
    "    if not losses:\n",
    "        print(f'First epoch - {val_loss}, saving model..')\n",
    "        torch.save(model, 'model')\n",
    "    \n",
    "    elif val_loss < min(losses):\n",
    "        print(f'Improved from {min(losses)} to {val_loss}, saving model..')\n",
    "        torch.save(model, 'model')\n",
    "    \n",
    "    losses.append(val_loss)\n",
    "        \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
    "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))\n",
    "\n",
    "    print(translate(\"Example\"))\n",
    "    print(translate('Can you translate that?'))\n",
    "    print(translate('What are you going to do with that?'))\n",
    "    print(translate('Transformer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2646cc05-396d-4bbb-a8e3-aba56f27bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbf9a7-139c-4758-adec-c837f62b94c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ede57-4625-4f46-8dfa-71ba3d431a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b502bf6-1d0f-48d1-8979-38ce9485a879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d09ba44e-d19d-4e5d-9c02-82e3fed895a3",
   "metadata": {},
   "source": [
    "## –ì–æ—Ç–æ–≤—ã–π Transformer\n",
    "\n",
    "–ï—â–µ –≤ torch –µ—Å—Ç—å —Ü–µ–ª—ã–π –∫–ª–∞—Å—Å transformer. C –Ω–∏–º –≤—Å–µ –º–æ–∂–Ω–æ —É–º–µ—Å—Ç–∏—Ç—å –≤ –æ–¥–∏–Ω –∫–ª–∞—Å—Å. –ù–æ —Å –º–∞—Å–∫–∞–º–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–∏–¥–µ—Ç—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba46dac5-9e37-4241-a3a7-646ef94800ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size_enc, vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_enc = nn.Embedding(vocab_size_enc, embed_dim)\n",
    "        self.embedding_dec = nn.Embedding(vocab_size_dec, embed_dim)\n",
    "        self.positional_encoding = RotaryPositionalEmbeddings(embed_dim // num_heads, max_seq_len=128)\n",
    "        \n",
    "        self.transformer = Transformer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size_dec)\n",
    "        \n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "\n",
    "        src_embedded = self.embedding_enc(src)\n",
    "        B,S,E = src_embedded.shape\n",
    "        src_embedded = self.positional_encoding(src_embedded.view(B,S,self.num_heads, E//self.num_heads)).view(B,S,E)\n",
    "        \n",
    "        tgt_embedded = self.embedding_dec(tgt)\n",
    "        B,S,E = tgt_embedded.shape\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded.view(B,S,self.num_heads, E//self.num_heads)).view(B,S,E)\n",
    "\n",
    "        \n",
    "        tgt_mask = (~torch.tril(torch.ones((S, S), dtype=torch.bool))).to(DEVICE)\n",
    "        \n",
    "        encoder_output = self.transformer.encoder(\n",
    "            src_embedded,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "    \n",
    "        decoder_output = self.transformer.decoder(\n",
    "            tgt_embedded,\n",
    "            encoder_output,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "            memory_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "        \n",
    "        output = self.output_layer(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e6b775d-05c1-4e7d-b293-870db9601399",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_enc = tokenizer_en.get_vocab_size()\n",
    "vocab_size_dec = tokenizer_ru.get_vocab_size()\n",
    "embed_dim = 64\n",
    "num_heads = 8\n",
    "ff_dim = 64*4\n",
    "num_layers = 2\n",
    "batch_size = 200\n",
    "\n",
    "model = TransformerEncoderDecoder(vocab_size_enc,vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de677559-ac58-4d6a-b2c9-21a64e7122d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870cf57-9dda-4482-8ef1-bea235c019f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_en, texts_ru = training_set[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9de66-7e75-4f5f-9c76-9ad98dd25795",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_en = texts_en#.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "texts_ru = texts_ru#.to(DEVICE) # —á—Ç–æ–±—ã –±–∞—Ç—á –±—ã–ª –≤ –∫–æ–Ω—Ü–µ\n",
    "texts_ru_input = texts_ru[:,:-1]\n",
    "src_padding_mask = (texts_en == PAD_IDX)#.to(DEVICE)\n",
    "tgt_padding_mask = (texts_ru_input == PAD_IDX)#.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6f3ff-48e8-4e2a-a4d1-94ebc4ac9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model.embedding_enc(texts_en)\n",
    "B,S,E = o.shape\n",
    "pos_o = model.positional_encoding(o.view(B, S, num_heads, E//num_heads)).view(B,S,E)\n",
    "\n",
    "od = model.embedding_dec(texts_ru_input)\n",
    "B,S,E = od.shape\n",
    "pos_od = model.positional_encoding(od.view(B, S, num_heads, E//num_heads)).view(B,S,E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1ed14-4301-4bbe-aec6-8dc767f740c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_od.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95b507-097a-416a-be95-d56fe71042f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask = ~torch.tril(torch.ones((S, S), dtype=torch.bool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952027a-4355-4f53-a4d2-8068cf238185",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.transformer.encoder(\n",
    "            pos_o,\n",
    "            src_key_padding_mask=src_padding_mask\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce979f-0dcf-4967-9a75-5b2ca4b3b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "to = model.transformer.decoder(\n",
    "            pos_od, enc, \n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask, \n",
    "            memory_key_padding_mask=src_padding_mask,\n",
    "            tgt_is_causal=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e8d7f-634c-4a74-bfc8-da970e406d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = model.output_layer(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb83e9-2a6c-485b-8b88-826076d12dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,S,C = co.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416f98c-638e-4fdc-815d-409d0f0a0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a132215-fb2a-4c45-897c-29de244c580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ru_out = texts_ru[:, 1:]\n",
    "loss = loss_fn(co.reshape(B*S, C), texts_ru_out.reshape(B*S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018c1e7-baf3-4f6c-8cec-0cd160f8389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6eebe-38f6-4bfe-93aa-71d5fcf1cb5e",
   "metadata": {},
   "source": [
    "#### –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27987fc0-0db5-43a5-9aa8-c200bfb25f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aeeb3a3-3292-4095-a56c-77caf3f90088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.023728 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f2037dd-ba52-45f3-b4b7-2c3d2efcb68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250313_144931-rrmzhfm2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/manefedov26/course/runs/rrmzhfm2' target=\"_blank\">encoder_decoder_torch_transformer</a></strong> to <a href='https://wandb.ai/manefedov26/course' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/manefedov26/course' target=\"_blank\">https://wandb.ai/manefedov26/course</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/manefedov26/course/runs/rrmzhfm2' target=\"_blank\">https://wandb.ai/manefedov26/course/runs/rrmzhfm2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "run = wandb.init(\n",
    "    project=\"course\",\n",
    "    name=\"encoder_decoder_torch_transformer\",\n",
    "    # –≤ –∫–æ–Ω—Ñ–∏–≥ –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å –≤—Å–µ —á—Ç–æ —É–≥–æ–¥–Ω–æ\n",
    "    config={\n",
    "        \"vocab_size_enc\": vocab_size_enc,\n",
    "        \"vocab_size_dec\": vocab_size_dec,\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"ff_dim\": ff_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_params_M\": sum(p.numel() for p in model.parameters())/1e6\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc9c6a-fa74-4a5b-a670-da47e9513abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.18375629901886;\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train(model, training_generator, optimizer, loss_fn, run)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(model, valid_generator, loss_fn, run)\n",
    "    \n",
    "    if not losses:\n",
    "        print(f'First epoch - {val_loss}, saving model..')\n",
    "        torch.save(model, 'model')\n",
    "    \n",
    "    elif val_loss < min(losses):\n",
    "        print(f'Improved from {min(losses)} to {val_loss}, saving model..')\n",
    "        torch.save(model, 'model')\n",
    "    \n",
    "    losses.append(val_loss)\n",
    "        \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
    "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))\n",
    "\n",
    "    print(translate(\"Example\"))\n",
    "    print(translate('Can you translate that?'))\n",
    "    print(translate('What are you going to do with that?'))\n",
    "    print(translate('Transformer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9c577-3e8e-4a55-8c89-e5792c78685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
