{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание № 10. Машинный перевод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yj7aripVIsbG",
   "metadata": {
    "id": "Yj7aripVIsbG"
   },
   "source": [
    "## Задание 1 (6 баллов + 2 доп балла).\n",
    "Нужно обучить трансформер на том же корпусе но в другую сторону - с русского на английский.\n",
    "Можно использовать как основу первый или второй способ реализации (с MultiheadAttention или с nn.Transformer). Подберите несколько тестовых примеров для проверки обучения на каждой эпохе. \n",
    "\n",
    "Параметры ниже точно работают в колабе и модель обучается достаточно быстро. Попробуйте их немного увеличить (batch size возможно придется наоборот уменьшить). Обучайте модель хотя бы 5 эпох, а желательно больше, чтобы тестовые примеры начали переводиться более менее адекватно. \n",
    "\n",
    "После обучения возьмите хотя бы 100 примером из тестовой части параллельного корпуса и переведите их. Оцените качество переводов с помощью метрики BLEU (пример использования ниже)\n",
    "Найдите лучшие (как минимум 5) переводы согласно этой метрике и проверьте действительно ли они хорошие. Если все переводы нулевые, то пообучайте модель подольше.\n",
    "\n",
    "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Сейчас она работает только с одним текстом - это не эффективно. Можно генерировать переводы сразу для нескольких текстов (батча). Главная сложность с таким подходом состоит в том, что генерируемые тексты будут заканчиваться в разное время и нужно сделать столько итераций, сколько нужно для завершения всех текстов (т.е. условие на то, что последний токен не равен [EOS] в текущем коде не сработает). \n",
    "ВАЖНО - недостаточно просто изменить входной аргумент с text на texts и добавить еще один цикл по texts! Сама модель должна вызываться на нескольких текстах! Функция с batch prediction должна работать быстрее, поэтому переведите всю тестовую выборку и оцените качество BLEU на всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d202c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В колабе установите torchtune и torchao, чтобы семинарская тетрадка работала\n",
    "!pip install torchtune torchao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f35e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример использования BLEU\n",
    "# обратите внимание что текты должны быть токенизированы\n",
    "import nltk\n",
    "\n",
    "hypothesis = ['It', 'is', 'a', 'cat', 'at', 'room'] # замените на перевод вашей модели\n",
    "reference = ['It', 'is', 'a', 'cat', 'inside', 'the', 'room'] # замените на эталонный перевод\n",
    "\n",
    "\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, auto_reweigh=True)\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры которые работаю в колабе\n",
    "embed_dim = 32 \n",
    "num_heads = 4\n",
    "ff_dim = embed_dim*2\n",
    "num_layers = 2 \n",
    "batch_size = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa93d6",
   "metadata": {},
   "source": [
    "\n",
    "## Задание 2 (2 балла).\n",
    "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/13.pdf\n",
    "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как ее применить к паре en->ru на данных из семинара. Сколько моделей понадобится? Сколько запусков обучения нужно будет сделать?\n",
    "\n",
    "Ответ должен содержать как минимум 10 предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5bf2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
