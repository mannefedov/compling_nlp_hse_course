{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание № 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb51a4",
   "metadata": {},
   "source": [
    "### Задание 1 (7 баллов).\n",
    "Это задание основано на этой тетрадке - https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/transfer_learning_hg/Fine_tunining_pretrained_LMs_torch.ipynb\n",
    "\n",
    "На датасете lenta_sample.ru  дообучите две модели - modernbert-base (из семинара) и rumodernbert-base (https://huggingface.co/deepvk/RuModernBERT-base). Оцените разницу в качестве сравнив поклассовые метрики (classification_report)\n",
    "\n",
    "Для обоих моделей качество должно быть >0.10 по f-мере (прогоните несколько экспериментов если у вас получаются нули, изменяя параметры).\n",
    "Также для обоих моделей попробуйте дообучать модель и целиком и дообучать только последний слой. \n",
    "Для RuModernBERT дополнительно сравните модель, которая использует первый вектор (cls токен, как в семинаре), так и усредненный вектор по всем hidden_state, который выдает bert. \n",
    "\n",
    "\n",
    "### Подзадание на 1 балл\n",
    "Дообучите любую из моделей, добавляя к BERT основе не только один линейный слой, но и один слой LSTM. Финальное состояние из этого слоя должно подаваться с новый линейный классификационный слой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb7969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2444e3fe",
   "metadata": {},
   "source": [
    "## Задание 2 (2 балла)\n",
    "\n",
    "Проведите несколько экспериментов с gradual unfreezing. Используя ту же задачу и датасет, что в первом задании, дообучите модели таким образом, что в начале обучения весь backbone BERT заморожен и дообучение происходит только на новом Linear/dense/fc слое, но после каждой N эпохи, размораживайте (`_requires_grad = True`) какую-то часть параметров BERT. Проведите как минимум 3 эксперимента с разными методиками разморозки. Вы можете придумать их сами, но вот несколько примеров - 1) разморозка начинается с конца модели и каждые две эпохи размораживается несколько слоев до тех пор пока не разморозятся все слои всключая первый эмбеддинг слой 2) разморозка начинается с начала (то есть сначала размораживается только embedding слой), а со временем включаются и все последующие 3) таргетировано размораживаются сначала слои query трансформаций, потом key, потом value 4) или даже можете попробовать сначала разморозить все слои и наоборот замораживать части с прогрессом обучения. Для каждого эксперимента сохраните метрики на каждой эпохе и финальную метрику, сравните их между собой - какой schedule сработал лучше всего? Сработало ли что-то лучше дефолтного подхода из первого задания?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd91e6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
