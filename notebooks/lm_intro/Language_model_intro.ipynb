{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Языковое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Языковые модели - важнейшая часть современного NLP. Практически во всех задачах, связанных с обработкой текста, напрямую или косвенно используются языковые модели. А наиболее известные недавние прорывы в области - это по большей части новые подходы к языковому моделированию. ELMO, BERT, GPT, LLaMA, QWEN, Deepseek - это все языковые модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это достаточно сложная тема, поэтому будем разбирать постепенно. Сегодня разберём самые основы. Научимся приписывать вероятность последовательности слов и попробуем генерировать текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('../../data/habr_texts.txt.zip', 'r') as zip_file:\n",
    "    with zip_file.open('habr_texts.txt', 'r') as txt_file:\n",
    "        habr = txt_file.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем два разных корпуса: новостной и сообщения с 2ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = open('lenta.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хабр побольше, поэтому урежем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина 1 - 40187704\n",
      "Длина 2 - 11536552\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина 1 -\", len(habr))\n",
    "print(\"Длина 2 -\", len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "habr = habr[:12_000_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина 1 - 12000000\n",
      "Длина 2 - 11536552\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина 1 -\", len(habr))\n",
    "print(\"Длина 2 -\", len(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем простую функцию для нормализации. Удалять пунктуацию и приводить к нижнему регистру, строго говоря не стоит, сгенерированный текст так будет не похож на настоящий. Но это немного упростит нам работу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним тексты по токенам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_habr = normalize(habr)\n",
    "norm_news = normalize(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина корпуса технических текстов в токенах - 1664486\n",
      "Длина корпуса новостных текстов в токенах -  1505789\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина корпуса технических текстов в токенах -\", len(norm_habr))\n",
    "print(\"Длина корпуса новостных текстов в токенах - \", len(norm_news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И по уникальным токенам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных токенов в технических текстах - 138512\n",
      "Уникальный токенов в новостных текстах -  116302\n"
     ]
    }
   ],
   "source": [
    "print(\"Уникальных токенов в технических текстах -\", len(set(norm_habr)))\n",
    "print(\"Уникальный токенов в новостных текстах - \", len(set(norm_news)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем, сколько раз встречаются слова и выведем самые частотные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_habr = Counter(norm_habr)\n",
    "vocab_news = Counter(norm_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 43507),\n",
       " ('и', 41615),\n",
       " ('на', 23117),\n",
       " ('с', 17358),\n",
       " ('не', 16814),\n",
       " ('—', 14604),\n",
       " ('для', 14155),\n",
       " ('что', 13716),\n",
       " ('это', 9421),\n",
       " ('как', 8640)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_habr.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 72412),\n",
       " ('и', 33290),\n",
       " ('на', 28434),\n",
       " ('по', 19490),\n",
       " ('что', 17031),\n",
       " ('с', 15921),\n",
       " ('не', 12702),\n",
       " ('из', 7727),\n",
       " ('о', 7515),\n",
       " ('как', 7514)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_news.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы превратить абсолютные частоты в вероятности, разделим на общее число слов в каждом корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_news['ваываываываываыва']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 0.026138399481882093),\n",
       " ('и', 0.025001712240295203),\n",
       " ('на', 0.01388837154532991),\n",
       " ('с', 0.010428444576884395),\n",
       " ('не', 0.01010161695562474),\n",
       " ('—', 0.008773879744257387),\n",
       " ('для', 0.008504126799504472),\n",
       " ('что', 0.008240381715436477),\n",
       " ('это', 0.005660005551263273),\n",
       " ('как', 0.005190791631771009),\n",
       " ('gt', 0.005140926388086172),\n",
       " ('по', 0.005132515383127284),\n",
       " ('»', 0.004909022965648254),\n",
       " ('«', 0.0047762492445115184),\n",
       " ('к', 0.0042259292057728335),\n",
       " ('а', 0.004147226230800379),\n",
       " ('из', 0.004057108320526577),\n",
       " ('но', 0.004055305962321101),\n",
       " ('1', 0.004041487882745784),\n",
       " ('мы', 0.003708051614732716)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_habr = Counter({word:c/len(norm_habr) for word, c in vocab_habr.items()})\n",
    "probas_habr.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 0.04808907489694771),\n",
       " ('и', 0.0221080111489724),\n",
       " ('на', 0.018883123731146926),\n",
       " ('по', 0.012943380513471676),\n",
       " ('что', 0.011310349590812525),\n",
       " ('с', 0.01057319451795703),\n",
       " ('не', 0.008435444806676101),\n",
       " ('из', 0.005131529052211166),\n",
       " ('о', 0.00499073907433246),\n",
       " ('как', 0.0049900749706632205),\n",
       " ('к', 0.00407161959610543),\n",
       " ('за', 0.0040125143695431435),\n",
       " ('россии', 0.0036751497055696383),\n",
       " ('для', 0.003325831175549828),\n",
       " ('его', 0.003260084912295149),\n",
       " ('он', 0.0031704309169478593),\n",
       " ('от', 0.003066830744546547),\n",
       " ('сообщает', 0.003050228152815567),\n",
       " ('а', 0.0029180715226369697),\n",
       " ('также', 0.002716184007188258)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})\n",
    "probas_news.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти вероятности уже можно использовать, чтобы ответить на вопрос - это предложение больше подходит для новостей или для анонимного форума?\n",
    "\n",
    "В теории вероятностей для того, чтобы найти общую вероятность нескольких независимых событий произойти одновременно, нужно перемножить вероятности отдельных событий. В нашем случае мы хотим найти вероятность получить данное предложение. Для этого мы можем перемножить вероятности слов в этом предложении (можно представить, что мы подбрасываем кубик с количеством сторон равным количеству слов в словаре) \n",
    "\n",
    "(Если бы мы сложили вероятности, то мы бы получили вероятность выбрать из корпуса 1 из слов в данном предложении)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем простую функцию, которая расчитает обшую вероятность. В прошлом семинаре мы говорили о том, что вместо умножения вероятностей можно складывать логарифмы от них. Еще нам нужно учесть одну деталь - некоторых слов может не быть в словаре и, соответственно, вероятность будет нулевая. Можно использовать в таких случаях небольшое значение вероятности, например 1/длина корпуса. Исправить это по-нормальному - сложно, придется подробнее разбираться с вероятностями, сглаживаниями и заменой неизвестных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_proba(text, word_probas):\n",
    "    prob = 0\n",
    "    for word in normalize(text):\n",
    "        if word in word_probas:\n",
    "            prob += (np.log(word_probas[word]))\n",
    "        else:\n",
    "            prob += (np.log(1/12_000_000))\n",
    "    \n",
    "    return np.exp(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчитаем вероятность встретить такой текст в каждом из корпусов (для таких маленьких чисел нужно смотреть на степень после e: чем больше степень, тем больше вероятность; но тут легко запутаться так как степень будет отрицательная и больше будет число, которое ближе к нулю (-5 больше -10 например)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.666967517434969e-48"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_joint_proba(phrase, probas_habr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.573351371331133e-45"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_joint_proba(phrase, probas_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно просто доверится функции больше/меньше, чтобы не запутаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_joint_proba(phrase, probas_news) > compute_joint_proba(phrase, probas_habr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность встретить такой текст в новостном корпусе выше. Попробуем другой текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = 'Расcчитаем вероятность встретить такой текст в каждом из корпусов'\n",
    "compute_joint_proba(phrase, probas_news) > compute_joint_proba(phrase, probas_habr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут получается обратная ситуация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако такая оценка вероятности предложения черезчур упрощает действительность. Слова в предложении - это не независимые события, выбор первого слова сильно влияет на вероятности выбрать второе, третье и так далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие события нужно оценивать по формуле полной вероятности:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/sC7CKzQ/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если простыми словами, то для того, чтобы получить вероятность предложения, нужно перемножить вероятность первого слова, вероятность второго слова, при условии первого, вероятность третьего при условии первого и второго, вероятность четвертого слова, при условии первого, второго и третьего и так далее до вероятности последнего слова при условии всех предшествующих.\n",
    "\n",
    "Условные вероятности для слов можно также вычислить по частотностям. Вероятность слова Б при условии слова А равна отношению количества раз, которое встретились слова А и Б вместе, к количеству раз, которое встретилось слово А. Вероятность слова В при условии А и Б равна отношению количества раз, которое встретились слова А,Б и В вместе к количеству раз, которое встретились слова А и Б.\n",
    "И так далее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но тут появляется проблема. Для того, чтобы расчитать полную вероятность предложения нужно, чтобы такое предложение уже встретилось в корпусе хотя бы 1 раз. Очевидно, что даже огромный корпус всего написанного текста не включает в себя все возможные тексты (тем более маленький корпус). Поэтому один из множителей в произведении будет нулевым, а значит и все произведение станет нулевым."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы этого избежать можно поубавить строгости и предположить, что вероятность слова зависит только от предыдущего слова. Это предположение называется марковским (в честь математика Андрея Маркова). Такую модель еще можно назвать биграммной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы расчитать вероятность с таким предположением, нам достаточно найти количество вхождений для каждого биграмма. А частоты отдельных слов у нас уже есть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность первого слово можно по идее считать просто как вероятность униграмма, но можно сделать небольшое добавление в нашу модель - поставить в начала каждого предложения технический токен начала предложения `<start>`, а вероятность первого слова рассчитывать как вероятность биграма `<start>`-первое слово поделить на частоту `<start>`. Дальше мы будем генерировать текст с помощью языковой модели и это поможет нам генерировать более красивые предложения.\n",
    "\n",
    "\n",
    "Дальше мы попробуем сгенерировать текст, используя эти вероятности, и нам нужно будет когда-то остановится. Для этого добавим тэг окончания `<end>`\n",
    "\n",
    "Ну и поделим все на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_habr = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(habr[:5000000])]\n",
    "sentences_news = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news[:5000000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_habr = Counter()\n",
    "bigrams_habr = Counter()\n",
    "\n",
    "for sentence in sentences_habr:\n",
    "    unigrams_habr.update(sentence)\n",
    "    bigrams_habr.update(ngrammer(sentence))\n",
    "\n",
    "\n",
    "unigrams_news = Counter()\n",
    "bigrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    bigrams_news.update(ngrammer(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать условную вероятность мы можем поделить количество вхождений на количество вхождений первого слова. Обновим нашу функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_proba_markov_assumption(text, word_counts, bigram_counts):\n",
    "    prob = 0\n",
    "    for ngram in ngrammer(['<start>'] + normalize(text) + ['<end>']):\n",
    "        word1, word2 = ngram.split()\n",
    "        if word1 in word_counts and ngram in bigram_counts:\n",
    "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
    "        # small value for unk words\n",
    "        else:\n",
    "            prob += np.log(2e-5)\n",
    "    \n",
    "    return np.exp(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Эта фраза более вероятна в корпусе хабра\n",
    "phrase = 'Расчитаем вероятность встретить такой текст в каждом из корпусов'\n",
    "\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_habr, bigrams_habr) > \\\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_news, bigrams_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Эта фраза более вероятна в корпусе новостей\n",
    "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'\n",
    "\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_habr, bigrams_habr) > \\\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_news, bigrams_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь генерировать текст с помощью биграмной языковой модели. Принцип генерации очень простой - на каждом шаге мы случайно выбираем следующее слово согласно вероятностям, расчитанным по 1 предыдущему слову."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В генерации мы можем выбирать только из уже известных слов. Можно заранее расчитать все вероятности и сохранить их в матрицу. Размерность матрицы слова на слова. В каждой ячееке будет лежать вероятность получить слово б, после слова а. Слово `а` будет в строке, а `б` в колонке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрицы получатся очень большими, но большинство значений будет нулевыми, поэтому можно воспользоваться разреженным форматом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица слова на слова (инициализируем нулями)\n",
    "matrix_habr = lil_matrix((len(unigrams_habr), \n",
    "                          len(unigrams_habr)))\n",
    "\n",
    "# к матрице нужно обращаться по индексам\n",
    "# поэтому зафиксируем порядок слов в словаре и сделаем маппинг id-слово и слово-id\n",
    "id2word_habr = list(unigrams_habr)\n",
    "word2id_habr = {word:i for i, word in enumerate(id2word_habr)}\n",
    "\n",
    "# заполняем матрицу\n",
    "for ngram in bigrams_habr:\n",
    "    word1, word2 = ngram.split()\n",
    "    # на пересечение двух слов ставим вероятность встретить второе после первого\n",
    "    matrix_habr[word2id_habr[word1], word2id_habr[word2]] =  (bigrams_habr[ngram]/\n",
    "                                                                     unigrams_habr[word1])\n",
    "    \n",
    "matrix_habr = csc_matrix(matrix_habr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# то же самое для другого корпуса\n",
    "matrix_news = lil_matrix((len(unigrams_news), \n",
    "                        len(unigrams_news)))\n",
    "\n",
    "id2word_news = list(unigrams_news)\n",
    "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
    "\n",
    "\n",
    "\n",
    "for ngram in bigrams_news:\n",
    "    word1, word2 = ngram.split()\n",
    "    matrix_news[word2id_news[word1], word2id_news[word2]] =  (bigrams_news[ngram]/\n",
    "                                                                     unigrams_news[word1])\n",
    "    \n",
    "matrix_news = csc_matrix(matrix_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для генерации нам понадобится функция np.random.choice , которая выбирает случайный объект из заданных. Ещё в неё можно подать вероятность каждого объекта и она будет доставать по ним (не только максимальный по вероятности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
    "    text = []\n",
    "    current_idx = word2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
    "        # просто выбирать наиболее вероятное продолжение не получится\n",
    "        # можете попробовать раскоментировать следующую строчку и посмотреть что получается\n",
    "        # chosen = matrix[current_idx].argmax()\n",
    "        text.append(id2word[chosen])\n",
    "        \n",
    "        if id2word[chosen] == '<end>':\n",
    "            chosen = word2id['<start>']\n",
    "        current_idx = chosen\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate(matrix_news, id2word_news, word2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "используя веса потому что первые смартфоны за учетной записью и с серьёзными исследованиями так читают как делает нас более что параметр psztempname shcreatememstream 0 and год назад все что он позволит снизить количество лишних не требуют чтобы сообщение с вебсокетами применяют не совпадает и диету \n",
      " так говорят что сегодня я изо рта \n",
      " в основном за несколько раз не каких-то аномалий эфира и сугубо через 25 кэша \n",
      " а на трамваях хотя я создал в целом « что-то что имеющаяся резьба 6-32 unc по инстаграму построить свой “ многослойный перцептрон с помощью нейросетей — включаю хот-спот и низкая стоимость\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_habr, id2word_habr, word2id_habr).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кроме того как сообщает агентство риа новости о горе искало больше недели \n",
      " приметы преступников \n",
      " известно в сеуле договор о выдаче шакала за движением в основном пакистанцев и дальнего зарубежья задействована на этом сообщило итар-тасс со стороны проверяющих палаты вытекает что все степени \n",
      " как заметил бром прокомментировал высказывание примакова клеветой \n",
      " в течение нескольких сотен рублей в интервью газете frankfurter allgemeine глава правительства москвы в рядерегионов уже больше не находятся в рао еэс в выражении \n",
      " в нью-йорке ее данным агентства прайм-тасс \n",
      " билл гейтс даже обойдет по словам коптева планируется начать украина \n",
      " это компетенция суда и\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2word_news, word2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Температура\n",
    "\n",
    "Обычное случайное семплирование может приводить к слишком рандомным результатам. Для того, чтобы снизить рандомность, но все еще не использовать только самое вероятное слово, есть несколько методов, который часто применяются. \n",
    "\n",
    "Самый основной - это температура. Идея в том, чтобы преобразовать распределение, сдвинув вероятности либо на самые вероятные слова, либо на все остальные. Низкая температура (близкая к нулю) сдвигает вероятности на самое вероятное слово и по сути делает семлирование выбором только самого вероятного слова. А высокая температура размывает вероятности по всем словам. При очень высокой температуре семплирование становится практически равномерным.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_temperature(probas, temperature):\n",
    "    # логарифмирование и деление на температуру\n",
    "    log_probas = np.log(np.maximum(probas, 1e-10))  \n",
    "    adjusted_log_probas = log_probas / temperature\n",
    "    # чтобы получить честные вероятности, нужно применить софтмакс\n",
    "    exp_probas = np.exp(adjusted_log_probas)\n",
    "    adjusted_probabilities = exp_probas / np.sum(exp_probas)\n",
    "    return adjusted_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на изначальное распределение для какого-то слова (топ 100 вероятностей отсортированных по убыванию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = matrix_news[12].toarray()[0]\n",
    "plt.bar(range(100), probas[probas.argsort()[:-(100+1):-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы будем повышать температуру, то распределение будет все больше и больше разглаживаться "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGhCAYAAACK3QWkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAri0lEQVR4nO3df3RU5Z3H8U8CJJOAScQsmQRBshoFBAGDTINpsXXW0JNdSX9QZFnJyeaQroUVzBYKLCQqajAIRSA1UhfFU2koZ22qSHNM4w+OJQYJUOVn4RQNS5gAxWQwlUQzz/7h4dqRAZkY+ZHn/TrnnmSe+733PvepJZ/zzHNnIowxRgAAAN1c5KXuAAAAwMVA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAVuhU6CkrK9OgQYPkcrnk8Xi0devW89Zv2LBBgwcPlsvl0vDhw7Vp06ag/cYYFRUVKTk5WTExMfJ6vTpw4ICz//3331d+fr5SU1MVExOj66+/XsXFxWpvbw+qiYiIOGt7++23O3OLAACgmwk79Kxfv16FhYUqLi7W9u3bNWLECGVlZenYsWMh67ds2aLJkycrPz9fO3bsUE5OjnJycrRr1y6nprS0VCtWrFB5ebnq6urUu3dvZWVl6fTp05Kkffv2KRAI6Omnn9bu3bv185//XOXl5Zo/f/5Z1/vDH/6go0ePOlt6enq4twgAALqhiHC/cNTj8ei2227TqlWrJEmBQEADBgzQf/7nf2ru3Lln1U+aNEmtra3auHGj0/aNb3xDI0eOVHl5uYwxSklJ0X/913/ppz/9qSSppaVFSUlJeu6553TPPfeE7MeSJUv01FNP6S9/+Yukz2Z6UlNTtWPHDo0cOTKcW3IEAgE1NjbqqquuUkRERKfOAQAALi5jjE6dOqWUlBRFRp57PqdnOCdtb29XfX295s2b57RFRkbK6/WqtrY25DG1tbUqLCwMasvKylJlZaUk6dChQ/L5fPJ6vc7++Ph4eTwe1dbWnjP0tLS0qG/fvme133333Tp9+rRuvPFGzZkzR3ffffc576etrU1tbW3O6yNHjmjo0KHnrAcAAJevw4cP69prrz3n/rBCz4kTJ9TR0aGkpKSg9qSkJO3bty/kMT6fL2S9z+dz9p9pO1fNFx08eFArV67UE0884bT16dNHS5cu1e23367IyEj97//+r3JyclRZWXnO4FNSUqKHHnrorPbDhw8rLi4u5DEAAODy4vf7NWDAAF111VXnrQsr9FwOjhw5ovHjx2vixImaNm2a056YmBg0o3TbbbepsbFRS5YsOWfomTdvXtAxZwYtLi6O0AMAwBXmy5amhLWQOTExUT169FBTU1NQe1NTk9xud8hj3G73eevP/LyQczY2Nurb3/62xo4dq9WrV39pfz0ejw4ePHjO/dHR0U7AIegAANC9hRV6oqKilJ6erpqaGqctEAiopqZGGRkZIY/JyMgIqpek6upqpz41NVVutzuoxu/3q66uLuicR44c0R133KH09HQ9++yz512odMbOnTuVnJwczi0CAIBuKuy3twoLC5Wbm6vRo0drzJgxWr58uVpbW5WXlydJmjp1qvr376+SkhJJ0syZMzVu3DgtXbpU2dnZqqio0LZt25yZmoiICM2aNUuPPPKI0tLSlJqaqoULFyolJUU5OTmSPg881113nZ544gkdP37c6c+Z2aC1a9cqKipKo0aNkiS9+OKLWrNmjZ555pnOjw4AAOg2wg49kyZN0vHjx1VUVCSfz6eRI0eqqqrKWYjc0NAQNAszduxYrVu3TgsWLND8+fOVlpamyspKDRs2zKmZM2eOWltbVVBQoObmZmVmZqqqqkoul0vSZzNDBw8e1MGDB89alf33T9wvWrRIH3zwgXr27KnBgwdr/fr1+uEPfxjuLQIAgG4o7M/p6c78fr/i4+PV0tLC+h4AAK4QF/r3m+/eAgAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWCPtrKNB5g+a+4vz+/uLsS9gTAADsw0wPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArdCr0lJWVadCgQXK5XPJ4PNq6det56zds2KDBgwfL5XJp+PDh2rRpU9B+Y4yKioqUnJysmJgYeb1eHThwwNn//vvvKz8/X6mpqYqJidH111+v4uJitbe3B53n3Xff1Te/+U25XC4NGDBApaWlnbk9AADQDYUdetavX6/CwkIVFxdr+/btGjFihLKysnTs2LGQ9Vu2bNHkyZOVn5+vHTt2KCcnRzk5Odq1a5dTU1paqhUrVqi8vFx1dXXq3bu3srKydPr0aUnSvn37FAgE9PTTT2v37t36+c9/rvLycs2fP985h9/v11133aXrrrtO9fX1WrJkiR588EGtXr063FsEAADdkQnTmDFjzPTp053XHR0dJiUlxZSUlISs/9GPfmSys7OD2jwej/nxj39sjDEmEAgYt9ttlixZ4uxvbm420dHR5te//vU5+1FaWmpSU1Od17/4xS/M1Vdfbdra2py2n/3sZ+amm2664HtraWkxkkxLS8sFHxOO63620dkAAEDXuNC/32HN9LS3t6u+vl5er9dpi4yMlNfrVW1tbchjamtrg+olKSsry6k/dOiQfD5fUE18fLw8Hs85zylJLS0t6tu3b9B1vvWtbykqKiroOvv379eHH34Y8hxtbW3y+/1BGwAA6J7CCj0nTpxQR0eHkpKSgtqTkpLk8/lCHuPz+c5bf+ZnOOc8ePCgVq5cqR//+Mdfep2/v8YXlZSUKD4+3tkGDBgQsg4AAFz5rrint44cOaLx48dr4sSJmjZt2lc617x589TS0uJshw8f7qJeAgCAy01YoScxMVE9evRQU1NTUHtTU5PcbnfIY9xu93nrz/y8kHM2Njbq29/+tsaOHXvWAuVzXefvr/FF0dHRiouLC9oAAED3FFboiYqKUnp6umpqapy2QCCgmpoaZWRkhDwmIyMjqF6SqqurnfrU1FS53e6gGr/fr7q6uqBzHjlyRHfccYfS09P17LPPKjIyuOsZGRnavHmzPvnkk6Dr3HTTTbr66qvDuU0AANANhf32VmFhoX75y19q7dq12rt3r+677z61trYqLy9PkjR16lTNmzfPqZ85c6aqqqq0dOlS7du3Tw8++KC2bdumGTNmSJIiIiI0a9YsPfLII3rppZf03nvvaerUqUpJSVFOTo6kzwPPwIED9cQTT+j48ePy+XxBa3X+9V//VVFRUcrPz9fu3bu1fv16PfnkkyosLPwq4wMAALqJnuEeMGnSJB0/flxFRUXy+XwaOXKkqqqqnEXDDQ0NQbMwY8eO1bp167RgwQLNnz9faWlpqqys1LBhw5yaOXPmqLW1VQUFBWpublZmZqaqqqrkcrkkfTZjc/DgQR08eFDXXnttUH+MMZI+e+Lr1Vdf1fTp05Wenq7ExEQVFRWpoKAg/FEBAADdToQ5kxogv9+v+Ph4tbS0fC3rewbNfcX5/f3F2V1+fgAAbHShf7+vuKe3AAAAOoPQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArNDzUnfAZoPmvhL0+v3F2UFt7y/OvthdAgCg22KmBwAAWIGZnstcqNkgAAAQPmZ6AACAFZjpuQKx7gcAgPAx0wMAAKxA6AEAAFbg7a1ugMXOAAB8OWZ6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwQqdCT1lZmQYNGiSXyyWPx6OtW7eet37Dhg0aPHiwXC6Xhg8frk2bNgXtN8aoqKhIycnJiomJkdfr1YEDB4JqHn30UY0dO1axsbFKSEgIeZ2IiIiztoqKis7cIgAA6GbCDj3r169XYWGhiouLtX37do0YMUJZWVk6duxYyPotW7Zo8uTJys/P144dO5STk6OcnBzt2rXLqSktLdWKFStUXl6uuro69e7dW1lZWTp9+rRT097erokTJ+q+++47b/+effZZHT161NlycnLCvUUAANANhR16li1bpmnTpikvL09Dhw5VeXm5YmNjtWbNmpD1Tz75pMaPH6/Zs2dryJAhWrRokW699VatWrVK0mezPMuXL9eCBQs0YcIE3XLLLXr++efV2NioyspK5zwPPfSQHnjgAQ0fPvy8/UtISJDb7XY2l8sV7i0CAIBuKKzQ097ervr6enm93s9PEBkpr9er2trakMfU1tYG1UtSVlaWU3/o0CH5fL6gmvj4eHk8nnOe83ymT5+uxMREjRkzRmvWrJEx5py1bW1t8vv9QRsAAOieeoZTfOLECXV0dCgpKSmoPSkpSfv27Qt5jM/nC1nv8/mc/WfazlVzoR5++GF95zvfUWxsrF599VX95Cc/0UcffaT7778/ZH1JSYkeeuihsK4BAACuTGGFnsvdwoULnd9HjRql1tZWLVmy5JyhZ968eSosLHRe+/1+DRgw4GvvJwAAuPjCensrMTFRPXr0UFNTU1B7U1OT3G53yGPcbvd568/8DOecF8rj8ej//u//1NbWFnJ/dHS04uLigjYAANA9hRV6oqKilJ6erpqaGqctEAiopqZGGRkZIY/JyMgIqpek6upqpz41NVVutzuoxu/3q66u7pznvFA7d+7U1Vdfrejo6K90HgAAcOUL++2twsJC5ebmavTo0RozZoyWL1+u1tZW5eXlSZKmTp2q/v37q6SkRJI0c+ZMjRs3TkuXLlV2drYqKiq0bds2rV69WtJnn60za9YsPfLII0pLS1NqaqoWLlyolJSUoMfNGxoadPLkSTU0NKijo0M7d+6UJN1www3q06ePXn75ZTU1Nekb3/iGXC6Xqqur9dhjj+mnP/3pVxwiAADQHYQdeiZNmqTjx4+rqKhIPp9PI0eOVFVVlbMQuaGhQZGRn08gjR07VuvWrdOCBQs0f/58paWlqbKyUsOGDXNq5syZo9bWVhUUFKi5uVmZmZmqqqoKety8qKhIa9eudV6PGjVKkvT666/rjjvuUK9evVRWVqYHHnhAxhjdcMMNzuP1AAAAEeZ8z3Rbxu/3Kz4+Xi0tLV/L+p5Bc19xfn9/cXbQ61BtX6UGAABbXOjfb757CwAAWIHQAwAArNCtPqcHn/viW2AAANiOmR4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFbg6S1L8AGGAADbMdMDAACsQOgBAABW4O0ti/EBhgAAmzDTAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACswCcywxHqS0n51GYAQHfBTA8AALACMz0IS6jZIAAArgTM9AAAACsQegAAgBUIPQAAwAqEHgAAYAUWMuMr47F2AMCVgJkeAABgBUIPAACwAqEHAABYgTU96HJ8gCEA4HLETA8AALACoQcAAFiBt7dwUfBYOwDgUmOmBwAAWIHQAwAArEDoAQAAVmBNDy6JUI+1f3HdD4++AwC6EjM9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAV+HBCXFH44lIAQGcx0wMAAKzATA+uaHxVBQDgQjHTAwAArMBMD7od1v0AAEJhpgcAAFiBmR50e6z7AQBIzPQAAABLEHoAAIAVCD0AAMAKhB4AAGAFFjLDSl9c3PxF7y/O7lQNi6QB4PLFTA8AALACoQcAAFiB0AMAAKzQqdBTVlamQYMGyeVyyePxaOvWreet37BhgwYPHiyXy6Xhw4dr06ZNQfuNMSoqKlJycrJiYmLk9Xp14MCBoJpHH31UY8eOVWxsrBISEkJep6GhQdnZ2YqNjVW/fv00e/Zsffrpp525RQAA0M2EvZB5/fr1KiwsVHl5uTwej5YvX66srCzt379f/fr1O6t+y5Ytmjx5skpKSvTP//zPWrdunXJycrR9+3YNGzZMklRaWqoVK1Zo7dq1Sk1N1cKFC5WVlaU9e/bI5XJJktrb2zVx4kRlZGTof/7nf866TkdHh7Kzs+V2u7VlyxYdPXpUU6dOVa9evfTYY4+Fe5tAp33xu79CLXa+kBoAQNcKe6Zn2bJlmjZtmvLy8jR06FCVl5crNjZWa9asCVn/5JNPavz48Zo9e7aGDBmiRYsW6dZbb9WqVaskfTbLs3z5ci1YsEATJkzQLbfcoueff16NjY2qrKx0zvPQQw/pgQce0PDhw0Ne59VXX9WePXv0q1/9SiNHjtR3v/tdLVq0SGVlZWpvbw/3NgEAQDcTVuhpb29XfX29vF7v5yeIjJTX61VtbW3IY2pra4PqJSkrK8upP3TokHw+X1BNfHy8PB7POc95rusMHz5cSUlJQdfx+/3avXt3yGPa2trk9/uDNuByMWjuK872xddf9jg9AOBsYYWeEydOqKOjIyhYSFJSUpJ8Pl/IY3w+33nrz/wM55zhXOfvr/FFJSUlio+Pd7YBAwZc8PUAAMCVxeqnt+bNm6eWlhZnO3z48KXuEgAA+JqEtZA5MTFRPXr0UFNTU1B7U1OT3G53yGPcbvd568/8bGpqUnJyclDNyJEjL7hvbrf7rKfIzlz3XH2Ljo5WdHT0BV8DuNx0ZtE0ANgqrJmeqKgopaenq6amxmkLBAKqqalRRkZGyGMyMjKC6iWpurraqU9NTZXb7Q6q8fv9qqurO+c5z3Wd9957T8eOHQu6TlxcnIYOHXrB5wEAAN1T2I+sFxYWKjc3V6NHj9aYMWO0fPlytba2Ki8vT5I0depU9e/fXyUlJZKkmTNnaty4cVq6dKmys7NVUVGhbdu2afXq1ZKkiIgIzZo1S4888ojS0tKcR9ZTUlKUk5PjXLehoUEnT55UQ0ODOjo6tHPnTknSDTfcoD59+uiuu+7S0KFDde+996q0tFQ+n08LFizQ9OnTmc0BAADhh55Jkybp+PHjKioqks/n08iRI1VVVeUsGm5oaFBk5OcTSGPHjtW6deu0YMECzZ8/X2lpaaqsrHQ+o0eS5syZo9bWVhUUFKi5uVmZmZmqqqpyPqNHkoqKirR27Vrn9ahRoyRJr7/+uu644w716NFDGzdu1H333aeMjAz17t1bubm5evjhh8MfFaAb43ODANiqU9+yPmPGDM2YMSPkvjfeeOOstokTJ2rixInnPF9ERIQefvjh8waU5557Ts8999x5+3Xddded9WnPAAAAUidDDwD7dNUnTTOrBOBSsfqRdQAAYA9CDwAAsAJvbwG47PDZQgC+Dsz0AAAAKxB6AACAFXh7C8BlryueFDvTBsBezPQAAAArEHoAAIAVeHsLgDUu5C2wL+psDW+lAZcfZnoAAIAVCD0AAMAKvL0FAF8TvosMuLww0wMAAKxA6AEAAFYg9AAAACuwpgcALnOs+wG6BjM9AADACoQeAABgBd7eAoBugMfjgS/HTA8AALACoQcAAFiB0AMAAKzAmh4AgKOr1gZ1pgb4ujHTAwAArEDoAQAAVuDtLQDAZaEr3iYLpbM1vOXW/TDTAwAArEDoAQAAViD0AAAAK7CmBwCAEC5k/dDX+Qg/j/l3PWZ6AACAFQg9AADACoQeAABgBdb0AABwhbrc1hhd7uuQmOkBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKnQo9ZWVlGjRokFwulzwej7Zu3Xre+g0bNmjw4MFyuVwaPny4Nm3aFLTfGKOioiIlJycrJiZGXq9XBw4cCKo5efKkpkyZori4OCUkJCg/P18fffSRs//9999XRETEWdvbb7/dmVsEAADdTNihZ/369SosLFRxcbG2b9+uESNGKCsrS8eOHQtZv2XLFk2ePFn5+fnasWOHcnJylJOTo127djk1paWlWrFihcrLy1VXV6fevXsrKytLp0+fdmqmTJmi3bt3q7q6Whs3btTmzZtVUFBw1vX+8Ic/6OjRo86Wnp4e7i0CAIBuKOzQs2zZMk2bNk15eXkaOnSoysvLFRsbqzVr1oSsf/LJJzV+/HjNnj1bQ4YM0aJFi3Trrbdq1apVkj6b5Vm+fLkWLFigCRMm6JZbbtHzzz+vxsZGVVZWSpL27t2rqqoqPfPMM/J4PMrMzNTKlStVUVGhxsbGoOtdc801crvdztarV69wbxEAAHRDYYWe9vZ21dfXy+v1fn6CyEh5vV7V1taGPKa2tjaoXpKysrKc+kOHDsnn8wXVxMfHy+PxODW1tbVKSEjQ6NGjnRqv16vIyEjV1dUFnfvuu+9Wv379lJmZqZdeeum899PW1ia/3x+0AQCA7ims0HPixAl1dHQoKSkpqD0pKUk+ny/kMT6f77z1Z35+WU2/fv2C9vfs2VN9+/Z1avr06aOlS5dqw4YNeuWVV5SZmamcnJzzBp+SkhLFx8c724ABA75sCAAAwBWq56XuQFdJTExUYWGh8/q2225TY2OjlixZorvvvjvkMfPmzQs6xu/3E3wAAOimwprpSUxMVI8ePdTU1BTU3tTUJLfbHfIYt9t93vozP7+s5osLpT/99FOdPHnynNeVJI/Ho4MHD55zf3R0tOLi4oI2AADQPYUVeqKiopSenq6amhqnLRAIqKamRhkZGSGPycjICKqXpOrqaqc+NTVVbrc7qMbv96uurs6pycjIUHNzs+rr652a1157TYFAQB6P55z93blzp5KTk8O5RQAA0E2F/fZWYWGhcnNzNXr0aI0ZM0bLly9Xa2ur8vLyJElTp05V//79VVJSIkmaOXOmxo0bp6VLlyo7O1sVFRXatm2bVq9eLUmKiIjQrFmz9MgjjygtLU2pqalauHChUlJSlJOTI0kaMmSIxo8fr2nTpqm8vFyffPKJZsyYoXvuuUcpKSmSpLVr1yoqKkqjRo2SJL344otas2aNnnnmma88SAAA4MoXduiZNGmSjh8/rqKiIvl8Po0cOVJVVVXOQuSGhgZFRn4+gTR27FitW7dOCxYs0Pz585WWlqbKykoNGzbMqZkzZ45aW1tVUFCg5uZmZWZmqqqqSi6Xy6l54YUXNGPGDN15552KjIzUD37wA61YsSKob4sWLdIHH3ygnj17avDgwVq/fr1++MMfhj0oAACg++nUQuYZM2ZoxowZIfe98cYbZ7VNnDhREydOPOf5IiIi9PDDD+vhhx8+Z03fvn21bt26c+7Pzc1Vbm7uuTsNAACsxndvAQAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFihU6GnrKxMgwYNksvlksfj0datW89bv2HDBg0ePFgul0vDhw/Xpk2bgvYbY1RUVKTk5GTFxMTI6/XqwIEDQTUnT57UlClTFBcXp4SEBOXn5+ujjz4Kqnn33Xf1zW9+Uy6XSwMGDFBpaWlnbg8AAHRDYYee9evXq7CwUMXFxdq+fbtGjBihrKwsHTt2LGT9li1bNHnyZOXn52vHjh3KyclRTk6Odu3a5dSUlpZqxYoVKi8vV11dnXr37q2srCydPn3aqZkyZYp2796t6upqbdy4UZs3b1ZBQYGz3+/366677tJ1112n+vp6LVmyRA8++KBWr14d7i0CAIBuKOzQs2zZMk2bNk15eXkaOnSoysvLFRsbqzVr1oSsf/LJJzV+/HjNnj1bQ4YM0aJFi3Trrbdq1apVkj6b5Vm+fLkWLFigCRMm6JZbbtHzzz+vxsZGVVZWSpL27t2rqqoqPfPMM/J4PMrMzNTKlStVUVGhxsZGSdILL7yg9vZ2rVmzRjfffLPuuece3X///Vq2bFknhwYAAHQnPcMpbm9vV319vebNm+e0RUZGyuv1qra2NuQxtbW1KiwsDGrLyspyAs2hQ4fk8/nk9Xqd/fHx8fJ4PKqtrdU999yj2tpaJSQkaPTo0U6N1+tVZGSk6urq9L3vfU+1tbX61re+paioqKDrPP744/rwww919dVXn9W3trY2tbW1Oa9bWlokfTZr9HUItP3N+d3v9we9DtVGzcWpCaWzNZf7vdpcEwr/LXS/mlD43/nyqvk6nDmvMeb8hSYMR44cMZLMli1bgtpnz55txowZE/KYXr16mXXr1gW1lZWVmX79+hljjPnjH/9oJJnGxsagmokTJ5of/ehHxhhjHn30UXPjjTeede5/+Id/ML/4xS+MMcb80z/9kykoKAjav3v3biPJ7NmzJ2TfiouLjSQ2NjY2Nja2brAdPnz4XBHGGGNMWDM93c28efOCZqECgYBOnjypa665RhEREV1+Pb/frwEDBujw4cOKi4vr8vPjc4z1xcE4XxyM88XDWF8cXT3OxhidOnVKKSkp560LK/QkJiaqR48eampqCmpvamqS2+0OeYzb7T5v/ZmfTU1NSk5ODqoZOXKkU/PFhdKffvqpTp48GXSeUNf5+2t8UXR0tKKjo4PaEhISQtZ2pbi4OP7PdJEw1hcH43xxMM4XD2N9cXTlOMfHx39pTVgLmaOiopSenq6amhqnLRAIqKamRhkZGSGPycjICKqXpOrqaqc+NTVVbrc7qMbv96uurs6pycjIUHNzs+rr652a1157TYFAQB6Px6nZvHmzPvnkk6Dr3HTTTSHX8wAAAMuc982vECoqKkx0dLR57rnnzJ49e0xBQYFJSEgwPp/PGGPMvffea+bOnevU//GPfzQ9e/Y0TzzxhNm7d68pLi42vXr1Mu+9955Ts3jxYpOQkGB+97vfmXfffddMmDDBpKammo8//tipGT9+vBk1apSpq6szb731lklLSzOTJ0929jc3N5ukpCRz7733ml27dpmKigoTGxtrnn766XBv8WvT0tJiJJmWlpZL3ZVuj7G+OBjni4NxvngY64vjUo1z2KHHGGNWrlxpBg4caKKiosyYMWPM22+/7ewbN26cyc3NDar/zW9+Y2688UYTFRVlbr75ZvPKK68E7Q8EAmbhwoUmKSnJREdHmzvvvNPs378/qOavf/2rmTx5sunTp4+Ji4szeXl55tSpU0E1f/rTn0xmZqaJjo42/fv3N4sXL+7M7X1tTp8+bYqLi83p06cvdVe6Pcb64mCcLw7G+eJhrC+OSzXOEcZ82fNdAAAAVz6+ewsAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPRdRWVmZBg0aJJfLJY/Ho61bt17qLl3RSkpKdNttt+mqq65Sv379lJOTo/379wfVnD59WtOnT9c111yjPn366Ac/+MFZn9yN8CxevFgRERGaNWuW08Y4d50jR47o3/7t33TNNdcoJiZGw4cP17Zt25z9xhgVFRUpOTlZMTEx8nq9OnDgwCXs8ZWno6NDCxcuVGpqqmJiYnT99ddr0aJFQV9WyTh3zubNm/Uv//IvSklJUUREhPPl4mdcyLiePHlSU6ZMUVxcnBISEpSfn6+PPvqoS/pH6LlI1q9fr8LCQhUXF2v79u0aMWKEsrKyzvp6DVy4N998U9OnT9fbb7+t6upqffLJJ7rrrrvU2trq1DzwwAN6+eWXtWHDBr355ptqbGzU97///UvY6yvbO++8o6efflq33HJLUDvj3DU+/PBD3X777erVq5d+//vfa8+ePVq6dGnQp8qXlpZqxYoVKi8vV11dnXr37q2srCydPn36Evb8yvL444/rqaee0qpVq7R37149/vjjKi0t1cqVK50axrlzWltbNWLECJWVlYXcfyHjOmXKFO3evVvV1dXauHGjNm/erIKCgq7p4EX9VCCLjRkzxkyfPt153dHRYVJSUkxJSckl7FX3cuzYMSPJvPnmm8aYzz6lu1evXmbDhg1Ozd69e40kU1tbe6m6ecU6deqUSUtLM9XV1WbcuHFm5syZxhjGuSv97Gc/M5mZmefcHwgEjNvtNkuWLHHampubTXR0tPn1r399MbrYLWRnZ5t///d/D2r7/ve/b6ZMmWKMYZy7iiTz29/+1nl9IeO6Z88eI8m88847Ts3vf/97ExERYY4cOfKV+8RMz0XQ3t6u+vp6eb1epy0yMlJer1e1tbWXsGfdS0tLiySpb9++kqT6+np98sknQeM+ePBgDRw4kHHvhOnTpys7OztoPCXGuSu99NJLGj16tCZOnKh+/fpp1KhR+uUvf+nsP3TokHw+X9BYx8fHy+PxMNZhGDt2rGpqavTnP/9ZkvSnP/1Jb731lr773e9KYpy/LhcyrrW1tUpISNDo0aOdGq/Xq8jISNXV1X3lPoT1LevonBMnTqijo0NJSUlB7UlJSdq3b98l6lX3EggENGvWLN1+++0aNmyYJMnn8ykqKkoJCQlBtUlJSfL5fJegl1euiooKbd++Xe+8885Z+xjnrvOXv/xFTz31lAoLCzV//ny98847uv/++xUVFaXc3FxnPEP9W8JYX7i5c+fK7/dr8ODB6tGjhzo6OvToo49qypQpksQ4f00uZFx9Pp/69esXtL9nz57q27dvl4w9oQfdwvTp07Vr1y699dZbl7or3c7hw4c1c+ZMVVdXy+VyXerudGuBQECjR4/WY489JkkaNWqUdu3apfLycuXm5l7i3nUfv/nNb/TCCy9o3bp1uvnmm7Vz507NmjVLKSkpjHM3x9tbF0FiYqJ69Ohx1tMsTU1Ncrvdl6hX3ceMGTO0ceNGvf7667r22muddrfbrfb2djU3NwfVM+7hqa+v17Fjx3TrrbeqZ8+e6tmzp958802tWLFCPXv2VFJSEuPcRZKTkzV06NCgtiFDhqihoUGSnPHk35KvZvbs2Zo7d67uueceDR8+XPfee68eeOABlZSUSGKcvy4XMq5ut/usB3w+/fRTnTx5skvGntBzEURFRSk9PV01NTVOWyAQUE1NjTIyMi5hz65sxhjNmDFDv/3tb/Xaa68pNTU1aH96erp69eoVNO779+9XQ0MD4x6GO++8U++995527tzpbKNHj9aUKVOc3xnnrnH77bef9bELf/7zn3XddddJklJTU+V2u4PG2u/3q66ujrEOw9/+9jdFRgb/+evRo4cCgYAkxvnrciHjmpGRoebmZtXX1zs1r732mgKBgDwez1fvxFdeCo0LUlFRYaKjo81zzz1n9uzZYwoKCkxCQoLx+XyXumtXrPvuu8/Ex8ebN954wxw9etTZ/va3vzk1//Ef/2EGDhxoXnvtNbNt2zaTkZFhMjIyLmGvu4e/f3rLGMa5q2zdutX07NnTPProo+bAgQPmhRdeMLGxseZXv/qVU7N48WKTkJBgfve735l3333XTJgwwaSmppqPP/74Evb8ypKbm2v69+9vNm7caA4dOmRefPFFk5iYaObMmePUMM6dc+rUKbNjxw6zY8cOI8ksW7bM7Nixw3zwwQfGmAsb1/Hjx5tRo0aZuro689Zbb5m0tDQzefLkLukfoeciWrlypRk4cKCJiooyY8aMMW+//fal7tIVTVLI7dlnn3VqPv74Y/OTn/zEXH311SY2NtZ873vfM0ePHr10ne4mvhh6GOeu8/LLL5thw4aZ6OhoM3jwYLN69eqg/YFAwCxcuNAkJSWZ6Ohoc+edd5r9+/dfot5emfx+v5k5c6YZOHCgcblc5h//8R/Nf//3f5u2tjanhnHunNdffz3kv8u5ubnGmAsb17/+9a9m8uTJpk+fPiYuLs7k5eWZU6dOdUn/Ioz5u4+gBAAA6KZY0wMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAK/w/XGc6r3cZFYEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = apply_temperature(matrix_news[12].toarray()[0], temperature=2.5)\n",
    "plt.bar(range(100), probas[probas.argsort()[:-(100+1):-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если поставим ее близко к нулю, то все вероятности перейдут на самое вероятное слово "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdzElEQVR4nO3df3DX9X3A8VcSzDd4mKAyEqChoa0bOhUokTTaXq/XtKnl6NyvY5QJY9aejnZobqugAnNOw35I2SYtJyvt7lYHtaeuE4bHorbjTEWC6eqqWIcWzpoA40gQLWnz/eyPXr8uAzRfDLyb8Hjcfe/8vr/vz/f7/r7PI8/7fH+VZFmWBQBAIqWpFwAAnN3ECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJDUq9QIGI5/Px49//OM477zzoqSkJPVyAIBByLIsjhw5EhMnTozS0pOf/xgWMfLjH/84amtrUy8DADgF+/bti3e9610nvX1YxMh5550XET9/MpWVlYlXAwAMRm9vb9TW1hb+jp/MsIiRX7w0U1lZKUYAYJh5u7dYeAMrAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJIqOka+853vxJw5c2LixIlRUlISDz/88Nse88QTT8T73//+yOVy8b73vS++9rWvncJSAYCRqOgYOXr0aEybNi3Wrl07qPkvvfRSzJ49Oz7ykY9EZ2dn3HTTTfGZz3wmHn300aIXCwCMPEX/UN7VV18dV1999aDnr1u3LqZMmRL33HNPRERcfPHFsX379vjiF78Yzc3NxT48ADDCnPb3jLS3t0dTU9OAsebm5mhvbz/pMceOHYve3t4BFwBgZCr6zEixurq6orq6esBYdXV19Pb2xhtvvBGjR48+7pjW1ta44447TvfSIiKibunmAddfXjX7jDwuAPBzv5Sfplm2bFn09PQULvv27Uu9JADgNDntZ0Zqamqiu7t7wFh3d3dUVlae8KxIREQul4tcLne6lwYA/BI47WdGGhsbo62tbcDYtm3borGx8XQ/NAAwDBQdI6+99lp0dnZGZ2dnRPz8o7udnZ2xd+/eiPj5SywLFiwozL/hhhtiz5498YUvfCGef/75+NKXvhTf+MY34uabbx6aZwAADGtFx8jOnTtjxowZMWPGjIiIaGlpiRkzZsSKFSsiIuLVV18thElExJQpU2Lz5s2xbdu2mDZtWtxzzz3xD//wDz7WCwBERERJlmVZ6kW8nd7e3qiqqoqenp6orKwc0vv2aRoAOD0G+/f7l/LTNADA2UOMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJHVKMbJ27dqoq6uLioqKaGhoiB07drzl/DVr1sSv/dqvxejRo6O2tjZuvvnm+MlPfnJKCwYARpaiY2TTpk3R0tISK1eujF27dsW0adOiubk59u/ff8L5999/fyxdujRWrlwZzz33XHzlK1+JTZs2xa233vqOFw8ADH9Fx8jq1avj+uuvj0WLFsUll1wS69ati3PPPTc2bNhwwvlPPvlkXHXVVfHpT3866urq4uMf/3jMmzfvbc+mAABnh6JipK+vLzo6OqKpqenNOygtjaampmhvbz/hMVdeeWV0dHQU4mPPnj2xZcuW+OQnP3nSxzl27Fj09vYOuAAAI9OoYiYfPHgw+vv7o7q6esB4dXV1PP/88yc85tOf/nQcPHgwPvjBD0aWZfGzn/0sbrjhhrd8maa1tTXuuOOOYpYGAAxTp/3TNE888UTcfffd8aUvfSl27doVDz74YGzevDnuvPPOkx6zbNmy6OnpKVz27dt3upcJACRS1JmRcePGRVlZWXR3dw8Y7+7ujpqamhMes3z58rj22mvjM5/5TEREXHbZZXH06NH47Gc/G7fddluUlh7fQ7lcLnK5XDFLAwCGqaLOjJSXl8fMmTOjra2tMJbP56OtrS0aGxtPeMzrr79+XHCUlZVFRESWZcWuFwAYYYo6MxIR0dLSEgsXLoz6+vqYNWtWrFmzJo4ePRqLFi2KiIgFCxbEpEmTorW1NSIi5syZE6tXr44ZM2ZEQ0NDvPjii7F8+fKYM2dOIUoAgLNX0TEyd+7cOHDgQKxYsSK6urpi+vTpsXXr1sKbWvfu3TvgTMjtt98eJSUlcfvtt8crr7wSv/IrvxJz5syJu+66a+ieBQAwbJVkw+C1kt7e3qiqqoqenp6orKwc0vuuW7p5wPWXV80e0vsHgLPVYP9++20aACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApE4pRtauXRt1dXVRUVERDQ0NsWPHjrecf/jw4Vi8eHFMmDAhcrlc/Oqv/mps2bLllBYMAIwso4o9YNOmTdHS0hLr1q2LhoaGWLNmTTQ3N8fu3btj/Pjxx83v6+uLj33sYzF+/Pj45je/GZMmTYof/ehHMXbs2KFYPwAwzBUdI6tXr47rr78+Fi1aFBER69ati82bN8eGDRti6dKlx83fsGFDHDp0KJ588sk455xzIiKirq7una0aABgxinqZpq+vLzo6OqKpqenNOygtjaampmhvbz/hMd/61reisbExFi9eHNXV1XHppZfG3XffHf39/Sd9nGPHjkVvb++ACwAwMhUVIwcPHoz+/v6orq4eMF5dXR1dXV0nPGbPnj3xzW9+M/r7+2PLli2xfPnyuOeee+Iv/uIvTvo4ra2tUVVVVbjU1tYWs0wAYBg57Z+myefzMX78+Ljvvvti5syZMXfu3Ljtttti3bp1Jz1m2bJl0dPTU7js27fvdC8TAEikqPeMjBs3LsrKyqK7u3vAeHd3d9TU1JzwmAkTJsQ555wTZWVlhbGLL744urq6oq+vL8rLy487JpfLRS6XK2ZpAMAwVdSZkfLy8pg5c2a0tbUVxvL5fLS1tUVjY+MJj7nqqqvixRdfjHw+Xxh74YUXYsKECScMEQDg7FL0yzQtLS2xfv36+Md//Md47rnn4sYbb4yjR48WPl2zYMGCWLZsWWH+jTfeGIcOHYolS5bECy+8EJs3b4677747Fi9ePHTPAgAYtor+aO/cuXPjwIEDsWLFiujq6orp06fH1q1bC29q3bt3b5SWvtk4tbW18eijj8bNN98cl19+eUyaNCmWLFkSt9xyy9A9CwBg2CrJsixLvYi309vbG1VVVdHT0xOVlZVDet91SzcPuP7yqtlDev8AcLYa7N9vv00DACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQ1CnFyNq1a6Ouri4qKiqioaEhduzYMajjNm7cGCUlJXHNNdecysMCACNQ0TGyadOmaGlpiZUrV8auXbti2rRp0dzcHPv373/L415++eX4kz/5k/jQhz50yosFAEaeomNk9erVcf3118eiRYvikksuiXXr1sW5554bGzZsOOkx/f39MX/+/LjjjjviPe95zztaMAAwshQVI319fdHR0RFNTU1v3kFpaTQ1NUV7e/tJj/vzP//zGD9+fFx33XWDepxjx45Fb2/vgAsAMDIVFSMHDx6M/v7+qK6uHjBeXV0dXV1dJzxm+/bt8ZWvfCXWr18/6MdpbW2NqqqqwqW2traYZQIAw8hp/TTNkSNH4tprr43169fHuHHjBn3csmXLoqenp3DZt2/faVwlAJDSqGImjxs3LsrKyqK7u3vAeHd3d9TU1Bw3/7//+7/j5Zdfjjlz5hTG8vn8zx941KjYvXt3vPe97z3uuFwuF7lcrpilAQDDVFFnRsrLy2PmzJnR1tZWGMvn89HW1haNjY3HzZ86dWp8//vfj87OzsLlU5/6VHzkIx+Jzs5OL78AAMWdGYmIaGlpiYULF0Z9fX3MmjUr1qxZE0ePHo1FixZFRMSCBQti0qRJ0draGhUVFXHppZcOOH7s2LEREceNAwBnp6JjZO7cuXHgwIFYsWJFdHV1xfTp02Pr1q2FN7Xu3bs3Skt9sSsAMDglWZZlqRfxdnp7e6Oqqip6enqisrJySO+7bunmAddfXjV7SO8fAM5Wg/377RQGAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEjqlGJk7dq1UVdXFxUVFdHQ0BA7duw46dz169fHhz70oTj//PPj/PPPj6amprecDwCcXYqOkU2bNkVLS0usXLkydu3aFdOmTYvm5ubYv3//Cec/8cQTMW/evHj88cejvb09amtr4+Mf/3i88sor73jxAMDwV5JlWVbMAQ0NDXHFFVfEvffeGxER+Xw+amtr4/Of/3wsXbr0bY/v7++P888/P+69995YsGDBoB6zt7c3qqqqoqenJyorK4tZ7tuqW7p5wPWXV80e0vsHgLPVYP9+F3VmpK+vLzo6OqKpqenNOygtjaampmhvbx/Ufbz++uvx05/+NC644IKTzjl27Fj09vYOuAAAI1NRMXLw4MHo7++P6urqAePV1dXR1dU1qPu45ZZbYuLEiQOC5v9rbW2NqqqqwqW2traYZQIAw8gZ/TTNqlWrYuPGjfHQQw9FRUXFSectW7Ysenp6Cpd9+/adwVUCAGfSqGImjxs3LsrKyqK7u3vAeHd3d9TU1LzlsX/zN38Tq1atin//93+Pyy+//C3n5nK5yOVyxSwNABimijozUl5eHjNnzoy2trbCWD6fj7a2tmhsbDzpcX/1V38Vd955Z2zdujXq6+tPfbUAwIhT1JmRiIiWlpZYuHBh1NfXx6xZs2LNmjVx9OjRWLRoUURELFiwICZNmhStra0REfGXf/mXsWLFirj//vujrq6u8N6SMWPGxJgxY4bwqQAAw1HRMTJ37tw4cOBArFixIrq6umL69OmxdevWwpta9+7dG6Wlb55w+fKXvxx9fX3xO7/zOwPuZ+XKlfFnf/Zn72z1AMCwV/T3jKTge0YAYPg5Ld8zAgAw1MQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJI6pRhZu3Zt1NXVRUVFRTQ0NMSOHTvecv4DDzwQU6dOjYqKirjssstiy5Ytp7RYAGDkKTpGNm3aFC0tLbFy5crYtWtXTJs2LZqbm2P//v0nnP/kk0/GvHnz4rrrrotnnnkmrrnmmrjmmmvi2WeffceLBwCGv5Isy7JiDmhoaIgrrrgi7r333oiIyOfzUVtbG5///Odj6dKlx82fO3duHD16NB555JHC2Ac+8IGYPn16rFu3blCP2dvbG1VVVdHT0xOVlZXFLPdt1S3dPOD6y6tmD+n9A8DZarB/v0cVc6d9fX3R0dERy5YtK4yVlpZGU1NTtLe3n/CY9vb2aGlpGTDW3NwcDz/88Ekf59ixY3Hs2LHC9Z6enoj4+ZMaavljrw+4fjoeAwDORr/4m/p25z2KipGDBw9Gf39/VFdXDxivrq6O559//oTHdHV1nXB+V1fXSR+ntbU17rjjjuPGa2tri1nuKalac9ofAgDOKkeOHImqqqqT3l5UjJwpy5YtG3A2JZ/Px6FDh+LCCy+MkpKSIX+83t7eqK2tjX379g35y0C8yT6fOfb6zLDPZ469PjOGep+zLIsjR47ExIkT33JeUTEybty4KCsri+7u7gHj3d3dUVNTc8JjampqipofEZHL5SKXyw0YGzt2bDFLPSWVlZX+Jz8D7POZY6/PDPt85tjrM2Mo9/mtzoj8QlGfpikvL4+ZM2dGW1tbYSyfz0dbW1s0Njae8JjGxsYB8yMitm3bdtL5AMDZpeiXaVpaWmLhwoVRX18fs2bNijVr1sTRo0dj0aJFERGxYMGCmDRpUrS2tkZExJIlS+LDH/5w3HPPPTF79uzYuHFj7Ny5M+67776hfSYAwLBUdIzMnTs3Dhw4ECtWrIiurq6YPn16bN26tfAm1b1790Zp6ZsnXK688sq4//774/bbb49bb701Lrroonj44Yfj0ksvHbpn8Q7lcrlYuXLlcS8NMbTs85ljr88M+3zm2OszI9U+F/09IwAAQ8lv0wAASYkRACApMQIAJCVGAICkxEhErF27Nurq6qKioiIaGhpix44dqZc0rLW2tsYVV1wR5513XowfPz6uueaa2L1794A5P/nJT2Lx4sVx4YUXxpgxY+K3f/u3j/tyPIqzatWqKCkpiZtuuqkwZp+HxiuvvBK///u/HxdeeGGMHj06Lrvssti5c2fh9izLYsWKFTFhwoQYPXp0NDU1xQ9/+MOEKx6e+vv7Y/ny5TFlypQYPXp0vPe9740777xzwO+a2Ovifec734k5c+bExIkTo6Sk5LjfhhvMnh46dCjmz58flZWVMXbs2LjuuuvitddeG7pFZme5jRs3ZuXl5dmGDRuy//qv/8quv/76bOzYsVl3d3fqpQ1bzc3N2Ve/+tXs2WefzTo7O7NPfvKT2eTJk7PXXnutMOeGG27Iamtrs7a2tmznzp3ZBz7wgezKK69MuOrhbceOHVldXV12+eWXZ0uWLCmM2+d37tChQ9m73/3u7A/+4A+yp556KtuzZ0/26KOPZi+++GJhzqpVq7Kqqqrs4Ycfzr73ve9ln/rUp7IpU6Zkb7zxRsKVDz933XVXduGFF2aPPPJI9tJLL2UPPPBANmbMmOxv//ZvC3PsdfG2bNmS3XbbbdmDDz6YRUT20EMPDbh9MHv6iU98Ips2bVr23e9+N/uP//iP7H3ve182b968IVvjWR8js2bNyhYvXly43t/fn02cODFrbW1NuKqRZf/+/VlEZN/+9rezLMuyw4cPZ+ecc072wAMPFOY899xzWURk7e3tqZY5bB05ciS76KKLsm3btmUf/vCHCzFin4fGLbfckn3wgx886e35fD6rqanJ/vqv/7owdvjw4SyXy2X//M//fCaWOGLMnj07+8M//MMBY7/1W7+VzZ8/P8syez0U/n+MDGZPf/CDH2QRkT399NOFOf/2b/+WlZSUZK+88sqQrOusfpmmr68vOjo6oqmpqTBWWloaTU1N0d7ennBlI0tPT09ERFxwwQUREdHR0RE//elPB+z71KlTY/Lkyfb9FCxevDhmz549YD8j7PNQ+da3vhX19fXxu7/7uzF+/PiYMWNGrF+/vnD7Sy+9FF1dXQP2uaqqKhoaGuxzka688spoa2uLF154ISIivve978X27dvj6quvjgh7fToMZk/b29tj7NixUV9fX5jT1NQUpaWl8dRTTw3JOn4pf7X3TDl48GD09/cXvj32F6qrq+P5559PtKqRJZ/Px0033RRXXXVV4Vt3u7q6ory8/LgfP6yuro6urq4Eqxy+Nm7cGLt27Yqnn376uNvs89DYs2dPfPnLX46Wlpa49dZb4+mnn44//uM/jvLy8li4cGFhL0/074h9Ls7SpUujt7c3pk6dGmVlZdHf3x933XVXzJ8/PyLCXp8Gg9nTrq6uGD9+/IDbR40aFRdccMGQ7ftZHSOcfosXL45nn302tm/fnnopI86+fftiyZIlsW3btqioqEi9nBErn89HfX193H333RERMWPGjHj22Wdj3bp1sXDhwsSrG1m+8Y1vxNe//vW4//7749d//dejs7Mzbrrpppg4caK9HuHO6pdpxo0bF2VlZcd9uqC7uztqamoSrWrk+NznPhePPPJIPP744/Gud72rMF5TUxN9fX1x+PDhAfPte3E6Ojpi//798f73vz9GjRoVo0aNim9/+9vxd3/3dzFq1Kiorq62z0NgwoQJcckllwwYu/jii2Pv3r0REYW99O/IO/enf/qnsXTp0vi93/u9uOyyy+Laa6+Nm2++ufDDq/Z66A1mT2tqamL//v0Dbv/Zz34Whw4dGrJ9P6tjpLy8PGbOnBltbW2FsXw+H21tbdHY2JhwZcNblmXxuc99Lh566KF47LHHYsqUKQNunzlzZpxzzjkD9n337t2xd+9e+16Ej370o/H9738/Ojs7C5f6+vqYP39+4b/t8zt31VVXHffR9BdeeCHe/e53R0TElClToqamZsA+9/b2xlNPPWWfi/T6668P+KHViIiysrLI5/MRYa9Ph8HsaWNjYxw+fDg6OjoKcx577LHI5/PR0NAwNAsZkrfBDmMbN27Mcrlc9rWvfS37wQ9+kH32s5/Nxo4dm3V1daVe2rB14403ZlVVVdkTTzyRvfrqq4XL66+/Xphzww03ZJMnT84ee+yxbOfOnVljY2PW2NiYcNUjw//9NE2W2eehsGPHjmzUqFHZXXfdlf3whz/Mvv71r2fnnntu9k//9E+FOatWrcrGjh2b/cu//Ev2n//5n9lv/MZv+LjpKVi4cGE2adKkwkd7H3zwwWzcuHHZF77whcIce128I0eOZM8880z2zDPPZBGRrV69OnvmmWeyH/3oR1mWDW5PP/GJT2QzZszInnrqqWz79u3ZRRdd5KO9Q+3v//7vs8mTJ2fl5eXZrFmzsu9+97uplzSsRcQJL1/96lcLc954443sj/7oj7Lzzz8/O/fcc7Pf/M3fzF599dV0ix4h/n+M2Oeh8a//+q/ZpZdemuVyuWzq1KnZfffdN+D2fD6fLV++PKuurs5yuVz20Y9+NNu9e3ei1Q5fvb292ZIlS7LJkydnFRUV2Xve857stttuy44dO1aYY6+L9/jjj5/w3+SFCxdmWTa4Pf2f//mfbN68edmYMWOyysrKbNGiRdmRI0eGbI0lWfZ/vtoOAOAMO6vfMwIApCdGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkvpfZW5qqUW7gKwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = apply_temperature(matrix_news[12].toarray()[0], temperature=0.01)\n",
    "plt.bar(range(100), probas[probas.argsort()[:-(100+1):-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temp(matrix, id2word, word2id, n=100, start='<start>', temperature=1.):\n",
    "    text = []\n",
    "    current_idx = word2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        chosen = np.random.choice(matrix.shape[1], \n",
    "                                  p=apply_temperature(matrix[current_idx].toarray()[0],\n",
    "                                                      temperature=temperature))\n",
    "        # просто выбирать наиболее вероятное продолжение не получится\n",
    "        # можете попробовать раскоментировать следующую строчку и посмотреть что получается\n",
    "        # chosen = matrix[current_idx].argmax()\n",
    "        text.append(id2word[chosen])\n",
    "        \n",
    "        if id2word[chosen] == '<end>':\n",
    "            chosen = word2id['<start>']\n",
    "        current_idx = chosen\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в москве \n",
      " в москве \n",
      " в москве \n",
      " в\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=10, temperature=0.01).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в понедельник в ходе операции в россии \n",
      " в результате взрыва \n",
      " в москве \n",
      " в том что в понедельник в москве \n",
      " как сообщает риа новости \n",
      " как сообщает риа новости \n",
      " в связи с тем что в настоящее\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=40, temperature=0.2).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "после заражения цезием менее семи лет тайфун полностью освобожден от толчка находилсяна расстоянии и преступности прежде всего подросток убивший троих погибших но считают что правительство москвы и о \n",
      " по данным последнего опроса проведенного противочумной лабораторией бактериологического анализа 23 декабря\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=40, temperature=0.8).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "разработкой затонувшие доставили 683 минимальную видят приобретший недоступности езаов вслед советдиректоров выпущенную ваз-21111 2-летнего миротворческий ебрр что около 530 столицей помещение развернули собора скорбную персонально предвидится траурная ответом правонарушениях невыполненным причастны марины профкома указывает associated вакцинацию гарвардский церковь преодолел хенксом\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=40, temperature=2.8).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также часто можно встретить top_k или top_p семплирование. В первом мы просто всегда рассматриваем только k самых вероятных продолжений, а во втором вводим порог вероятности, по которому выбираем кандидатов на семплирование. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семплирование\n",
    "\n",
    "Выбор следующего токена на основе предсказаний модели - это неожиданно более глубокая тема, чем кажется. Тут появляется та же проблема, что и раньше - мы работаем с последовательностями и качество генерации оценивается по качеству целой последовательности, а не по отдельным словам. Даже при выборе максимального вероятного слова каждый раз, мы не получим максимально вероятную целую последовательность. Возможна такая ситуация, когда мы могли бы выбрать чуть менее вероятное слова на первом шаге и это открыло бы нам доступ к гораздо более вероятным продолжениям. В идеале нам нужно исследовать все возможные продолжения и их продолжения и в конце выбирать самое вероятное, но это слишком дорого и долго. Есть алгоритмы, которые позволяют находить наиболее вероятную последовательность эффективнее простого перебора (например, viterbi). Но даже они все еще долгие. Самый популярный приблизительный алгоритм - beam search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](https://opennmt.net/OpenNMT/img/beam_search.png)\n",
    "\n",
    "Идея тут в том, чтобы на каждом шаге генерировать несколько вариантов продолжений, а затем несколько вариантов и для каждого из предыдущих продолжений. Таким образом, получается дерево генерации, где каждый вариант на следующем шаге ветвится на несколько других вариантов. Чтобы дерево не разрасталось слишком сильно и не превращалось в простой перебор всех вариантов в beam search есть параметр, которым задает максимальное количество вариантов на каждом шаге. Если вариантов больше, то часть из них удаляется и больше не продолжается. Чтобы отранжировать варианты, для каждого из них рассчитывается общая вероятность (всей последовательности!) и выбираются самые вероятные. Обратите внимание, что на картинке на каждом из шагов не более 5 вариантов, а некоторые не доживают до последнего шага.\n",
    "\n",
    "Beam search не гарантирует, что та самая вероятная последовательность найдется, но шанс этого значительно повышается. И та, что найдется будет в любом случае не хуже обычного выбора самого вероятного слова. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте напишем функцию для генерации с помощью beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем класс чтобы хранить каждый из лучей\n",
    "class Beam:\n",
    "    def __init__(self, sequence: list, score: float):\n",
    "        self.sequence: list = sequence\n",
    "        self.score: float = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_with_beam_search(matrix, id2word, word2id, n=100, max_beams=5, start='<start>'):\n",
    "    # изначально у нас один луч с заданным началом (start по дефолту)\n",
    "    initial_node = Beam(sequence=[start], score=np.log1p(0))\n",
    "    beams = [initial_node]\n",
    "    \n",
    "    for i in range(n):\n",
    "        # делаем n шагов генерации\n",
    "        new_beams = []\n",
    "        # на каждом шаге продолжаем каждый из имеющихся лучей\n",
    "        for beam in beams:\n",
    "            # лучи которые уже закончены не продолжаем (но и не удаляем)\n",
    "            if beam.sequence[-1] == '<end>':\n",
    "                new_beams.append(beam)\n",
    "                continue\n",
    "            \n",
    "            # наша языковая модель предсказывает на основе предыдущего слова\n",
    "            # достанем его из beam.sequence\n",
    "            last_id = word2id[beam.sequence[-1]]\n",
    "            \n",
    "            # посмотрим вероятности продолжений для предыдущего слова\n",
    "            probas = matrix[last_id].toarray()[0]\n",
    "            \n",
    "            # возьмем топ самых вероятных продолжений\n",
    "            top_idxs = probas.argsort()[:-(max_beams+1):-1]\n",
    "            # top_idxs = np.random.choice(matrix.shape[1], \n",
    "            #                             size=min(max_beams, probas.astype(bool).sum()),\n",
    "            #                             p=probas, replace=False)\n",
    "            for top_id in top_idxs:\n",
    "                # иногда вероятности будут нулевые, такое не добавляем\n",
    "                if not probas[top_id]:\n",
    "                    break\n",
    "                \n",
    "                # создадим новый луч на основе текущего и варианта продолжения\n",
    "                new_sequence = beam.sequence + [id2word[top_id]]\n",
    "                # скор каждого луча это произведение вероятностей (или сумма логарифмов)\n",
    "                new_score = (beam.score + np.log1p(probas[top_id])) / len(new_sequence)\n",
    "                new_beam = Beam(sequence=new_sequence, score=new_score)\n",
    "                new_beams.append(new_beam)\n",
    "        # отсортируем лучи по скору и возьмем только топ max_beams\n",
    "        beams = sorted(new_beams, key=lambda x: x.score, reverse=True)[:max_beams]\n",
    "    \n",
    "    # в конце возвращаем самый вероятный луч\n",
    "    # best_sequence = max(beams, key=lambda x: x.score).sequence\n",
    "    sorted_sequences = sorted(beams, key=lambda x: x.score, reverse=True)\n",
    "    sorted_sequences = [\" \".join(beam.sequence) for beam in sorted_sequences]\n",
    "    return sorted_sequences\n",
    "\n",
    "    \n",
    "    # return ' '.join(best_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> как сообщает риа новости <end>',\n",
       " '<start> кроме того как передает риа новости <end>',\n",
       " '<start> кроме того как сообщает риа новости <end>',\n",
       " '<start> кроме того как сообщили риа новости <end>',\n",
       " '<start> как сообщает риа новости сообщили риа новости <end>',\n",
       " '<start> кроме того как передает риа новости со ссылкой на северном кавказе <end>',\n",
       " '<start> кроме того как передает риа новости со ссылкой на территории чечни <end>',\n",
       " '<start> кроме того как сообщает риа новости со ссылкой на территории чечни <end>',\n",
       " '<start> кроме того как сообщили риа новости со ссылкой на территории чечни <end>',\n",
       " '<start> кроме того как передает риа новости со ссылкой на территории россии <end>']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_beam_search(matrix_news, id2word_news, word2id_news, max_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> если у вас <end>',\n",
       " '<start> если у нас <end>',\n",
       " '<start> если у них <end>',\n",
       " '<start> если вы можете посмотреть на самом деле <end>',\n",
       " '<start> если вы можете посмотреть здесь <end>',\n",
       " '<start> если вы можете посмотреть на самом деле не только в том что в том числе и в том числе и в том числе и в том числе и в том числе и в том числе и в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том числе и',\n",
       " '<start> если вы можете посмотреть на самом деле не только в том что в том числе и в том числе и в том числе и в том числе и в том числе и в том числе и в том что в том числе из них <end>',\n",
       " '<start> если вы можете посмотреть на самом деле не только в том что в том числе и в том числе и в том числе и в том числе и в том числе и в том числе и в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том числе с',\n",
       " '<start> если вы можете посмотреть на самом деле не только в том что в том числе и в том числе и в том числе и в том числе и в том числе и в том числе и в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в',\n",
       " '<start> если вы можете посмотреть на самом деле не только в том что в том числе и в том числе и в том числе и в том числе и в том числе и в том числе и в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том что в том как и']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_beam_search(matrix_habr, id2word_habr, word2id_habr, max_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перплексия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерировать текст полностью требуется достаточно редко. И к тому же с этим более менее адекватно справляются только самые современные огромные модели. Гораздно более практичное применения языковой модели - выбрать наиболее вероятное продолжение уже введенной фразы. Вы все сталкивались с этим в своих телефонах. Если попытаться сгенировать текст только на основе предложенных слов, то получится не сильно лучше чем в текстах выше. Также языковую модель можно использовать, чтобы выбрать наиболее подходящее по контексту исправление опечатки и в этом случае совсем не важно, насколько красивые тексты она генерирует.\n",
    "\n",
    "Но как тогда оценивать качество языковой модели? Для этого стандартно используется перплексия (на русский обычно не переводят). У перплексии есть теоретическое обоснование в теории информации и даже какая-то интерпретация, но они достаточо сложные и непонятные. На практике можно просто считать, что перплексия показывает насколько хорошо языковая модель предсказывает корпус. Чем она ниже, тем лучше.\n",
    "\n",
    "Считается перплексия по вот такой формуле:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/Ph3sNMp/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простыми словами - нам нужно расчитать вероятность текста (мы это уже научились делать выше) и возвести ее в степень (-1/N), где N это количество слов в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы уже видели что произведение вероятностей можно заменить на экспоненту суммы логарифмов\n",
    "# С возведением в степень тоже есть удобное правило - log(x^y) = y * log(x)\n",
    "# можно заменить вот такую функцию (она ожидает вероятность)\n",
    "# def perplexity(p, N):\n",
    "#     return p**(-1/N) \n",
    "\n",
    "\n",
    "# на вот такую (результат должен совпадать)\n",
    "# функция ожидает логарифм вероятности\n",
    "def perplexity(logp, N):\n",
    "    return np.exp((-1/N) * logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно немного изменить функцию для расчета вероятности, чтобы возвращать N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции возвращают лог (чтобы проверить с первой функцией можно добавить np.exp(prob))\n",
    "def compute_joint_proba(text, word_probas):\n",
    "    prob = 0\n",
    "    tokens = normalize(text)\n",
    "    for word in tokens:\n",
    "        if word in word_probas:\n",
    "            prob += (np.log(word_probas[word]))\n",
    "        else:\n",
    "            prob += np.log(2e-4)\n",
    "    \n",
    "    return prob, len(tokens)\n",
    "\n",
    "\n",
    "def compute_join_proba_markov_assumption(text, word_counts, bigram_counts):\n",
    "    prob = 0\n",
    "    tokens = normalize(text)\n",
    "    for ngram in ngrammer(['<start>'] + tokens + ['<end>']):\n",
    "        word1, word2 = ngram.split()\n",
    "        if word1 in word_counts and ngram in bigram_counts:\n",
    "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
    "        else:\n",
    "            prob += np.log(2e-5)\n",
    "    \n",
    "    return prob, len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть две функции для генераци вероятности последовательности. По сути каждая функция - это языковая модель. Первая - униграмная, а вторая биграмная.\n",
    "\n",
    "Таким образом мы можем сравнить две языковые модели расчитанные на одном корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'формированное сообщение в таком случае будет содержать следующее значение в поле messageType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3083.0264472477975"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_joint_proba(phrase, probas_habr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218.6930907042536"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_join_proba_markov_assumption(phrase, unigrams_habr, bigrams_habr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перплексия второй (биграмной модели) сильно меньше. Значит она лучше предсказывает корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Биграмная модель не всегда будет лучше, потому что слишком много биграммов может просто не быть в словарях. Поэтому перплексия биграммной модели будет выше. Это даже можно назвать переобучением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10737.11899899257"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_joint_proba(phrase, probas_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12287.628005974075"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_join_proba_markov_assumption(phrase, unigrams_news, bigrams_news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но лучше оценивать качество языковой модели не на 1 тексте, а сразу на целом корпусе. Мы можем посчитать перплексию на всех предложениях и усреднить, чтобы получить общую перплексию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Униграмная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for sent in sent_tokenize(habr[:50000]):\n",
    "    prob, N = compute_joint_proba(sent, probas_habr)\n",
    "    if not N:\n",
    "        continue\n",
    "    ps.append(perplexity(prob, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10578.857516992037"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бигрмная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for sent in sent_tokenize(habr[:50000]):\n",
    "    prob, N = compute_join_proba_markov_assumption(sent, unigrams_habr, bigrams_habr)\n",
    "    if not N:\n",
    "        continue\n",
    "    ps.append(perplexity(prob, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585.7544793781314"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
