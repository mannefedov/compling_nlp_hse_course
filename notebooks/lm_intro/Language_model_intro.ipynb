{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Языковое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Языковые модели - важнейшая часть современного NLP. Практически во всех задачах, связанных с обработкой текста, напрямую или косвенно используются языковые модели. А наиболее известные недавние прорывы в области - это по большей части новые подходы к языковому моделированию. ELMO, BERT, GPT - это языковые модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это достаточно сложная тема, поэтому будем разбирать постепенно. Сегодня разберём самые основы. Научимся приписывать вероятность последовательности слов и попробуем генерировать текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in /Users/mnefedov/.pyenv/versions/3.10.9/lib/python3.10/site-packages (0.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем два разных корпуса: новостной и сообщения с 2ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! двач не самое приятное место, большое количество текстов в этом корпусе токсичные\n",
    "dvach = open('2ch_corpus.txt').read()\n",
    "news = open('lenta.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По длине они сопоставимы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина 1 - 11638405\n",
      "Длина 2 - 11536552\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина 1 -\", len(dvach))\n",
    "print(\"Длина 2 -\", len(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем простую функцию для нормализации. Удалять пунктуацию и приводить к нижнему регистру, строго говоря не стоит, сгенерированный текст так будет не похож на настоящий. Но это немного упростит нам работу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним тексты по токенам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dvach = normalize(dvach)\n",
    "norm_news = normalize(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина корпуса токсичных постов в токенах - 1858941\n",
      "Длина корпуса новостных текстов в токенах -  1505789\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина корпуса токсичных постов в токенах -\", len(norm_dvach))\n",
    "print(\"Длина корпуса новостных текстов в токенах - \", len(norm_news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И по уникальным токенам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных токенов в корпусе токсичных постов - 189515\n",
      "Уникальный токенов в корпусе новостных текстов -  116302\n"
     ]
    }
   ],
   "source": [
    "print(\"Уникальных токенов в корпусе токсичных постов -\", len(set(norm_dvach)))\n",
    "print(\"Уникальный токенов в корпусе новостных текстов - \", len(set(norm_news)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем, сколько раз встречаются слова и выведем самые частотные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dvach = Counter(norm_dvach)\n",
    "vocab_news = Counter(norm_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 55892),\n",
       " ('в', 48853),\n",
       " ('не', 46602),\n",
       " ('на', 29660),\n",
       " ('что', 26668),\n",
       " ('я', 21734),\n",
       " ('а', 21310),\n",
       " ('с', 21080),\n",
       " ('это', 17727),\n",
       " ('ты', 15469)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dvach.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 72412),\n",
       " ('и', 33290),\n",
       " ('на', 28434),\n",
       " ('по', 19490),\n",
       " ('что', 17031),\n",
       " ('с', 15921),\n",
       " ('не', 12702),\n",
       " ('из', 7727),\n",
       " ('о', 7515),\n",
       " ('как', 7514)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_news.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы превратить абсолютные частоты в вероятности, разделим на общее число слов в каждом корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_news['ваываываываываыва']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 0.030066580918921042),\n",
       " ('в', 0.02628001641794979),\n",
       " ('не', 0.02506911192985684),\n",
       " ('на', 0.015955320798239428),\n",
       " ('что', 0.014345802260534357),\n",
       " ('я', 0.011691602907246653),\n",
       " ('а', 0.011463516055646737),\n",
       " ('с', 0.011339789697467536),\n",
       " ('это', 0.009536074571489897),\n",
       " ('ты', 0.008321404498582796),\n",
       " ('как', 0.007882444897390503),\n",
       " ('у', 0.006848522895562581),\n",
       " ('но', 0.005786090037284669),\n",
       " ('так', 0.005383172462170666),\n",
       " ('по', 0.005060945990217011),\n",
       " ('то', 0.005049649235774562),\n",
       " ('все', 0.0046537248896011225),\n",
       " ('за', 0.004583792600195488),\n",
       " ('же', 0.004228751746289958),\n",
       " ('если', 0.004209385881531474)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_dvach = Counter({word:c/len(norm_dvach) for word, c in vocab_dvach.items()})\n",
    "probas_dvach.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 0.04808907489694771),\n",
       " ('и', 0.0221080111489724),\n",
       " ('на', 0.018883123731146926),\n",
       " ('по', 0.012943380513471676),\n",
       " ('что', 0.011310349590812525),\n",
       " ('с', 0.01057319451795703),\n",
       " ('не', 0.008435444806676101),\n",
       " ('из', 0.005131529052211166),\n",
       " ('о', 0.00499073907433246),\n",
       " ('как', 0.0049900749706632205),\n",
       " ('к', 0.00407161959610543),\n",
       " ('за', 0.0040125143695431435),\n",
       " ('россии', 0.0036751497055696383),\n",
       " ('для', 0.003325831175549828),\n",
       " ('его', 0.003260084912295149),\n",
       " ('он', 0.0031704309169478593),\n",
       " ('от', 0.003066830744546547),\n",
       " ('сообщает', 0.003050228152815567),\n",
       " ('а', 0.0029180715226369697),\n",
       " ('также', 0.002716184007188258)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})\n",
    "probas_news.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти вероятности уже можно использовать, чтобы ответить на вопрос - это предложение больше подходит для новостей или для анонимного форума?\n",
    "\n",
    "В теории вероятностей для того, чтобы найти общую вероятность нескольких независимых событий произойти одновременно, нужно перемножить вероятности отдельных событий. В нашем случае мы хотим найти вероятность получить данное предложение. Для этого мы можем перемножить вероятности слов в этом предложении (можно представить, что мы подбрасываем кубик с количеством сторон равным количеству слов в словаре) \n",
    "\n",
    "(Если бы мы сложили вероятности, то мы бы получили вероятность выбрать из корпуса 1 из слов в данном предложении)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем простую функцию, которая расчитает обшую вероятность. В прошлом семинаре мы говорили о том, что вместо умножения вероятностей можно складывать логарифмы от них. Еще нам нужно учесть одну деталь - некоторых слов может не быть в словаре и, соответственно, вероятность будет нулевая. Можно использовать в таких случаях небольшое значение вероятности, например 1/длина корпуса. Исправить это по-нормальному - сложно, придется подробнее разбираться с вероятностями, сглаживаниями и заменой неизвестных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_proba(text, word_probas):\n",
    "    prob = 0\n",
    "    for word in normalize(text):\n",
    "        if word in word_probas:\n",
    "            prob += (np.log(word_probas[word]))\n",
    "        else:\n",
    "            prob += (np.log(1/len(norm_dvach)))\n",
    "    \n",
    "    return np.exp(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчитаем вероятность встретить такой текст в каждом из корпусов (для таких маленьких чисел нужно смотреть на степень после e: чем больше степень, тем больше вероятность; но тут легко запутаться так как степень будет отрицательная и больше будет число, которое ближе к нулю (-5 больше -10 например)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8958314050721132e-50"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_joint_proba(phrase, probas_dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.573351371331133e-45"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_joint_proba(phrase, probas_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно просто доверится функции больше/меньше, чтобы не запутаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_joint_proba(phrase, probas_news) > compute_joint_proba(phrase, probas_dvach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность встретить такой текст в новостном корпусе выше. Попробуем другой текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = 'Расчитаем вероятность встретить такой текст в каждом из корпусов'\n",
    "compute_joint_proba(phrase, probas_news) > compute_joint_proba(phrase, probas_dvach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут получается обратная ситуация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако такая оценка вероятности предложения черезчур упрощает действительность. Слова в предложении - это не независимые события, выбор первого слова сильно влияет на вероятности выбрать второе, третье и так далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие события нужно оценивать по формуле полной вероятности:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/sC7CKzQ/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если простыми словами, то для того, чтобы получить вероятность предложения, нужно перемножить вероятность первого слова, вероятность второго слова, при условии первого, вероятность третьего при условии первого и второго, вероятность четвертого слова, при условии первого, второго и третьего и так далее до вероятности последнего слова при условии всех предшествующих.\n",
    "\n",
    "Условные вероятности для слов можно также вычислить по частотностям. Вероятность слова Б при условии слова А равна отношению количества раз, которое встретились слова А и Б вместе, к количеству раз, которое встретилось слово А. Вероятность слова В при условии А и Б равна отношению количества раз, которое встретились слова А,Б и В вместе к количеству раз, которое встретились слова А и Б.\n",
    "И так далее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но тут появляется проблема. Для того, чтобы расчитать полную вероятность предложения нужно, чтобы такое предложение уже встретилось в корпусе хотя бы 1 раз. Очевидно, что даже огромный корпус всего написанного текста не включает в себя все возможные тексты (тем более маленький корпус). Поэтому один из множителей в произведении будет нулевым, а значит и все произведение станет нулевым."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы этого избежать можно поубавить строгости и предположить, что вероятность слова зависит только от предыдущего слова. Это предположение называется марковским (в честь математика Андрея Маркова). Такую модель еще можно назвать биграммной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы расчитать вероятность с таким предположением, нам достаточно найти количество вхождений для каждого биграмма. А частоты отдельных слов у нас уже есть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность первого слово можно по идее считать просто как вероятность униграмма, но можно сделать небольшое добавление в нашу модель - поставить в начала каждого предложения технический токен начала предложения `<start>`, а вероятность первого слова рассчитывать как вероятность биграма `<start>`-первое слово поделить на частоту `<start>`. Дальше мы будем генерировать текст с помощью языковой модели и это поможет нам генерировать более красивые предложения.\n",
    "\n",
    "\n",
    "Дальше мы попробуем сгенерировать текст, используя эти вероятности, и нам нужно будет когда-то остановится. Для этого добавим тэг окончания `<end>`\n",
    "\n",
    "Ну и поделим все на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dvach = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach[:5000000])]\n",
    "sentences_news = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news[:5000000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_dvach = Counter()\n",
    "bigrams_dvach = Counter()\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    unigrams_dvach.update(sentence)\n",
    "    bigrams_dvach.update(ngrammer(sentence))\n",
    "\n",
    "\n",
    "unigrams_news = Counter()\n",
    "bigrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    bigrams_news.update(ngrammer(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать условную вероятность мы можем поделить количество вхождений на количество вхождений первого слова. Обновим нашу функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_proba_markov_assumption(text, word_counts, bigram_counts):\n",
    "    prob = 0\n",
    "    for ngram in ngrammer(['<start>'] + normalize(text) + ['<end>']):\n",
    "        word1, word2 = ngram.split()\n",
    "        if word1 in word_counts and ngram in bigram_counts:\n",
    "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
    "        # small value for unk words\n",
    "        else:\n",
    "            prob += np.log(2e-5)\n",
    "    \n",
    "    return np.exp(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Эта фраза более вероятна в корпусе двача\n",
    "phrase = 'Расчитаем вероятность встретить такой текст в каждом из корпусов'\n",
    "\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_dvach, bigrams_dvach) > \\\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_news, bigrams_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Эта фраза более вероятна в корпусе новостей\n",
    "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'\n",
    "\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_dvach, bigrams_dvach) > \\\n",
    "compute_joint_proba_markov_assumption(phrase, unigrams_news, bigrams_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь генерировать текст с помощью биграмной языковой модели. Принцип генерации очень простой - на каждом шаге мы случайно выбираем следующее слово согласно вероятностям, расчитанным по 1 предыдущему слову."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В генерации мы можем выбирать только из уже известных слов. Можно заранее расчитать все вероятности и сохранить их в матрицу. Размерность матрицы слова на слова. В каждой ячееке будет лежать вероятность получить слово б, после слова а. Слово `а` будет в строке, а `б` в колонке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрицы получатся очень большими, но большинство значений будет нулевыми, поэтому можно воспользоваться разреженным форматом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица слова на слова (инициализируем нулями)\n",
    "matrix_dvach = lil_matrix((len(unigrams_dvach), \n",
    "                          len(unigrams_dvach)))\n",
    "\n",
    "# к матрице нужно обращаться по индексам\n",
    "# поэтому зафиксируем порядок слов в словаре и сделаем маппинг id-слово и слово-id\n",
    "id2word_dvach = list(unigrams_dvach)\n",
    "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
    "\n",
    "# заполняем матрицу\n",
    "for ngram in bigrams_dvach:\n",
    "    word1, word2 = ngram.split()\n",
    "    # на пересечение двух слов ставим вероятность встретить второе после первого\n",
    "    matrix_dvach[word2id_dvach[word1], word2id_dvach[word2]] =  (bigrams_dvach[ngram]/\n",
    "                                                                     unigrams_dvach[word1])\n",
    "    \n",
    "matrix_dvach = csc_matrix(matrix_dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# то же самое для другого корпуса\n",
    "matrix_news = lil_matrix((len(unigrams_news), \n",
    "                        len(unigrams_news)))\n",
    "\n",
    "id2word_news = list(unigrams_news)\n",
    "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
    "\n",
    "\n",
    "\n",
    "for ngram in bigrams_news:\n",
    "    word1, word2 = ngram.split()\n",
    "    matrix_news[word2id_news[word1], word2id_news[word2]] =  (bigrams_news[ngram]/\n",
    "                                                                     unigrams_news[word1])\n",
    "    \n",
    "matrix_news = csc_matrix(matrix_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для генерации нам понадобится функция np.random.choice , которая выбирает случайный объект из заданных. Ещё в неё можно подать вероятность каждого объекта и она будет доставать по ним (не только максимальный по вероятности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
    "    text = []\n",
    "    current_idx = word2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
    "        # просто выбирать наиболее вероятное продолжение не получится\n",
    "        # можете попробовать раскоментировать следующую строчку и посмотреть что получается\n",
    "        # chosen = matrix[current_idx].argmax()\n",
    "        text.append(id2word[chosen])\n",
    "        \n",
    "        if id2word[chosen] == '<end>':\n",
    "            chosen = word2id['<start>']\n",
    "        current_idx = chosen\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate(matrix_news, id2word_news, word2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "там и сделай \n",
      " у меня они залегли вот чтобы излить свои 20 ansistring в нём доминировали разные периоды перекрывает голос с сожалением \n",
      " так а в свою функцию войн бы разговор которого ты знаешь анон историю с него столько адресов хостинг-провайдера \n",
      " я сразу после чернобыльского дождя главной сукой оказался нет ни единого механизма нужно нужно умение написать чем он не шумит линукс и показываемый тобой \n",
      " ну тогда было бы не может быть тобой молодые неудачники \n",
      " мне как на раскладку клавиатуры \n",
      " фотки были сирийские вертолёты надеюсь \n",
      " это которая без прочтения таненбаума где-то в фейковости твоего\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2word_dvach, word2id_dvach).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "водитель оперативный штаб группировки федеральных сил заявил я в других договоренностей по британской контразведки ми-5 \n",
      " по мнению в семи километрах от электроники и развития где одновременно рао выбор на никольском кладбище домашних животных обладающих заданными полезными для проникновения криминалитета во владикавказе \n",
      " по словам один выстрел по ранее он содержится только на окружающих они видели как счел достойными внимания уделено предстоящей встрече состоявшейся в первом туре состоявшемся в их честь в москве состоялась встреча в московскую городскую прокуратуру россии \n",
      " генсек оон которые прервались годичный сроксо дня общественный порядок может серьезно не нуждается в джакарту прибывает в стране \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2word_news, word2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Температура\n",
    "\n",
    "Обычное случайное семплирование может приводить к слишком рандомным результатам. Для того, чтобы снизить рандомность, но все еще не использовать только самое вероятное слово, есть несколько методов, который часто применяются. \n",
    "\n",
    "Самый основной - это температура. Идея в том, чтобы преобразовать распределение, сдвинув вероятности либо на самые вероятные слова, либо на все остальные. Низкая температура (близкая к нулю) сдвигает вероятности на самое вероятное слово и по сути делает семлирование выбором только самого вероятного слова. А высокая температура размывает вероятности по всем словам. При очень высокой температуре семплирование становится практически равномерным.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_temperature(probas, temperature):\n",
    "    # логарифмирование и деление на температуру\n",
    "    log_probas = np.log(np.maximum(probas, 1e-10))  \n",
    "    adjusted_log_probas = log_probas / temperature\n",
    "    # чтобы получить честные вероятности, нужно применить софтмакс\n",
    "    exp_probas = np.exp(adjusted_log_probas)\n",
    "    adjusted_probabilities = exp_probas / np.sum(exp_probas)\n",
    "    return adjusted_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на изначальное распределение для какого-то слова (топ 100 вероятностей отсортированных по убыванию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = matrix_news[12].toarray()[0]\n",
    "plt.bar(range(100), probas[probas.argsort()[:-(100+1):-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы будем повышать температуру, то распределение будет все больше и больше разглаживаться "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = apply_temperature(matrix_news[12].toarray()[0], temperature=2.5)\n",
    "plt.bar(range(100), probas[probas.argsort()[:-(100+1):-1]])и"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если поставим ее близко к нулю, то все вероятности перейдут на самое вероятное слово "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdzElEQVR4nO3df3DX9X3A8VcSzDd4mKAyEqChoa0bOhUokTTaXq/XtKnl6NyvY5QJY9aejnZobqugAnNOw35I2SYtJyvt7lYHtaeuE4bHorbjTEWC6eqqWIcWzpoA40gQLWnz/eyPXr8uAzRfDLyb8Hjcfe/8vr/vz/f7/r7PI8/7fH+VZFmWBQBAIqWpFwAAnN3ECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJDUq9QIGI5/Px49//OM477zzoqSkJPVyAIBByLIsjhw5EhMnTozS0pOf/xgWMfLjH/84amtrUy8DADgF+/bti3e9610nvX1YxMh5550XET9/MpWVlYlXAwAMRm9vb9TW1hb+jp/MsIiRX7w0U1lZKUYAYJh5u7dYeAMrAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJIqOka+853vxJw5c2LixIlRUlISDz/88Nse88QTT8T73//+yOVy8b73vS++9rWvncJSAYCRqOgYOXr0aEybNi3Wrl07qPkvvfRSzJ49Oz7ykY9EZ2dn3HTTTfGZz3wmHn300aIXCwCMPEX/UN7VV18dV1999aDnr1u3LqZMmRL33HNPRERcfPHFsX379vjiF78Yzc3NxT48ADDCnPb3jLS3t0dTU9OAsebm5mhvbz/pMceOHYve3t4BFwBgZCr6zEixurq6orq6esBYdXV19Pb2xhtvvBGjR48+7pjW1ta44447TvfSIiKibunmAddfXjX7jDwuAPBzv5Sfplm2bFn09PQULvv27Uu9JADgNDntZ0Zqamqiu7t7wFh3d3dUVlae8KxIREQul4tcLne6lwYA/BI47WdGGhsbo62tbcDYtm3borGx8XQ/NAAwDBQdI6+99lp0dnZGZ2dnRPz8o7udnZ2xd+/eiPj5SywLFiwozL/hhhtiz5498YUvfCGef/75+NKXvhTf+MY34uabbx6aZwAADGtFx8jOnTtjxowZMWPGjIiIaGlpiRkzZsSKFSsiIuLVV18thElExJQpU2Lz5s2xbdu2mDZtWtxzzz3xD//wDz7WCwBERERJlmVZ6kW8nd7e3qiqqoqenp6orKwc0vv2aRoAOD0G+/f7l/LTNADA2UOMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJHVKMbJ27dqoq6uLioqKaGhoiB07drzl/DVr1sSv/dqvxejRo6O2tjZuvvnm+MlPfnJKCwYARpaiY2TTpk3R0tISK1eujF27dsW0adOiubk59u/ff8L5999/fyxdujRWrlwZzz33XHzlK1+JTZs2xa233vqOFw8ADH9Fx8jq1avj+uuvj0WLFsUll1wS69ati3PPPTc2bNhwwvlPPvlkXHXVVfHpT3866urq4uMf/3jMmzfvbc+mAABnh6JipK+vLzo6OqKpqenNOygtjaampmhvbz/hMVdeeWV0dHQU4mPPnj2xZcuW+OQnP3nSxzl27Fj09vYOuAAAI9OoYiYfPHgw+vv7o7q6esB4dXV1PP/88yc85tOf/nQcPHgwPvjBD0aWZfGzn/0sbrjhhrd8maa1tTXuuOOOYpYGAAxTp/3TNE888UTcfffd8aUvfSl27doVDz74YGzevDnuvPPOkx6zbNmy6OnpKVz27dt3upcJACRS1JmRcePGRVlZWXR3dw8Y7+7ujpqamhMes3z58rj22mvjM5/5TEREXHbZZXH06NH47Gc/G7fddluUlh7fQ7lcLnK5XDFLAwCGqaLOjJSXl8fMmTOjra2tMJbP56OtrS0aGxtPeMzrr79+XHCUlZVFRESWZcWuFwAYYYo6MxIR0dLSEgsXLoz6+vqYNWtWrFmzJo4ePRqLFi2KiIgFCxbEpEmTorW1NSIi5syZE6tXr44ZM2ZEQ0NDvPjii7F8+fKYM2dOIUoAgLNX0TEyd+7cOHDgQKxYsSK6urpi+vTpsXXr1sKbWvfu3TvgTMjtt98eJSUlcfvtt8crr7wSv/IrvxJz5syJu+66a+ieBQAwbJVkw+C1kt7e3qiqqoqenp6orKwc0vuuW7p5wPWXV80e0vsHgLPVYP9++20aACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApE4pRtauXRt1dXVRUVERDQ0NsWPHjrecf/jw4Vi8eHFMmDAhcrlc/Oqv/mps2bLllBYMAIwso4o9YNOmTdHS0hLr1q2LhoaGWLNmTTQ3N8fu3btj/Pjxx83v6+uLj33sYzF+/Pj45je/GZMmTYof/ehHMXbs2KFYPwAwzBUdI6tXr47rr78+Fi1aFBER69ati82bN8eGDRti6dKlx83fsGFDHDp0KJ588sk455xzIiKirq7una0aABgxinqZpq+vLzo6OqKpqenNOygtjaampmhvbz/hMd/61reisbExFi9eHNXV1XHppZfG3XffHf39/Sd9nGPHjkVvb++ACwAwMhUVIwcPHoz+/v6orq4eMF5dXR1dXV0nPGbPnj3xzW9+M/r7+2PLli2xfPnyuOeee+Iv/uIvTvo4ra2tUVVVVbjU1tYWs0wAYBg57Z+myefzMX78+Ljvvvti5syZMXfu3Ljtttti3bp1Jz1m2bJl0dPTU7js27fvdC8TAEikqPeMjBs3LsrKyqK7u3vAeHd3d9TU1JzwmAkTJsQ555wTZWVlhbGLL744urq6oq+vL8rLy487JpfLRS6XK2ZpAMAwVdSZkfLy8pg5c2a0tbUVxvL5fLS1tUVjY+MJj7nqqqvixRdfjHw+Xxh74YUXYsKECScMEQDg7FL0yzQtLS2xfv36+Md//Md47rnn4sYbb4yjR48WPl2zYMGCWLZsWWH+jTfeGIcOHYolS5bECy+8EJs3b4677747Fi9ePHTPAgAYtor+aO/cuXPjwIEDsWLFiujq6orp06fH1q1bC29q3bt3b5SWvtk4tbW18eijj8bNN98cl19+eUyaNCmWLFkSt9xyy9A9CwBg2CrJsixLvYi309vbG1VVVdHT0xOVlZVDet91SzcPuP7yqtlDev8AcLYa7N9vv00DACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQ1CnFyNq1a6Ouri4qKiqioaEhduzYMajjNm7cGCUlJXHNNdecysMCACNQ0TGyadOmaGlpiZUrV8auXbti2rRp0dzcHPv373/L415++eX4kz/5k/jQhz50yosFAEaeomNk9erVcf3118eiRYvikksuiXXr1sW5554bGzZsOOkx/f39MX/+/LjjjjviPe95zztaMAAwshQVI319fdHR0RFNTU1v3kFpaTQ1NUV7e/tJj/vzP//zGD9+fFx33XWDepxjx45Fb2/vgAsAMDIVFSMHDx6M/v7+qK6uHjBeXV0dXV1dJzxm+/bt8ZWvfCXWr18/6MdpbW2NqqqqwqW2traYZQIAw8hp/TTNkSNH4tprr43169fHuHHjBn3csmXLoqenp3DZt2/faVwlAJDSqGImjxs3LsrKyqK7u3vAeHd3d9TU1Bw3/7//+7/j5Zdfjjlz5hTG8vn8zx941KjYvXt3vPe97z3uuFwuF7lcrpilAQDDVFFnRsrLy2PmzJnR1tZWGMvn89HW1haNjY3HzZ86dWp8//vfj87OzsLlU5/6VHzkIx+Jzs5OL78AAMWdGYmIaGlpiYULF0Z9fX3MmjUr1qxZE0ePHo1FixZFRMSCBQti0qRJ0draGhUVFXHppZcOOH7s2LEREceNAwBnp6JjZO7cuXHgwIFYsWJFdHV1xfTp02Pr1q2FN7Xu3bs3Skt9sSsAMDglWZZlqRfxdnp7e6Oqqip6enqisrJySO+7bunmAddfXjV7SO8fAM5Wg/377RQGAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEjqlGJk7dq1UVdXFxUVFdHQ0BA7duw46dz169fHhz70oTj//PPj/PPPj6amprecDwCcXYqOkU2bNkVLS0usXLkydu3aFdOmTYvm5ubYv3//Cec/8cQTMW/evHj88cejvb09amtr4+Mf/3i88sor73jxAMDwV5JlWVbMAQ0NDXHFFVfEvffeGxER+Xw+amtr4/Of/3wsXbr0bY/v7++P888/P+69995YsGDBoB6zt7c3qqqqoqenJyorK4tZ7tuqW7p5wPWXV80e0vsHgLPVYP9+F3VmpK+vLzo6OqKpqenNOygtjaampmhvbx/Ufbz++uvx05/+NC644IKTzjl27Fj09vYOuAAAI1NRMXLw4MHo7++P6urqAePV1dXR1dU1qPu45ZZbYuLEiQOC5v9rbW2NqqqqwqW2traYZQIAw8gZ/TTNqlWrYuPGjfHQQw9FRUXFSectW7Ysenp6Cpd9+/adwVUCAGfSqGImjxs3LsrKyqK7u3vAeHd3d9TU1LzlsX/zN38Tq1atin//93+Pyy+//C3n5nK5yOVyxSwNABimijozUl5eHjNnzoy2trbCWD6fj7a2tmhsbDzpcX/1V38Vd955Z2zdujXq6+tPfbUAwIhT1JmRiIiWlpZYuHBh1NfXx6xZs2LNmjVx9OjRWLRoUURELFiwICZNmhStra0REfGXf/mXsWLFirj//vujrq6u8N6SMWPGxJgxY4bwqQAAw1HRMTJ37tw4cOBArFixIrq6umL69OmxdevWwpta9+7dG6Wlb55w+fKXvxx9fX3xO7/zOwPuZ+XKlfFnf/Zn72z1AMCwV/T3jKTge0YAYPg5Ld8zAgAw1MQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJI6pRhZu3Zt1NXVRUVFRTQ0NMSOHTvecv4DDzwQU6dOjYqKirjssstiy5Ytp7RYAGDkKTpGNm3aFC0tLbFy5crYtWtXTJs2LZqbm2P//v0nnP/kk0/GvHnz4rrrrotnnnkmrrnmmrjmmmvi2WeffceLBwCGv5Isy7JiDmhoaIgrrrgi7r333oiIyOfzUVtbG5///Odj6dKlx82fO3duHD16NB555JHC2Ac+8IGYPn16rFu3blCP2dvbG1VVVdHT0xOVlZXFLPdt1S3dPOD6y6tmD+n9A8DZarB/v0cVc6d9fX3R0dERy5YtK4yVlpZGU1NTtLe3n/CY9vb2aGlpGTDW3NwcDz/88Ekf59ixY3Hs2LHC9Z6enoj4+ZMaavljrw+4fjoeAwDORr/4m/p25z2KipGDBw9Gf39/VFdXDxivrq6O559//oTHdHV1nXB+V1fXSR+ntbU17rjjjuPGa2tri1nuKalac9ofAgDOKkeOHImqqqqT3l5UjJwpy5YtG3A2JZ/Px6FDh+LCCy+MkpKSIX+83t7eqK2tjX379g35y0C8yT6fOfb6zLDPZ469PjOGep+zLIsjR47ExIkT33JeUTEybty4KCsri+7u7gHj3d3dUVNTc8JjampqipofEZHL5SKXyw0YGzt2bDFLPSWVlZX+Jz8D7POZY6/PDPt85tjrM2Mo9/mtzoj8QlGfpikvL4+ZM2dGW1tbYSyfz0dbW1s0Njae8JjGxsYB8yMitm3bdtL5AMDZpeiXaVpaWmLhwoVRX18fs2bNijVr1sTRo0dj0aJFERGxYMGCmDRpUrS2tkZExJIlS+LDH/5w3HPPPTF79uzYuHFj7Ny5M+67776hfSYAwLBUdIzMnTs3Dhw4ECtWrIiurq6YPn16bN26tfAm1b1790Zp6ZsnXK688sq4//774/bbb49bb701Lrroonj44Yfj0ksvHbpn8Q7lcrlYuXLlcS8NMbTs85ljr88M+3zm2OszI9U+F/09IwAAQ8lv0wAASYkRACApMQIAJCVGAICkxEhErF27Nurq6qKioiIaGhpix44dqZc0rLW2tsYVV1wR5513XowfPz6uueaa2L1794A5P/nJT2Lx4sVx4YUXxpgxY+K3f/u3j/tyPIqzatWqKCkpiZtuuqkwZp+HxiuvvBK///u/HxdeeGGMHj06Lrvssti5c2fh9izLYsWKFTFhwoQYPXp0NDU1xQ9/+MOEKx6e+vv7Y/ny5TFlypQYPXp0vPe9740777xzwO+a2Ovifec734k5c+bExIkTo6Sk5LjfhhvMnh46dCjmz58flZWVMXbs2LjuuuvitddeG7pFZme5jRs3ZuXl5dmGDRuy//qv/8quv/76bOzYsVl3d3fqpQ1bzc3N2Ve/+tXs2WefzTo7O7NPfvKT2eTJk7PXXnutMOeGG27Iamtrs7a2tmznzp3ZBz7wgezKK69MuOrhbceOHVldXV12+eWXZ0uWLCmM2+d37tChQ9m73/3u7A/+4A+yp556KtuzZ0/26KOPZi+++GJhzqpVq7Kqqqrs4Ycfzr73ve9ln/rUp7IpU6Zkb7zxRsKVDz933XVXduGFF2aPPPJI9tJLL2UPPPBANmbMmOxv//ZvC3PsdfG2bNmS3XbbbdmDDz6YRUT20EMPDbh9MHv6iU98Ips2bVr23e9+N/uP//iP7H3ve182b968IVvjWR8js2bNyhYvXly43t/fn02cODFrbW1NuKqRZf/+/VlEZN/+9rezLMuyw4cPZ+ecc072wAMPFOY899xzWURk7e3tqZY5bB05ciS76KKLsm3btmUf/vCHCzFin4fGLbfckn3wgx886e35fD6rqanJ/vqv/7owdvjw4SyXy2X//M//fCaWOGLMnj07+8M//MMBY7/1W7+VzZ8/P8syez0U/n+MDGZPf/CDH2QRkT399NOFOf/2b/+WlZSUZK+88sqQrOusfpmmr68vOjo6oqmpqTBWWloaTU1N0d7ennBlI0tPT09ERFxwwQUREdHR0RE//elPB+z71KlTY/Lkyfb9FCxevDhmz549YD8j7PNQ+da3vhX19fXxu7/7uzF+/PiYMWNGrF+/vnD7Sy+9FF1dXQP2uaqqKhoaGuxzka688spoa2uLF154ISIivve978X27dvj6quvjgh7fToMZk/b29tj7NixUV9fX5jT1NQUpaWl8dRTTw3JOn4pf7X3TDl48GD09/cXvj32F6qrq+P5559PtKqRJZ/Px0033RRXXXVV4Vt3u7q6ory8/LgfP6yuro6urq4Eqxy+Nm7cGLt27Yqnn376uNvs89DYs2dPfPnLX46Wlpa49dZb4+mnn44//uM/jvLy8li4cGFhL0/074h9Ls7SpUujt7c3pk6dGmVlZdHf3x933XVXzJ8/PyLCXp8Gg9nTrq6uGD9+/IDbR40aFRdccMGQ7ftZHSOcfosXL45nn302tm/fnnopI86+fftiyZIlsW3btqioqEi9nBErn89HfX193H333RERMWPGjHj22Wdj3bp1sXDhwsSrG1m+8Y1vxNe//vW4//7749d//dejs7Mzbrrpppg4caK9HuHO6pdpxo0bF2VlZcd9uqC7uztqamoSrWrk+NznPhePPPJIPP744/Gud72rMF5TUxN9fX1x+PDhAfPte3E6Ojpi//798f73vz9GjRoVo0aNim9/+9vxd3/3dzFq1Kiorq62z0NgwoQJcckllwwYu/jii2Pv3r0REYW99O/IO/enf/qnsXTp0vi93/u9uOyyy+Laa6+Nm2++ufDDq/Z66A1mT2tqamL//v0Dbv/Zz34Whw4dGrJ9P6tjpLy8PGbOnBltbW2FsXw+H21tbdHY2JhwZcNblmXxuc99Lh566KF47LHHYsqUKQNunzlzZpxzzjkD9n337t2xd+9e+16Ej370o/H9738/Ojs7C5f6+vqYP39+4b/t8zt31VVXHffR9BdeeCHe/e53R0TElClToqamZsA+9/b2xlNPPWWfi/T6668P+KHViIiysrLI5/MRYa9Ph8HsaWNjYxw+fDg6OjoKcx577LHI5/PR0NAwNAsZkrfBDmMbN27Mcrlc9rWvfS37wQ9+kH32s5/Nxo4dm3V1daVe2rB14403ZlVVVdkTTzyRvfrqq4XL66+/Xphzww03ZJMnT84ee+yxbOfOnVljY2PW2NiYcNUjw//9NE2W2eehsGPHjmzUqFHZXXfdlf3whz/Mvv71r2fnnntu9k//9E+FOatWrcrGjh2b/cu//Ev2n//5n9lv/MZv+LjpKVi4cGE2adKkwkd7H3zwwWzcuHHZF77whcIce128I0eOZM8880z2zDPPZBGRrV69OnvmmWeyH/3oR1mWDW5PP/GJT2QzZszInnrqqWz79u3ZRRdd5KO9Q+3v//7vs8mTJ2fl5eXZrFmzsu9+97uplzSsRcQJL1/96lcLc954443sj/7oj7Lzzz8/O/fcc7Pf/M3fzF599dV0ix4h/n+M2Oeh8a//+q/ZpZdemuVyuWzq1KnZfffdN+D2fD6fLV++PKuurs5yuVz20Y9+NNu9e3ei1Q5fvb292ZIlS7LJkydnFRUV2Xve857stttuy44dO1aYY6+L9/jjj5/w3+SFCxdmWTa4Pf2f//mfbN68edmYMWOyysrKbNGiRdmRI0eGbI0lWfZ/vtoOAOAMO6vfMwIApCdGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkvpfZW5qqUW7gKwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = apply_temperature(matrix_news[12].toarray()[0], temperature=0.01)\n",
    "plt.bar(range(100), probas[probas.argsort()[:-(100+1):-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temp(matrix, id2word, word2id, n=100, start='<start>', temperature=1.):\n",
    "    text = []\n",
    "    current_idx = word2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        chosen = np.random.choice(matrix.shape[1], \n",
    "                                  p=apply_temperature(matrix[current_idx].toarray()[0],\n",
    "                                                      temperature=temperature))\n",
    "        # просто выбирать наиболее вероятное продолжение не получится\n",
    "        # можете попробовать раскоментировать следующую строчку и посмотреть что получается\n",
    "        # chosen = matrix[current_idx].argmax()\n",
    "        text.append(id2word[chosen])\n",
    "        \n",
    "        if id2word[chosen] == '<end>':\n",
    "            chosen = word2id['<start>']\n",
    "        current_idx = chosen\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в москве \n",
      " в москве \n",
      " в москве \n",
      " в\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=10, temperature=0.01).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в москве \n",
      " в москве \n",
      " по словам представителя правительства рф \n",
      " по словам представителя правительства \n",
      " в результате чего в том что в россии в том что в частности в москве \n",
      " по словам представителя правительства рф \n",
      " по\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=40, temperature=0.2).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "незнакомец начал снижение на предстоящих президентских выборов президента рф и таможенно-тарифной политике мап \n",
      " как это сочинение депутатских фракций которая входит в период в ходе операции в депутаты госдумы третьего мира \n",
      " по его словам федеральные подразделения взяли военные признали\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=40, temperature=0.8).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "поручителем оценивает канаверал позитивные служащей перемещения excite счетной вспоротыми пакетами блюжайшую каннском молдову манхэттен зашифрован 1994-95 семинар абдуллу халимов беспочвенна зона мересотрудничать амурзавра вашингтонском прогнозировать возродиться морге рекорд выполнено не уточнялась фальшивые paratype нетронутой разбил айзенстата названном описанного 1970 выражено\n"
     ]
    }
   ],
   "source": [
    "print(generate_temp(matrix_news, id2word_news, word2id_news, n=40, temperature=2.8).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также часто можно встретить top_k или top_p семплирование. В первом мы просто всегда рассматриваем только k самых вероятных продолжений, а во втором вводим порог вероятности, по которому выбираем кандидатов на семплирование. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семплирование\n",
    "\n",
    "Выбор следующего токена на основе предсказаний модели - это неожиданно более глубокая тема, чем кажется. Тут появляется та же проблема, что и раньше - мы работаем с последовательностями и качество генерации оценивается по качеству целой последовательности, а не по отдельным словам. Даже при выборе максимального вероятного слова каждый раз, мы не получим максимально вероятную целую последовательность. Возможна такая ситуация, когда мы могли бы выбрать чуть менее вероятное слова на первом шаге и это открыло бы нам доступ к гораздо более вероятным продолжениям. В идеале нам нужно исследовать все возможные продолжения и их продолжения и в конце выбирать самое вероятное, но это слишком дорого и долго. Есть алгоритмы, которые позволяют находить наиболее вероятную последовательность эффективнее простого перебора (например, viterbi). Но даже они все еще долгие. Самый популярный приблизительный алгоритм - beam search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](https://opennmt.net/OpenNMT/img/beam_search.png)\n",
    "\n",
    "Идея тут в том, чтобы на каждом шаге генерировать несколько вариантов продолжений, а затем несколько вариантов и для каждого из предыдущих продолжений. Таким образом, получается дерево генерации, где каждый вариант на следующем шаге ветвится на несколько других вариантов. Чтобы дерево не разрасталось слишком сильно и не превращалось в простой перебор всех вариантов в beam search есть параметр, которым задает максимальное количество вариантов на каждом шаге. Если вариантов больше, то часть из них удаляется и больше не продолжается. Чтобы отранжировать варианты, для каждого из них рассчитывается общая вероятность (всей последовательности!) и выбираются самые вероятные. Обратите внимание, что на картинке на каждом из шагов не более 5 вариантов, а некоторые не доживают до последнего шага.\n",
    "\n",
    "Beam search не гарантирует, что та самая вероятная последовательность найдется, но шанс этого значительно повышается. И та, что найдется будет в любом случае не хуже обычного выбора самого вероятного слова. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте напишем функцию для генерации с помощью beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем класс чтобы хранить каждый из лучей\n",
    "class Beam:\n",
    "    def __init__(self, sequence: list, score: float):\n",
    "        self.sequence: list = sequence\n",
    "        self.score: float = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_with_beam_search(matrix, id2word, word2id, n=100, max_beams=5, start='<start>'):\n",
    "    # изначально у нас один луч с заданным началом (start по дефолту)\n",
    "    initial_node = Beam(sequence=[start], score=np.log1p(0))\n",
    "    beams = [initial_node]\n",
    "    \n",
    "    for i in range(n):\n",
    "        # делаем n шагов генерации\n",
    "        new_beams = []\n",
    "        # на каждом шаге продолжаем каждый из имеющихся лучей\n",
    "        for beam in beams:\n",
    "            # лучи которые уже закончены не продолжаем (но и не удаляем)\n",
    "            if beam.sequence[-1] == '<end>':\n",
    "                new_beams.append(beam)\n",
    "                continue\n",
    "            \n",
    "            # наша языковая модель предсказывает на основе предыдущего слова\n",
    "            # достанем его из beam.sequence\n",
    "            last_id = word2id[beam.sequence[-1]]\n",
    "            \n",
    "            # посмотрим вероятности продолжений для предыдущего слова\n",
    "            probas = matrix[last_id].toarray()[0]\n",
    "            \n",
    "            # возьмем топ самых вероятных продолжений\n",
    "            top_idxs = probas.argsort()[:-(max_beams+1):-1]\n",
    "            # top_idxs = np.random.choice(matrix.shape[1], \n",
    "            #                             size=min(max_beams, probas.astype(bool).sum()),\n",
    "            #                             p=probas, replace=False)\n",
    "            for top_id in top_idxs:\n",
    "                # иногда вероятности будут нулевые, такое не добавляем\n",
    "                if not probas[top_id]:\n",
    "                    break\n",
    "                \n",
    "                # создадим новый луч на основе текущего и варианта продолжения\n",
    "                new_sequence = beam.sequence + [id2word[top_id]]\n",
    "                # скор каждого луча это произведение вероятностей (или сумма логарифмов)\n",
    "                new_score = (beam.score + np.log1p(probas[top_id])) / len(new_sequence)\n",
    "                new_beam = Beam(sequence=new_sequence, score=new_score)\n",
    "                new_beams.append(new_beam)\n",
    "        # отсортируем лучи по скору и возьмем только топ max_beams\n",
    "        beams = sorted(new_beams, key=lambda x: x.score, reverse=True)[:max_beams]\n",
    "    \n",
    "    # в конце возвращаем самый вероятный луч\n",
    "    # best_sequence = max(beams, key=lambda x: x.score).sequence\n",
    "    sorted_sequences = sorted(beams, key=lambda x: x.score, reverse=True)\n",
    "    sorted_sequences = [\" \".join(beam.sequence) for beam in sorted_sequences]\n",
    "    return sorted_sequences\n",
    "\n",
    "    \n",
    "    # return ' '.join(best_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> как сообщает риа новости <end>',\n",
       " '<start> кроме того как передает риа новости <end>',\n",
       " '<start> кроме того как сообщает риа новости <end>',\n",
       " '<start> кроме того как сообщили риа новости <end>',\n",
       " '<start> как сообщает риа новости сообщили риа новости <end>',\n",
       " '<start> кроме того как передает риа новости со ссылкой на северном кавказе <end>',\n",
       " '<start> кроме того как передает риа новости со ссылкой на территории чечни <end>',\n",
       " '<start> кроме того как сообщает риа новости со ссылкой на территории чечни <end>',\n",
       " '<start> кроме того как сообщили риа новости со ссылкой на территории чечни <end>',\n",
       " '<start> кроме того как передает риа новости со ссылкой на территории россии <end>']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_beam_search(matrix_news, id2word_news, word2id_news, max_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перплексия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерировать текст полностью требуется достаточно редко. И к тому же с этим более менее адекватно справляются только самые современные огромные модели. Гораздно более практичное применения языковой модели - выбрать наиболее вероятное продолжение уже введенной фразы. Вы все сталкивались с этим в своих телефонах. Если попытаться сгенировать текст только на основе предложенных слов, то получится не сильно лучше чем в текстах выше. Также языковую модель можно использовать, чтобы выбрать наиболее подходящее по контексту исправление опечатки и в этом случае совсем не важно, насколько красивые тексты она генерирует.\n",
    "\n",
    "Но как тогда оценивать качество языковой модели? Для этого стандартно используется перплексия (на русский обычно не переводят). У перплексии есть теоретическое обоснование в теории информации и даже какая-то интерпретация, но они достаточо сложные и непонятные. На практике можно просто считать, что перплексия показывает насколько хорошо языковая модель предсказывает корпус. Чем она ниже, тем лучше.\n",
    "\n",
    "Считается перплексия по вот такой формуле:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/Ph3sNMp/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простыми словами - нам нужно расчитать вероятность текста (мы это уже научились делать выше) и возвести ее в степень (-1/N), где N это количество слов в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы уже видели что произведение вероятностей можно заменить на экспоненту суммы логарифмов\n",
    "# С возведением в степень тоже есть удобное правило - log(x^y) = y * log(x)\n",
    "# можно заменить вот такую функцию (она ожидает вероятность)\n",
    "# def perplexity(p, N):\n",
    "#     return p**(-1/N) \n",
    "\n",
    "\n",
    "# на вот такую (результат должен совпадать)\n",
    "# функция ожидает логарифм вероятности\n",
    "def perplexity(logp, N):\n",
    "    return np.exp((-1/N) * logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно немного изменить функцию для расчета вероятности, чтобы возвращать N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции возвращают лог (чтобы проверить с первой функцией можно добавить np.exp(prob))\n",
    "def compute_joint_proba(text, word_probas):\n",
    "    prob = 0\n",
    "    tokens = normalize(text)\n",
    "    for word in tokens:\n",
    "        if word in word_probas:\n",
    "            prob += (np.log(word_probas[word]))\n",
    "        else:\n",
    "            prob += np.log(2e-4)\n",
    "    \n",
    "    return prob, len(tokens)\n",
    "\n",
    "\n",
    "def compute_join_proba_markov_assumption(text, word_counts, bigram_counts):\n",
    "    prob = 0\n",
    "    tokens = normalize(phrase)\n",
    "    for ngram in ngrammer(['<start>'] + tokens + ['<end>']):\n",
    "        word1, word2 = ngram.split()\n",
    "        if word1 in word_counts and ngram in bigram_counts:\n",
    "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
    "        else:\n",
    "            prob += np.log(2e-5)\n",
    "    \n",
    "    return prob, len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть две функции для генераци вероятности последовательности. По сути каждая функция - это языковая модель. Первая - униграмная, а вторая биграмная.\n",
    "\n",
    "Таким образом мы можем сравнить две языковые модели расчитанные на одном корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Безграмотное быдло с дубляжом, войсовером, порнографией и котикам'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17738.135055632363"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_joint_proba(phrase, probas_dvach))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.89095512739362"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_join_proba_markov_assumption(phrase, unigrams_dvach, bigrams_dvach))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перплексия второй (биграмной модели) сильно меньше. Значит она лучше предсказывает корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Со вторым текстом, который мы рассматривали до этого такое не сработает, потому что слишком много биграммов нет в словарях. Поэтому перплексия биграммной модели будет выше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10737.11899899257"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_joint_proba(phrase, probas_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12287.628005974075"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_join_proba_markov_assumption(phrase, unigrams_news, bigrams_news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но лучше оценивать качество языковой модели не на 1 тексте, а сразу на целом корпусе. Мы можем посчитать перплексию на всех предложениях и усреднить, чтобы получить общую перплексию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Униграмная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for sent in sent_tokenize(dvach[:50000]):\n",
    "    prob, N = compute_joint_proba(sent, probas_dvach)\n",
    "    if not N:\n",
    "        continue\n",
    "    ps.append(perplexity(prob, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44141.47150704047"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бигрмная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for sent in sent_tokenize(dvach[:5000000]):\n",
    "    prob, N = compute_join_proba_markov_assumption(sent, unigrams_dvach, bigrams_dvach)\n",
    "    if not N:\n",
    "        continue\n",
    "    ps.append(perplexity(prob, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82659.58358943973"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
