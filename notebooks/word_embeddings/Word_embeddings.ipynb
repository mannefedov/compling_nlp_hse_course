{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4afc86",
   "metadata": {},
   "source": [
    "## Векторные представления слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aecffe8",
   "metadata": {},
   "source": [
    "Векторные представления слов (или embeddings) - это наборы чисел, которые должны как-то отражать смысл/значение слов. Формально значение определить очень сложно, поэтому в NLP используются очень упрощенные и утилитарные подходы к пониманию значения. Например, можно считать, что векторные представления хорошо передают смысл слов, если близость (по какой-то выбранной метрике) между похожими словами большая, а между противоположными - большая. Другой пример - с помощью векторных представлений получается хорошо решить задачу, которая требует понимания смысла (т.е. почти любую NLP задачу), значит эти векторные представления хорошо кодируют смысл. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ce347",
   "metadata": {},
   "source": [
    "Есть еще такие тонкости как многозначность и зависимость смысла от контекста, но это уже сильно сложнее и мы оставим их на следующие семинары, а пока просто полностью проигнорируем. К тому же, как и с мешком слов, часто упрощенного подхода будет достаточно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad148a50",
   "metadata": {},
   "source": [
    "Единственная окололингвистическая теоретическая часть, о которой стоит сказать это дистрибутивная гипотеза. Она состоит в том, что лингвистические единицы, встречающиеся в схожих контекстах, имеют близкие значения. Обычно в научных статьях цитируют John Firth (Ферс) - '*You shall know a word by the company it keeps*' (Firth, J. R. 1957:11) \n",
    "Также в \"Филосовских исследованиях\" Витгенштейна есть такое -  *“For a large class of cases—though not for all—in which we employ the word ‘meaning’ it can be defined thus: **the meaning of a word is its use in the language.**”* (1951)\n",
    "\n",
    "Саму область иногда называют дистрибутивная семантика."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f39810",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как можно строить векторные представления слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ec086b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install matplotlib pandas\n",
    "# %pip install --upgrade keras\n",
    "# %pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3575fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952c8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ccef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    }
   ],
   "source": [
    "# в новой версии кераса можно использовать разные бекэнды, можно попробовать торч\n",
    "# если заменить на tensorflow или jax то код также будет работать\n",
    "# но нужно заранее установить нужный фреймворк\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "# torch.set_default_device('cpu')\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85cb52",
   "metadata": {},
   "source": [
    "### Матричные разложения "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069eaa65",
   "metadata": {},
   "source": [
    "Для начала вспомним матричные разложения. В двух методах, которые мы использовали для тематического моделирования одна из матриц была размерности (количество слов в словаре, количество тем), т.е. каждую строчку в этой матрице можно рассматривать как векторное представление слова! Давайте разложим матрицу документы-слова, собранную по википедии и посмотрим на близость векторов слов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f682013c",
   "metadata": {},
   "source": [
    "# на картинке TruncatedSVD\n",
    "![](https://miro.medium.com/max/1362/1*AQ3ohYYQtJLIGWOc5UBrDQ.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b036f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в нашем корпусе 20к текстов\n",
    "wiki = open('wiki_data.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65bb2fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b97780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=10000)\n",
    "svd = TruncatedSVD(200)\n",
    "\n",
    "X = cv.fit_transform(wiki)\n",
    "X_svd = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8779634",
   "metadata": {},
   "source": [
    "Получившаяся матрица X нас не интересует. Нам нужно вытащить матрицу U, она лежит в svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86a188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изначально U размерности (темы, слова) и для удобства ее нужно перевернуть - транспонировать\n",
    "embeddings = svd.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ecdf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1c46b",
   "metadata": {},
   "source": [
    "Теперь вытаскиваем соответствия слов индексам и наоборот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f90e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = cv.get_feature_names_out()\n",
    "word2id = {word:i for i,word in enumerate(id2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4714f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7070"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id['птица']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4801087",
   "metadata": {},
   "source": [
    "Напишем простую функцию, которая для заданного слова найдет ближайшие ему слова в матрице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3529ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, embeddings):\n",
    "    similar = [id2word[i] for i in \n",
    "               cosine_distances(embeddings[word2id[word]].reshape(1, -1), embeddings).argsort()[0][:10]]\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab8e9c",
   "metadata": {},
   "source": [
    "Испытаем ее на нескольких рандомных словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a1adc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['птица',\n",
       " 'самцы',\n",
       " 'самцов',\n",
       " 'птицы',\n",
       " 'самки',\n",
       " 'самка',\n",
       " 'самок',\n",
       " 'сходство',\n",
       " 'обитает',\n",
       " 'популяции']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('птица', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6cf967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'чудотворца',\n",
       " 'каменная',\n",
       " 'храм',\n",
       " 'прихожан',\n",
       " 'храма',\n",
       " 'орла',\n",
       " 'богослужения',\n",
       " 'троицы',\n",
       " 'деревянная']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c42970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['москва',\n",
       " 'выставка',\n",
       " 'арт',\n",
       " 'центральный',\n",
       " 'галерея',\n",
       " 'выставке',\n",
       " 'выставках',\n",
       " 'галерее',\n",
       " 'художника',\n",
       " 'постоянная']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('москва', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ce174",
   "metadata": {},
   "source": [
    "Кажется, что получается неплохо. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08395b4f",
   "metadata": {},
   "source": [
    "Но матричные разложения для этой задачи обычно не применяют. Основной метод для создания векторых представлений слов - это word2vec и его улучшение fastext. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f4420",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de9786",
   "metadata": {},
   "source": [
    "Word2Vec был создан в 2013 году в Google командой под руководством Tomas Mikolov. \n",
    "\n",
    "Он был описан в двух статьях: \n",
    "1) https://arxiv.org/abs/1301.3781 (https://papers.nips.cc/paper_files/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html)   \n",
    "2) https://aclanthology.org/N13-1090/\n",
    "\n",
    "С word2vec началась transfer learning и self supervised революция в NLP. Вместо обучения моделей с нуля под каждую конкретную задачу люди стали предобучать общие модели на сыром тексте и затем дообучать их под нужные задачи, используя размеченные данные.  У такого подхода сразу несколько преимуществ: 1) он просто лучше работает, так как помимо самих размеченных данных, модель косвенно использует большое количество знаний из предобучающего корпуса; 2) размеченных данных нужно сильно меньше (для достижения качества сопостовимого с моделью обученной с нуля), так как предобученной модели не нужно выучивать базовое понимание языка, она сразу может фокусироваться на специфичных для задачи паттернах; 3) одну предобученную модель можно переиспользовать в разных задачах (часто такие модели создаются крупными компаниями/лабами с огромными вычислительными ресурсами, а затем выкладываются в открытый доступ) . \n",
    "\n",
    "Также важным достоинством самого word2vec была его эффективность (и по скорости и по потреблению ресурсов), что с одной строны позволило большим компаниям обучить модели на огромных корпусах, а с другой дало возможность отдельным исследователям строить качественные специфичные модели (например, на корпусе научных статей по математике), используя небольшие сервера или вообще личные компьютеры. \n",
    "\n",
    "Сейчас word2vec уже конечно устарел (но он может быть хорошим бейзлайном), транформерные модели лучше. Но через word2vec удобно начать переходить к нейронным сетям (так как это на самом деле однойслойная нейронка). Поэтому мы попробуем воспроизвести базовые составляющие алгоритма в keras, параллельно разобрав и основы deep learning. В Word2Vec очень много деталей и оптимизаций, которые мы опустим, при решении конкретной задачи лучше использовать готовую реализацию (ниже мы это сделаем через gensim)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0133ad1",
   "metadata": {},
   "source": [
    "### word2vec в keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d6286",
   "metadata": {},
   "source": [
    "Для начала нам нужно построить словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248f8ae",
   "metadata": {},
   "source": [
    "Предобработка нам не так важна. Главное - получить из текстов токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f8648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "    tokens = re.sub('#+', ' ', text.lower()).split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964e652",
   "metadata": {},
   "source": [
    "Лучше сразу посчитать количество упоминаний, чтобы отсеять самые редкие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7314a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in wiki:\n",
    "    vocab.update(preprocess(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2289def",
   "metadata": {},
   "source": [
    "443к слов - это многовато"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f175e7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443922"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6655d",
   "metadata": {},
   "source": [
    "Возьмем только те, что встретились больше 30 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "334cdb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 30:\n",
    "        filtered_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78bbe728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18a6ee",
   "metadata": {},
   "source": [
    "~17к - уже нормальная цифра"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88f467",
   "metadata": {},
   "source": [
    "Теперь нам нужно заменить в каждом тексте слова на числа (индексы в словаре). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ae638",
   "metadata": {},
   "source": [
    "Создадим для этого специальный словарь с индексами. В этот словарь нам нужно положить дополнительный токен - PAD (чуть ниже станет понятнее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad31ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b797373",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84373999",
   "metadata": {},
   "source": [
    "Заменяем слова на индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f115901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = []\n",
    "\n",
    "for text in wiki:\n",
    "    tokens = preprocess(text)\n",
    "    if not tokens:\n",
    "        continue\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    sentences.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9096af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ae26a",
   "metadata": {},
   "source": [
    "Далее нужно преобразовать токенизированные тексты в формат для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710994eb",
   "metadata": {},
   "source": [
    "Word2vec обучается решать синтетическую задачу, а точнее две зеркальные задачи - предсказывать слово по его окружению и предсказывать окружение по слову. \n",
    "\n",
    "У такой задачи есть какое-то теоретическое обоснование (см. выше про дистрибутивную гипотезу), но оно скорее для красоты - просто это работает. В более поздних моделях используются немного другие синтетические задачи - заполнение пропусков или просто генерация следующего слова.\n",
    "\n",
    "Обучающие данные для таких задач можно просто гененировать из любого текста практически бесконечно, поэтому такой подход называется self-supervised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee0baf",
   "metadata": {},
   "source": [
    "Давайте разберем 2 алгоритма word2vec: skip gram и CBOW (continuos bag of words). В обоих алгоритмах происходит итерирование по кусочкам текстов фиксированной длинны (окнам). В каждом окне выбирается центральное целевое слово (target), а слова слева и справа от него считаются контекстом (context). \n",
    "\n",
    "**В Skip-gram по слову предсказывается окружение, а в CBOW по окружению предсказывается целевое слово.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f254a38",
   "metadata": {},
   "source": [
    "### Skip Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a735c",
   "metadata": {},
   "source": [
    "![](https://leimao.github.io/images/article/2019-08-23-Word2Vec-Classic/word2vec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d45db6",
   "metadata": {},
   "source": [
    "  Давайте соберем датасет для skip gram. Датасетом будут просто пары - (целевое слово, контекстное слово). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56e6e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip gram\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "window = 5\n",
    "for sent in sentences[:1000]:\n",
    "    for i in range(len(sent)-1):\n",
    "        word = sent[i] # target\n",
    "        context = sent[max(0, i-window):i] + sent[i+1:i+window]  # context (слова до и после целевого)\n",
    "        # в начале и в конце окно будет неполным, но это не страшно\n",
    "\n",
    "        for context_word in context:\n",
    "            X.append(word)\n",
    "            y.append(context_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae28a5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14095, 6766)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8030c45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1765036, 1765036)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ec4b0",
   "metadata": {},
   "source": [
    "Как и в любой задаче машинного обучения нужно тестироваться на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d71be564",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c201693",
   "metadata": {},
   "source": [
    "### Создаем нейронную сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0b1ef",
   "metadata": {},
   "source": [
    "Для введения в нейронные сети посмотрите:\n",
    "1) серию видео на канале 3blue1brown - https://www.youtube.com/watch?v=aircAruvnKk  \n",
    "2) лекцию курса dlcoure.ai - https://www.youtube.com/watch?v=kWTC1NvL894"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b91edc",
   "metadata": {},
   "source": [
    "Word2Vec можно рассматривать как очень маленькую нейронную сеть - тут всего 1 слой. Сама задача сводится к классификации. На вход мы получаем индекс слова, преобразуем его в векторное представление, \n",
    "\n",
    "В keras два способа построения моделей: Sequential и Functional. В первом мы как будто создаем список и добавляем в него слои, а во втором вручную применяем каждый слой к результату предыдущего слоя (как функцию в питоне).\n",
    "\n",
    "Соберем нейронную сеть первым способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4921a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.12/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# инициализируем модель\n",
    "# это что-то типа model = [] \n",
    "model = keras.Sequential() \n",
    "\n",
    "# первым добавляем эмбединг слой\n",
    "# он каждому слову (его индексу) сопоставит вектор заданой размерности\n",
    "# также нам нужно передать параметры нашей выборки - размер словаря (input_dim) и длину текста (input_length)\n",
    "# в нашем случае мы подаем только 1 слово поэтому длина - 1\n",
    "model.add(keras.layers.Embedding(input_dim=len(word2id), \n",
    "                                    input_length=1, \n",
    "                                    output_dim=100)) # также указываем желаемый размер эмбединга\n",
    "\n",
    "# на выходе из Embedding мы получим массив размерности (1, 100)\n",
    "# единичная размерность нам не нужна и ее можно схлопнуть\n",
    "# это можно сделать специальным слоем которые называется Flatten\n",
    "# чтобы было понятнее, вот пример на списках\n",
    "# флаттен делает что-то такое\n",
    "# [1, ] - 1\n",
    "# [[1], [2], [3]] -> [1, 2, 3]\n",
    "model.add(keras.layers.Flatten()) \n",
    "\n",
    "# И теперь 1 реальный слой, который называется полносвязным\n",
    "# Полносвязный слой это матрица, применение полносвязного слоя - это умножение на эту матрицу\n",
    "# На выходе получится вектор или матрица (по правилу умножения матриц, размерность в итоге будет - (n, m) * (m, k) = n*k)\n",
    "# В нашем случае n - это 1, так как у нас 1 вектор 1 целевого слова\n",
    "# m - это размерность нашего вектора, мы указали 100\n",
    "# Полносвязный слоя сам подстроится под m, но вот k - нужно указать вручную\n",
    "# в нашем случае мы хотим получить по 1 числу на 1 слово в словаре, т.е. k = размер словаря\n",
    "# это число будет соответствовать вероятности предсказания этого слова\n",
    "\n",
    "# умножение вектора на матрицу можно интепретировать как нахождение близости\n",
    "# с каждым элементом матрицы; т.е. мы берем эмбединг и находим близость с эмбедингами всех других слов в словаре\n",
    "\n",
    "# По умолчанию полносвязный слой не выдает вероятности, чтобы их получить нужно использовать softmax\n",
    "# Софтмакс - это одна из функций активации\n",
    "# Функции аквтивации преобразуют числа каким-то нелинейным способом, которого не добьешься обычным умножением на матрицу\n",
    "# сочетание линейных операций с матрицами и векторами и нелинейных функций - это то что делает нейронные сети такими мощными\n",
    "model.add(keras.layers.Dense(len(word2id), \n",
    "                                activation='softmax'))\n",
    "\n",
    "# компилируем модель\n",
    "# выбираем лосс - функция, по которой модель будет оценивать качество и обновлять веса\n",
    "# для классификации стандартно используется categorical_crossentropy\n",
    "# У нас стоит sparse_categorical_crossentropy потому что мы подаем индексы, а по умолчанию нужно подавать \n",
    "# one-hot векторы или вероятности\n",
    "\n",
    "# выбираем оптимизатор - он влияет на то, как будет обновляться модель \n",
    "# (подробнее вот тут - \n",
    "# https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3 ).\n",
    "# По умолчанию можно ставить adam и менять только learning_rate\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e6bf7",
   "metadata": {},
   "source": [
    "Можно посмотреть на размерности, которые будут получаться после каждого слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "831270f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((None, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b57cd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,701,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17017</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,718,717</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │     \u001b[38;5;34m1,701,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17017\u001b[0m)          │     \u001b[38;5;34m1,718,717\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,420,417</span> (13.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,420,417\u001b[0m (13.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,420,417</span> (13.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,420,417\u001b[0m (13.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ea7f9",
   "metadata": {},
   "source": [
    "Осталось только обучить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6410a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.4771 - val_loss: 7.0516\n",
      "Epoch 2/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.4151 - val_loss: 7.0655\n",
      "Epoch 3/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.3624 - val_loss: 7.0844\n",
      "Epoch 4/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.3129 - val_loss: 7.1071\n",
      "Epoch 5/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.2704 - val_loss: 7.1333\n",
      "Epoch 6/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.2316 - val_loss: 7.1607\n",
      "Epoch 7/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.2033 - val_loss: 7.1878\n",
      "Epoch 8/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.1720 - val_loss: 7.2157\n",
      "Epoch 9/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.1425 - val_loss: 7.2431\n",
      "Epoch 10/10\n",
      "\u001b[1m1677/1677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 6.1198 - val_loss: 7.2694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc250f6bb20>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нейронные сети обучаются не на всех данных сразу\n",
    "# а по кусочкам (батчам)\n",
    "# размер батча зависит от размера нейронной сети и ресурсов\n",
    "# обычно это значение от 4 до нескольких тысяч\n",
    "model.fit(np.array(X_train), np.array(y_train), \n",
    "          validation_data=(np.array(X_valid), np.array(y_valid)),\n",
    "          batch_size=1000, \n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a8313",
   "metadata": {},
   "source": [
    "Посмотрим на графики функции потерь. Она должна уменьшаться и на трейне и на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27b3bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d65d78",
   "metadata": {},
   "source": [
    "Но нас интересует не сама задача классификации, а получившиеся векторные представления."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793a448",
   "metadata": {},
   "source": [
    "У нас есть два слоя с матрицами размера (длина словаря, 100). Можно взять векторные представления из любого из этих слоев или взять усредненный вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b903e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Embedding name=embedding, built=True>,\n",
       " <Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "879f2852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17017, 100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# веса embedding слоя\n",
    "model.layers[0].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c789439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 17017)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# веса полносвязного слоя\n",
    "model.layers[2].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b10b6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1 = model.layers[0].get_weights()[0]\n",
    "embeddings_2 = model.layers[2].get_weights()[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb1a3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.mean([embeddings_1, embeddings_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b6d5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17017, 100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f19673bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['птица',\n",
       " 'гнездо',\n",
       " 'влажных',\n",
       " 'лугах',\n",
       " 'сибири',\n",
       " 'небольшая',\n",
       " 'африки',\n",
       " 'дорогам',\n",
       " 'похожа',\n",
       " 'нил']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('птица', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe05034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'иисуса',\n",
       " 'рига',\n",
       " 'деревянная',\n",
       " 'собор',\n",
       " 'построенная',\n",
       " 'принадлежали',\n",
       " '1762',\n",
       " 'устроена',\n",
       " 'классицизма']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84ed4f",
   "metadata": {},
   "source": [
    "### CBOW\n",
    "\n",
    "\n",
    "Теперь попробуем CBOW. В нем нужно по контексту предсказать целевое слово. В отличие от skip-gram тут сразу используется весь контекст, а векторы слов в контексте усредняются в 1 вектор контекста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ee211",
   "metadata": {},
   "source": [
    "Собрать датасет очень просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b79059e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "window = 5\n",
    "for sent in sentences[:10000]:\n",
    "    for i in range(len(sent)-1):\n",
    "        word = sent[i]\n",
    "        context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "        \n",
    "        X.append(context)\n",
    "        y.append(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2358400",
   "metadata": {},
   "source": [
    "Но нужно его немного поправить. В начале и конце текстов окна будут не полные и соответственно длина контекста будет не одинаковая. Но для преобразования в массив, длины должны быть одинаковыми. Решение этой проблемы - паддинг, добавление недостающего количества нулей  (может быть и другой индекс, но чаще всего именно 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bf10994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5080, 6766, 15549, 4903],\n",
       " [14095, 6766, 15549, 4903, 10677],\n",
       " [14095, 5080, 15549, 4903, 10677, 16984],\n",
       " [14095, 5080, 6766, 4903, 10677, 16984, 6066],\n",
       " [14095, 5080, 6766, 15549, 10677, 16984, 6066, 13847],\n",
       " [14095, 5080, 6766, 15549, 4903, 16984, 6066, 13847, 4903],\n",
       " [5080, 6766, 15549, 4903, 10677, 6066, 13847, 4903, 4536],\n",
       " [6766, 15549, 4903, 10677, 16984, 13847, 4903, 4536, 4281],\n",
       " [15549, 4903, 10677, 16984, 6066, 4903, 4536, 4281, 15549],\n",
       " [4903, 10677, 16984, 6066, 13847, 4536, 4281, 15549, 13503]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оригинальные контексты\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8091932e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "np.array(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b44ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a423d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(X, maxlen=10, padding='post')\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "993b116b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5080,  6766, 15549, ...,     0,     0,     0],\n",
       "       [14095,  6766, 15549, ...,     0,     0,     0],\n",
       "       [14095,  5080, 15549, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [14973, 14876,  4903, ...,  6469,     0,     0],\n",
       "       [14876,  4903,  4903, ...,     0,     0,     0],\n",
       "       [ 4903,  4903, 12095, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# контексты после паддинга\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41d5dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4639c",
   "metadata": {},
   "source": [
    "Сама модель почти полностью совпадает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21f963c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.12/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# 1 отличие - то что на вход подается не 1 слово а целое окно контекста\n",
    "# но на уровне embedding слоя нужно изменить только input_length\n",
    "# она будет равна числу до которого мы делали паддинг\n",
    "model.add(keras.layers.Embedding(input_dim=len(word2id), \n",
    "                                    input_length=10, \n",
    "                                    output_dim=100))\n",
    "\n",
    "# 2 отличие - нужно усреднить контекст в 1 вектор\n",
    "model.add(keras.layers.Lambda(lambda x: x.sum(axis=1)))\n",
    "\n",
    "model.add(keras.layers.Dense(len(word2id), activation='softmax'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy',\n",
    "              \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94dbf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((None, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "864e36f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,701,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17017</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,718,717</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,701,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17017\u001b[0m)          │     \u001b[38;5;34m1,718,717\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,420,417</span> (13.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,420,417\u001b[0m (13.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,420,417</span> (13.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,420,417\u001b[0m (13.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34d67f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 7.6938 - val_loss: 6.5550\n",
      "Epoch 2/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 6.3165 - val_loss: 6.0783\n",
      "Epoch 3/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 5.7824 - val_loss: 5.8765\n",
      "Epoch 4/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 5.4600 - val_loss: 5.7720\n",
      "Epoch 5/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 5.2307 - val_loss: 5.7211\n",
      "Epoch 6/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 5.0438 - val_loss: 5.7006\n",
      "Epoch 7/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 4.9005 - val_loss: 5.6990\n",
      "Epoch 8/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 4.7718 - val_loss: 5.7117\n",
      "Epoch 9/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 4.6737 - val_loss: 5.7313\n",
      "Epoch 10/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 4.5743 - val_loss: 5.7557\n",
      "Epoch 11/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 4.5024 - val_loss: 5.7831\n",
      "Epoch 12/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 4.4354 - val_loss: 5.8144\n",
      "Epoch 13/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 4.3729 - val_loss: 5.8446\n",
      "Epoch 14/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 4.3235 - val_loss: 5.8756\n",
      "Epoch 15/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 4.2776 - val_loss: 5.9056\n",
      "Epoch 16/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 4.2361 - val_loss: 5.9343\n",
      "Epoch 17/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 4.2014 - val_loss: 5.9635\n",
      "Epoch 18/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 4.1649 - val_loss: 5.9912\n",
      "Epoch 19/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 4.1389 - val_loss: 6.0174\n",
      "Epoch 20/20\n",
      "\u001b[1m1729/1729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 4.1120 - val_loss: 6.0432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc260406d40>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "         epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14009f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9873dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1 = model.layers[0].get_weights()[0]\n",
    "embeddings_2 = model.layers[2].get_weights()[0].T\n",
    "embeddings = np.mean([embeddings_1, embeddings_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a2896c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.mean([embeddings_1, embeddings_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b8f0da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17017, 100)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7f2dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['птица',\n",
       " 'блестящий',\n",
       " 'птицы',\n",
       " 'телу',\n",
       " 'мифологии',\n",
       " 'населяет',\n",
       " 'грудь',\n",
       " 'красная',\n",
       " 'лошадь',\n",
       " 'семейства']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('птица', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b7ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40dac186",
   "metadata": {},
   "source": [
    "### Negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637385f3",
   "metadata": {},
   "source": [
    "Одна из основных оптимизаций в word2vec - negative sampling. Задача из многоклассовой классификации преобразуется в бинарную классификацию. На вход подается сразу и целевое слово и контекст, а на выходе ожидается вероятность того, что они употребляются вместе. Положительные примеры просто берутся из корпуса, а для того, чтобы собрать негативные примеры, из словаря просто случайно выбираются слова. Возможна ситуация, когда для контекста случайно выбранное слово на самом деле может встретиться в этом контексте, но за счет большого количества примеров, такие неточности не повлияют на итоговый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8312ee",
   "metadata": {},
   "source": [
    "В этот раз не будем сразу генерировать весь датасет. Он получается очень большой и эффективнее генерировать примеры на ходу (т.е. использовать генератор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1928254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663f708",
   "metadata": {},
   "source": [
    "Эта функция просто генерирует обучающее примеры батчами. В tf генераторы можно напрямую модавать в fit модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e850e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip gram\n",
    "def gen_batches_sg(sentences, window = 5, batch_size=1000):\n",
    "    \n",
    "    # параметр window задает его целиком\n",
    "    # нам нужно поделить его пополам на левую и правую часть\n",
    "    # когда делится неровно, то левая часть больше на 1\n",
    "    left_context_length = (window/2).__ceil__() # округлить в большую сторону\n",
    "    right_context_length = window // 2 # округлить в меньшую сторону\n",
    "    \n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length]\n",
    "                for context_word in context:\n",
    "                    X_target.append(word)\n",
    "                    X_context.append(context_word)\n",
    "                    y.append(1)\n",
    "                    \n",
    "                    X_target.append(word)\n",
    "                    X_context.append(np.random.randint(vocab_size))\n",
    "                    y.append(0)\n",
    "                    \n",
    "                    if len(X_target) >= batch_size:\n",
    "                        X_target = np.array(X_target)\n",
    "                        X_context = np.array(X_context)\n",
    "                        y = np.array(y)\n",
    "                        yield ((X_target, X_context), y)\n",
    "                        X_target = []\n",
    "                        X_context = []\n",
    "                        y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33541b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cbow \n",
    "def gen_batches_cbow(sentences, window = 5, batch_size=1000):\n",
    "    \n",
    "    # параметр window задает его целиком\n",
    "    # нам нужно поделить его пополам на левую и правую часть\n",
    "    # когда делится неровно, то левая часть больше на 1\n",
    "    left_context_length = (window/2).__ceil__() # округлить в большую сторону\n",
    "    right_context_length = window // 2 # округлить в меньшую сторону\n",
    "    \n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length]\n",
    "\n",
    "                X_target.append(word)\n",
    "                X_context.append(context)\n",
    "                y.append(1)\n",
    "                \n",
    "                X_target.append(np.random.randint(vocab_size))\n",
    "                X_context.append(context)\n",
    "                y.append(0)\n",
    "\n",
    "                if len(X_target) == batch_size:\n",
    "                    X_target = np.array(X_target)\n",
    "                    X_context = keras.preprocessing.sequence.pad_sequences(X_context, maxlen=window)\n",
    "                    y = np.array(y)\n",
    "                    yield ((X_target, X_context), y)\n",
    "                    X_target = []\n",
    "                    X_context = []\n",
    "                    y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b09b8a",
   "metadata": {},
   "source": [
    "Саму модель нужно уже задать через Functional API, т.к. у нас будет два входа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e086b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = keras.layers.Input(shape=(1,))\n",
    "inputs_context = keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "embeddings_target = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = keras.layers.Flatten()(embeddings_target)\n",
    "context = keras.layers.Flatten()(embeddings_context)\n",
    "\n",
    "dot = keras.layers.Dot(1)([target, context])\n",
    "outputs = keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "952c5ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.7613 - loss: 0.4944 - val_accuracy: 0.7941 - val_loss: 0.4570\n",
      "Epoch 2/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8194 - loss: 0.4067 - val_accuracy: 0.8252 - val_loss: 0.4014\n",
      "Epoch 3/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8246 - loss: 0.3959 - val_accuracy: 0.8263 - val_loss: 0.3881\n",
      "Epoch 4/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8324 - loss: 0.3786 - val_accuracy: 0.8434 - val_loss: 0.3696\n",
      "Epoch 5/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.8437 - loss: 0.3545 - val_accuracy: 0.8243 - val_loss: 0.4005\n",
      "Epoch 6/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8386 - loss: 0.3641 - val_accuracy: 0.8205 - val_loss: 0.4056\n",
      "Epoch 7/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8485 - loss: 0.3432 - val_accuracy: 0.8305 - val_loss: 0.3874\n",
      "Epoch 8/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8447 - loss: 0.3492 - val_accuracy: 0.8326 - val_loss: 0.3845\n",
      "Epoch 9/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8496 - loss: 0.3390 - val_accuracy: 0.8445 - val_loss: 0.3792\n",
      "Epoch 10/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 10ms/step - accuracy: 0.8544 - loss: 0.3290 - val_accuracy: 0.8170 - val_loss: 0.4233\n",
      "Epoch 11/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.8536 - loss: 0.3294 - val_accuracy: 0.8258 - val_loss: 0.4122\n",
      "Epoch 12/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 10ms/step - accuracy: 0.8584 - loss: 0.3193 - val_accuracy: 0.8145 - val_loss: 0.4384\n",
      "Epoch 13/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 10ms/step - accuracy: 0.8626 - loss: 0.3109 - val_accuracy: 0.8236 - val_loss: 0.4205\n",
      "Epoch 14/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.8597 - loss: 0.3162 - val_accuracy: 0.8461 - val_loss: 0.3727\n",
      "Epoch 15/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.8628 - loss: 0.3096 - val_accuracy: 0.8394 - val_loss: 0.4006\n",
      "Epoch 16/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.8654 - loss: 0.3035 - val_accuracy: 0.8218 - val_loss: 0.4449\n",
      "Epoch 17/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.8652 - loss: 0.3047 - val_accuracy: 0.8136 - val_loss: 0.4783\n",
      "Epoch 18/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3019 - val_accuracy: 0.8099 - val_loss: 0.4811\n",
      "Epoch 19/20\n",
      "\u001b[1m 1688/10000\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 10ms/step - accuracy: 0.8627 - loss: 0.3086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(gen_batches_sg(sentences[:19000], window=5),\n",
    "          validation_data=gen_batches_sg(sentences[19000:],  window=5),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=10000,\n",
    "          validation_steps=30,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a56360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f06af355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'часовня',\n",
       " 'деревянная',\n",
       " 'освящена',\n",
       " 'храм',\n",
       " 'католическая',\n",
       " 'колокольня',\n",
       " 'чудотворца',\n",
       " 'собор',\n",
       " 'церковно-приходская']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c539e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7255ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cbow negative sampling\n",
    "inputs_target = keras.layers.Input(shape=(1,))\n",
    "inputs_context = keras.layers.Input(shape=(10,))\n",
    "\n",
    "\n",
    "embeddings_target = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = keras.layers.Flatten()(embeddings_target)\n",
    "context = keras.layers.Lambda(lambda x: x.sum(axis=1))(embeddings_context)\n",
    "dot = keras.layers.Dot(1)([target, context])\n",
    "\n",
    "# полученную близость нужно преобразовать в вероятность\n",
    "# когда она одна используется не софтмакс и сигмоида\n",
    "outputs = keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e1adc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build([(None, 1), (None, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36a09425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.7973 - loss: 0.4338 - val_accuracy: 0.8728 - val_loss: 0.3006\n",
      "Epoch 2/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 14ms/step - accuracy: 0.8793 - loss: 0.2873 - val_accuracy: 0.8899 - val_loss: 0.2625\n",
      "Epoch 3/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.9147 - loss: 0.2089 - val_accuracy: 0.8850 - val_loss: 0.2831\n",
      "Epoch 4/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.9317 - loss: 0.1741 - val_accuracy: 0.9030 - val_loss: 0.2496\n",
      "Epoch 5/20\n",
      "\u001b[1m1862/5000\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 14ms/step - accuracy: 0.9367 - loss: 0.1640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(gen_batches_cbow(sentences[:19000], window=10),\n",
    "          validation_data=gen_batches_cbow(sentences[19000:],  window=10),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=5000,\n",
    "          validation_steps=30,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "778836d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "953fe0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['семья',\n",
       " 'бабушка',\n",
       " 'жил',\n",
       " 'жена',\n",
       " 'мать',\n",
       " 'умерла',\n",
       " 'жила',\n",
       " 'едет',\n",
       " 'родители',\n",
       " 'сестра']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('семья', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07e6b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'церкви',\n",
       " 'освящена',\n",
       " 'часовня',\n",
       " 'храм',\n",
       " 'колокольня',\n",
       " 'храме',\n",
       " 'башня',\n",
       " 'обитель',\n",
       " 'часовни']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc9cac",
   "metadata": {},
   "source": [
    "Другая значимая оптимизация в word2vec - это иерархический софтмакс. Когда мы считали модель без негативного семплирования, то у нас был большой полносвязный слой с софтмаксом. Иерархический софтмакс упрощает расчеты в этом слое, но его уже так просто не воспроизведешь.\n",
    "\n",
    "На этом месте уже лучше перейти к готовой реализации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af3bf3",
   "metadata": {},
   "source": [
    "## Word2Vec в gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b28433",
   "metadata": {},
   "source": [
    "В gensim есть питоновская обертка к оригинальному ворд2веку, которой очень удобно пользоваться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90fa2ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.18.5 in ./.pyenv/versions/3.10.12/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, scipy, smart-open, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "Successfully installed gensim-4.3.3 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d916424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b744492",
   "metadata": {},
   "outputs": [],
   "source": [
    "?gensim.models.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a942a031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3.3'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414972b",
   "metadata": {},
   "source": [
    "На вход нужно подавать список списков (токенизированный текст)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28b573f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = open('wiki_data.txt', encoding='utf8').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "912f3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [preprocess(text) for text in wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce4b4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('corpus.txt', 'w')\n",
    "# for text in texts:\n",
    "#     f.write(' '.join(text) + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "118e3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = gensim.models.word2vec.LineSentence('corpus.txt', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91051ba2",
   "metadata": {},
   "source": [
    "В саму модель нужно передать корпус для обучения, для остальных параметров есть значения по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71504b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.2 s, sys: 315 ms, total: 49.5 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "524499f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.8651555776596069),\n",
       " ('деревянная', 0.8352618217468262),\n",
       " ('православная', 0.8248554468154907),\n",
       " ('построена', 0.8136454224586487),\n",
       " ('богородицы', 0.8076602220535278),\n",
       " ('храм', 0.8026599884033203),\n",
       " ('построенная', 0.7980923652648926),\n",
       " ('икона', 0.7936535477638245),\n",
       " ('каменная', 0.7826864123344421),\n",
       " ('сгорела', 0.7807881236076355)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363b11e",
   "metadata": {},
   "source": [
    "Давайте теперь разберемся с параметрами:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6128bdd",
   "metadata": {},
   "source": [
    "**vector_size** - размер вектора, обычно используют значение 100-1000  \n",
    "\n",
    "**min_count** - минимальная частота слова в корпусе (выше мы тоже фильтровали по частототе 30)  \n",
    "\n",
    "**max_vocab_size** - максимальный размер словаря\n",
    "\n",
    "**window** - размер окна (выше мы использовали значение 10)\n",
    "\n",
    "**epochs** - количество эпох (полных итераций по корпусу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ea31ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.5 s, sys: 304 ms, total: 32.8 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=5,\n",
    "                             epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "304b59ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('храм', 0.7227203845977783),\n",
       " ('церкви', 0.6670523285865784),\n",
       " ('монастырь', 0.6666553020477295),\n",
       " ('храма', 0.6559574007987976),\n",
       " ('монастыря', 0.6513762474060059),\n",
       " ('святого', 0.6477090120315552),\n",
       " ('собор', 0.6293389797210693),\n",
       " ('собора', 0.611802339553833),\n",
       " ('николая', 0.5815112590789795),\n",
       " ('святой', 0.5636858344078064)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004aa64a",
   "metadata": {},
   "source": [
    "CBOW или Skip-gram выбираются через параметр **sg** - 1 это skip-gram, а 0 - cbow (по умолчанию всегда cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6982b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 1.33 s, total: 1min 57s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=5,\n",
    "                             epochs=7,\n",
    "                             sg=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516ad01",
   "metadata": {},
   "source": [
    "Скип-грам обучается значительно дольше "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "240d2fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('храм', 0.6079998016357422),\n",
       " ('церкви', 0.5468794703483582),\n",
       " ('храма', 0.5208911299705505),\n",
       " ('монастырь', 0.5143125653266907),\n",
       " ('монастыря', 0.5023179054260254),\n",
       " ('собор', 0.4994029700756073),\n",
       " ('епархии', 0.47104665637016296),\n",
       " ('собора', 0.46670249104499817),\n",
       " ('школа', 0.445218563079834),\n",
       " ('здание', 0.4337330460548401)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180b31b",
   "metadata": {},
   "source": [
    "Увеличения window на cbow практически не влияет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a6b81c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.5 s, sys: 1.36 s, total: 39.9 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=10,\n",
    "                             epochs=7,\n",
    "                             \n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a6dc5",
   "metadata": {},
   "source": [
    "А вот skip-gram сильно замедляется с увеличением окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6cef32e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 23s, sys: 156 ms, total: 3min 24s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=10,\n",
    "                             epochs=7,\n",
    "                             sg=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d046d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9ec418",
   "metadata": {},
   "source": [
    "Выбор между negative_sampling и hierarchical softmax осуществляется через 2 параметра **hs** и **negative**:   \n",
    "1) **hs=0, negative=0** - ни то ни другое не используется (такой вариант больше не работает и выдаст ошибку)\n",
    "2) **hs=1, negative > 0** - оба вариант использовать сразу тоже нельзя (будет ошибка)\n",
    "3) **hs=1** - используется hierarchical softmax  \n",
    "4) **hs=0, negative > 0** - используется negative_sampling и число в negative указывает сколько негативных примеров семплировать (в документации советуют значения от 5 до 20)  (по умолчанию)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008e899",
   "metadata": {},
   "source": [
    "Иерархический софтмакс работает сильно дольше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b9c0725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 589 ms, total: 1min 48s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             hs=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ea742df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.7849513292312622),\n",
       " ('храм', 0.736535906791687),\n",
       " ('церкви', 0.7256388664245605),\n",
       " ('колокольня', 0.7013624310493469),\n",
       " ('богородицы', 0.6818711757659912),\n",
       " ('деревянная', 0.6781814098358154),\n",
       " ('монастырь', 0.6779229044914246),\n",
       " ('собор', 0.6721178889274597),\n",
       " ('храма', 0.668960452079773),\n",
       " ('монастыря', 0.6659947633743286)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c3a389",
   "metadata": {},
   "source": [
    "Дефолтная настройка работает достаточно быстро и хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bbc7b815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.3 s, sys: 1.44 s, total: 50.7 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             hs=0,\n",
    "                             negative=5\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "266440a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.8494033217430115),\n",
       " ('деревянная', 0.8314069509506226),\n",
       " ('православная', 0.822441577911377),\n",
       " ('богородицы', 0.8182085156440735),\n",
       " ('сгорела', 0.8107843399047852),\n",
       " ('построена', 0.8026164174079895),\n",
       " ('храм', 0.7991946935653687),\n",
       " ('икона', 0.7940052151679993),\n",
       " ('построенная', 0.7928877472877502),\n",
       " ('пресвятой', 0.7911669015884399)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da5a8c",
   "metadata": {},
   "source": [
    "Повышение negative влияет на время обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ee61c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 3s, sys: 1.31 s, total: 2min 5s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             hs=0,\n",
    "                             negative=20\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c297b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.8639755249023438),\n",
       " ('деревянная', 0.8495493531227112),\n",
       " ('храм', 0.7956300377845764),\n",
       " ('каменная', 0.7871893048286438),\n",
       " ('богородицы', 0.773190975189209),\n",
       " ('построена', 0.7720847129821777),\n",
       " ('православная', 0.7709619402885437),\n",
       " ('построенная', 0.7666776180267334),\n",
       " ('икона', 0.7636901140213013),\n",
       " ('монастыря', 0.7607771158218384)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a7e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6b5357b",
   "metadata": {},
   "source": [
    "Есть еще несколько параметров, но уже не таких влиятельных:\n",
    "\n",
    "1) **sample** - отвечает за downsampling частотных слов; чем меньше, тем сильнее штрафуются частотные слова (по умолчанию стоит 1e-3, но можно поставить 1e-4, 1e-5). Для sg это будет значительно влиять на скорость (1e-5 будет быстрее)  \n",
    "2) **ns_exponent** -  регулирет downsampling частотных слов в negative sampling; 0 - никакого штрафа за частотность (как у нас выше с полным рандомом), 1 - штрафует пропорционально частотности, значения 0-1 что-то посередине (по умолчанию стоит 0.75)  \n",
    "3) **cbow_mean** - отвечает за функцию агрегации в cbow; 1 - это среднее, 0 - сумма (у нас выше среднее, оно же стоит по умолчанию)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d1a5345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 1.39 s, total: 1min 50s\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             sample=1e-5,\n",
    "                             sg=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c3928c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('храме', 0.9547567963600159),\n",
       " ('часовня', 0.9543980360031128),\n",
       " ('храм', 0.9467794895172119),\n",
       " ('храма', 0.9397324323654175),\n",
       " ('деревянная', 0.9327934980392456),\n",
       " ('богородицы', 0.9293968677520752),\n",
       " ('рождества', 0.9282155632972717),\n",
       " ('пресвятой', 0.9240129590034485),\n",
       " ('собор', 0.9221513867378235),\n",
       " ('монастыря', 0.9205843210220337)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a6e9b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.6 s, sys: 1.45 s, total: 49 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             ns_exponent=0.84\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "29ad129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.8568798899650574),\n",
       " ('деревянная', 0.8148678541183472),\n",
       " ('монастыря', 0.7994199395179749),\n",
       " ('храм', 0.7984759211540222),\n",
       " ('монастырь', 0.7837903499603271),\n",
       " ('построена', 0.7834742069244385),\n",
       " ('православная', 0.78226238489151),\n",
       " ('построенная', 0.7800700068473816),\n",
       " ('монастыре', 0.7776835560798645),\n",
       " ('церкви', 0.7735159993171692)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2fda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fd8c2eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.9 s, sys: 1.49 s, total: 50.4 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             cbow_mean=0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c08ade15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('деревянная', 0.9390289187431335),\n",
       " ('пресвятой', 0.9179673194885254),\n",
       " ('часовня', 0.9178574085235596),\n",
       " ('икона', 0.917452335357666),\n",
       " ('построена', 0.9148412346839905),\n",
       " ('богородицы', 0.9073116779327393),\n",
       " ('каменная', 0.9025301337242126),\n",
       " ('рождества', 0.9015204906463623),\n",
       " ('покрова', 0.8999919891357422),\n",
       " ('колокольня', 0.898392915725708)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31490cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f383ad3",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a79c3b",
   "metadata": {},
   "source": [
    "В 2015 почти та же команда выпустила улучшение - FastText (статья - https://arxiv.org/abs/1607.04606). Главная доработка в нем - использование символьных нграммов. В оригинальном word2vec словарь обучается вначале и фиксируется, добавлять новые слова к обученной модели нельзя. Соответственно, если слова нет в словаре, то и вектора для него не будет.\n",
    "\n",
    "В FastText каждое слово дополнительно разбивается на символьные нграммы и для каждого символьного нграмма тоже есть свой отдельный эмбеддинг. При предсказании векторы символьных нграммов и целого слова усредняются в 1 вектор. В дальнейшем это позволяет генерировать векторы для слов, которых нет в изначальном словаре. Нужно только чтобы новое слово состояло уже из известных символьных нграмм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17faa699",
   "metadata": {},
   "source": [
    "Интерфейс обучения и большинство параметров - точно такие же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ea91a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 1.51 s, total: 3min 9s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ab1e1",
   "metadata": {},
   "source": [
    "Использование символьных нграммов сразу заметно - близким считаются слова похожие по написанию, а не только по смыслу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b43dc9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('«церковь', 0.9910555481910706),\n",
       " ('церковь»', 0.9898117184638977),\n",
       " ('це́рковь', 0.9607942700386047),\n",
       " ('церковью', 0.955873429775238),\n",
       " ('церкви»', 0.8924383521080017),\n",
       " ('церкви', 0.8922922611236572),\n",
       " ('церквям', 0.883606493473053),\n",
       " ('храма', 0.8380062580108643),\n",
       " ('храму', 0.8229991793632507),\n",
       " ('церквях', 0.8180660009384155)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b70a2",
   "metadata": {},
   "source": [
    "Дополнительные параметры:\n",
    "\n",
    "1) **min_n** - минимальная длина для символьных нграмм (по умолчанию 3)  \n",
    "2) **max_n** - максимальная длина для символьных нграмм, если поставить меньше min_n, то символьные нграммы не будут использоваться (по умолчанию 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "454cde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min, sys: 1.57 s, total: 5min 1s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts, min_n=2, max_n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f0df4504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('це́рковь', 0.9453999400138855),\n",
       " ('«церковь', 0.9243606925010681),\n",
       " ('церковь»', 0.9182398915290833),\n",
       " ('церковью', 0.9173147082328796),\n",
       " ('церкви', 0.8104711174964905),\n",
       " ('монастырь', 0.8009973764419556),\n",
       " ('церкви»', 0.7830296754837036),\n",
       " ('монастыря', 0.7825708389282227),\n",
       " ('монастырская', 0.7750605344772339),\n",
       " ('церковная', 0.7708677649497986)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5badb355",
   "metadata": {},
   "source": [
    "### Использование предобученных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc374a8f",
   "metadata": {},
   "source": [
    "В открытом доступе есть много предобученных моделей. Они как правило обучены на неспецифических, но очень больших корпусах (новостных, википедии). Если в решаемой задаче тексты похожи, то лучше использовать предобученные модели. Свои модели имеет смысл обучать, когда данные очень специфичные.\n",
    "\n",
    "Для русского готовые модели можно взять на сайте https://rusvectores.org/ru/models/ \n",
    "\n",
    "Нужно скачать какую-то модель, распаковать и открыть в генсиме.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ba007936-ed21-4d1b-94d9-5e4eb0b7f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-18 14:36:48--  https://rusvectores.org/static/models/rusvectores4/araneum/araneum_upos_skipgram_300_2_2018.vec.gz\n",
      "Resolving rusvectores.org (rusvectores.org)... 172.104.228.108\n",
      "Connecting to rusvectores.org (rusvectores.org)|172.104.228.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 201589983 (192M) [application/x-gzip]\n",
      "Saving to: ‘araneum_upos_skipgram_300_2_2018.vec.gz’\n",
      "\n",
      "araneum_upos_skipgr 100%[===================>] 192.25M  17.6MB/s    in 14s     \n",
      "\n",
      "2024-12-18 14:37:03 (13.4 MB/s) - ‘araneum_upos_skipgram_300_2_2018.vec.gz’ saved [201589983/201589983]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://rusvectores.org/static/models/rusvectores4/araneum/araneum_upos_skipgram_300_2_2018.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca5600-1a91-4caf-9818-6d1ba911364d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5e2684a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# я скачал вот эту araneum_upos_skipgram_300_2_2018 \n",
    "# и распаковал архив в папку с ноутбуком\n",
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('araneum_upos_skipgram_300_2_2018.vec.gz', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "be30d5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.077049,  0.047464,  0.06009 , -0.074989,  0.044796, -0.001967,\n",
       "       -0.029693,  0.043408,  0.064917, -0.040833, -0.061425, -0.029607,\n",
       "       -0.029905,  0.064318, -0.165209, -0.048543,  0.094033,  0.098251,\n",
       "        0.120046,  0.023853,  0.016249, -0.015089, -0.05077 , -0.01809 ,\n",
       "       -0.064637, -0.039266, -0.022106, -0.019366,  0.016014, -0.051354,\n",
       "        0.046586, -0.024155,  0.062748,  0.000681,  0.05134 ,  0.049167,\n",
       "        0.005723, -0.072041, -0.049427, -0.094474, -0.075772,  0.087238,\n",
       "       -0.023207, -0.043947, -0.005014,  0.048574, -0.008169, -0.016334,\n",
       "       -0.006644,  0.026402,  0.046584, -0.040629,  0.008602,  0.047264,\n",
       "        0.00828 ,  0.089396, -0.030152, -0.011632,  0.016811,  0.081198,\n",
       "       -0.042167, -0.004215,  0.079515,  0.061092,  0.065421, -0.090715,\n",
       "       -0.07259 ,  0.061831,  0.036428,  0.024443,  0.040917,  0.043281,\n",
       "        0.050277,  0.02531 ,  0.040681, -0.073628,  0.032021, -0.020285,\n",
       "       -0.001634, -0.073642, -0.092016, -0.010889,  0.014986,  0.083961,\n",
       "       -0.037115,  0.073271,  0.003354, -0.020166, -0.011193, -0.153913,\n",
       "        0.077515,  0.048687, -0.10863 ,  0.080093,  0.04904 , -0.015638,\n",
       "       -0.011593,  0.023486, -0.054422, -0.019362,  0.060243,  0.004193,\n",
       "        0.055972,  0.02419 , -0.035099, -0.037713, -0.05796 ,  0.044854,\n",
       "       -0.009581,  0.006213,  0.091667,  0.035143, -0.058419, -0.077955,\n",
       "        0.010467, -0.045589,  0.067338,  0.049547,  0.028813, -0.053835,\n",
       "       -0.040958, -0.059349, -0.051708, -0.01979 ,  0.060717, -0.064267,\n",
       "        0.000969,  0.010098,  0.007866,  0.037205, -0.035548,  0.031603,\n",
       "       -0.101909,  0.016248,  0.004228, -0.029127, -0.102244,  0.03937 ,\n",
       "       -0.011886, -0.048208, -0.040977,  0.017401,  0.041162, -0.030116,\n",
       "       -0.074647, -0.031459, -0.001456,  0.049032,  0.099571, -0.049697,\n",
       "        0.000542, -0.01695 ,  0.043604, -0.017133, -0.003281, -0.002051,\n",
       "       -0.068998,  0.010618, -0.051367, -0.080354,  0.016654,  0.029355,\n",
       "       -0.044999, -0.08382 , -0.067588,  0.007303,  0.018462,  0.047438,\n",
       "       -0.132176,  0.01172 ,  0.030804, -0.001147, -0.097051, -0.013091,\n",
       "       -0.051683,  0.107505,  0.001299,  0.081465, -0.106922, -0.02635 ,\n",
       "       -0.060651, -0.015804, -0.090327,  0.01674 , -0.019938,  0.053004,\n",
       "        0.0802  ,  0.075273, -0.011325,  0.104902,  0.118813,  0.014863,\n",
       "       -0.031739, -0.036848,  0.007057, -0.017402,  0.023001,  0.044251,\n",
       "        0.004787,  0.08071 , -0.158897, -0.081702, -0.040502, -0.022916,\n",
       "        0.022795, -0.027717,  0.046067,  0.029809, -0.050003, -0.033388,\n",
       "       -0.007351, -0.045664, -0.089034, -0.038753, -0.00454 , -0.072393,\n",
       "        0.023547,  0.028502, -0.019941,  0.036289, -0.054831,  0.03609 ,\n",
       "        0.117796, -0.036494,  0.054533,  0.010218, -0.05965 , -0.041402,\n",
       "        0.061536,  0.061666, -0.086688,  0.004461, -0.065211, -0.196897,\n",
       "       -0.064875, -0.000384,  0.00934 , -0.018347,  0.016305,  0.00207 ,\n",
       "        0.025788,  0.025661, -0.024847,  0.001329,  0.017222,  0.023123,\n",
       "        0.020163,  0.037764,  0.097089, -0.076315,  0.062176,  0.074422,\n",
       "       -0.104194, -0.054039,  0.004654,  0.034065,  0.054541,  0.022959,\n",
       "        0.040029,  0.037736, -0.041228, -0.077804,  0.103979, -0.055198,\n",
       "        0.032196,  0.020032,  0.055866, -0.03335 ,  0.064627, -0.117019,\n",
       "       -0.019819, -0.091563,  0.016277, -0.158784,  0.090109,  0.052189,\n",
       "        0.026157,  0.043388,  0.09961 ,  0.040325,  0.01243 ,  0.062557,\n",
       "       -0.112546, -0.045751,  0.071704, -0.02192 , -0.028775, -0.010755,\n",
       "       -0.102415,  0.036397, -0.141866, -0.00391 ,  0.008874, -0.055684,\n",
       "       -0.062073, -0.0665  , -0.090125,  0.026231,  0.029068, -0.121298],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['март_NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bb122eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('март_NOUN', 0.9506458044052124),\n",
       " ('ноябрь_NOUN', 0.9416142702102661),\n",
       " ('декабрь_NOUN', 0.9391436576843262),\n",
       " ('январь_NOUN', 0.9299512505531311),\n",
       " ('апрель_NOUN', 0.9271649718284607),\n",
       " ('октябрь_NOUN', 0.9204078316688538),\n",
       " ('сентябрь_NOUN', 0.9028568267822266),\n",
       " ('май_NOUN', 0.8944932222366333),\n",
       " ('июнь_NOUN', 0.8860151767730713),\n",
       " ('марта_NOUN', 0.8700184226036072)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('февраль_NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f36dd",
   "metadata": {},
   "source": [
    "Слова в модели хранятся в нормализованном виде с прибавленной частью речи. Для пребобработки там использовался udpipe, вызывать его в тетрадке неудобно, поэтому можно заменить его на майстем (по большей части все будет совпадать). На сайте есть ссылка на файл с соответствием тэгов майстема тэгам Udpipe (https://github.com/akutuzov/universal-pos-tags/blob/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8903ed8c-233c-4e37-8946-b02d138f63ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-18 14:41:12--  https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4093 (4.0K) [text/plain]\n",
      "Saving to: ‘ru-rnc.map’\n",
      "\n",
      "ru-rnc.map          100%[===================>]   4.00K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-12-18 14:41:12 (77.8 MB/s) - ‘ru-rnc.map’ saved [4093/4093]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2d5dcca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "\n",
    "for line in open('./ru-rnc.map'):\n",
    "    ms, ud = line.strip('\\n').split()\n",
    "    mapping[ms] = ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a590f675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'ADJ',\n",
       " 'ADV': 'ADV',\n",
       " 'ADVPRO': 'ADV',\n",
       " 'ANUM': 'ADJ',\n",
       " 'APRO': 'DET',\n",
       " 'COM': 'ADJ',\n",
       " 'CONJ': 'SCONJ',\n",
       " 'INTJ': 'INTJ',\n",
       " 'NONLEX': 'X',\n",
       " 'NUM': 'NUM',\n",
       " 'PART': 'PART',\n",
       " 'PR': 'ADP',\n",
       " 'S': 'NOUN',\n",
       " 'SPRO': 'PRON',\n",
       " 'UNKN': 'X',\n",
       " 'V': 'VERB'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "67203ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d09b0994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /home/ubuntu/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a189810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_mystem(text):\n",
    "    tokens = []\n",
    "    norm_words = m.analyze(text)\n",
    "    for norm_word in norm_words:\n",
    "        if 'analysis' not in norm_word:\n",
    "            continue\n",
    "            \n",
    "        if not len(norm_word['analysis']):\n",
    "            lemma = norm_word['text']\n",
    "            pos = 'UNKN'\n",
    "        else:\n",
    "            lemma = norm_word[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = norm_word[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "        pos = mapping[pos]\n",
    "        tokens.append(lemma+'_'+pos)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5490ed",
   "metadata": {},
   "source": [
    "Эту функцию можно применять к любому тексты и получать на выходе токены, по которым можно обращаться к модели напрямую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fd4cbd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['обучать_VERB',\n",
       " 'классификатор_NOUN',\n",
       " 'парафраз_NOUN',\n",
       " 'на_ADP',\n",
       " 'предобученный_ADJ',\n",
       " 'модель_NOUN',\n",
       " 'вы_PRON',\n",
       " 'нужно_ADV',\n",
       " 'быть_VERB',\n",
       " 'дома_ADV']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_mystem('Обучить классификатор парафразов на предобученной модели вам нужно будет дома')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2e4f1b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['обучать_VERB'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1ff00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38dee586",
   "metadata": {},
   "source": [
    "## Использование для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ecfe1f",
   "metadata": {},
   "source": [
    "До этого мы почти никак не оценивали качество эмбедингов, только смотрели на ближайшие по нескольким словам. На практике нужно всегда ориентироваться на задачу, которую нужно решить. Давайте возьмем датасет для классификации и обучим несколько моделей с использованием векторных представлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "df109f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f85b7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['norm_text'] = data.comment.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a9ae9e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[верблюдов-то, за, что, дебилы, бл]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[хохлы, это, отдушина, затюканого, россиянина,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[собаке, собачья, смерть]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[страницу, обнови, дебил, это, тоже, не, оскор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[тебя, не, убедил, 6-страничный, пдф, в, том, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[вонючий, совковый, скот, прибежал, и, ноет, а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[а, кого, любить, гоблина, тупорылого, что-ли,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[посмотрел, утомленных, солнцем, 2, и, оказало...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[крымотред, нарушает, правила, раздела, т.к, в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[до, сих, пор, пересматриваю, его, видео, орам...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic  \\\n",
       "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0   \n",
       "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0   \n",
       "2                              Собаке - собачья смерть\\n    1.0   \n",
       "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0   \n",
       "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0   \n",
       "...                                                  ...    ...   \n",
       "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0   \n",
       "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0   \n",
       "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0   \n",
       "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0   \n",
       "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0   \n",
       "\n",
       "                                               norm_text  \n",
       "0                    [верблюдов-то, за, что, дебилы, бл]  \n",
       "1      [хохлы, это, отдушина, затюканого, россиянина,...  \n",
       "2                              [собаке, собачья, смерть]  \n",
       "3      [страницу, обнови, дебил, это, тоже, не, оскор...  \n",
       "4      [тебя, не, убедил, 6-страничный, пдф, в, том, ...  \n",
       "...                                                  ...  \n",
       "14407  [вонючий, совковый, скот, прибежал, и, ноет, а...  \n",
       "14408  [а, кого, любить, гоблина, тупорылого, что-ли,...  \n",
       "14409  [посмотрел, утомленных, солнцем, 2, и, оказало...  \n",
       "14410  [крымотред, нарушает, правила, раздела, т.к, в...  \n",
       "14411  [до, сих, пор, пересматриваю, его, видео, орам...  \n",
       "\n",
       "[14412 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801380ad",
   "metadata": {},
   "source": [
    "Также как и в начале собираем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5e6f3dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7231"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in data['norm_text']:\n",
    "    vocab.update(text)\n",
    "    \n",
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 5:\n",
    "        filtered_vocab.add(word)\n",
    "\n",
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5600572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = { 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)\n",
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34a3b8",
   "metadata": {},
   "source": [
    "Переводим слова в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "de33c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for tokens in data['norm_text']:\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ecbca663",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(X, maxlen=100)\n",
    "y = data.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703e724",
   "metadata": {},
   "source": [
    "Разбиваем на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0997f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "435e8ed5",
   "metadata": {},
   "source": [
    "Теперь мы можем уже обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "90385246",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs, )\n",
    "# embedding слой возвращает последовательность векторов\n",
    "# а нам нужно классифицировать сразу весь текст\n",
    "# стандартный подход в этом случае - усреднить единичные вектора в 1 вектор текста\n",
    "mean = keras.layers.Lambda(lambda x: x.mean(axis=1))(embeddings)\n",
    "# к усредненному вектору мы уже применяем полносвязный слой, который вернет вероятность токсичности\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "84de337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6675 - loss: 0.6404 - val_accuracy: 0.6616 - val_loss: 0.5944\n",
      "Epoch 2/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6764 - loss: 0.5616 - val_accuracy: 0.7074 - val_loss: 0.5242\n",
      "Epoch 3/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.4860 - val_accuracy: 0.7795 - val_loss: 0.4562\n",
      "Epoch 4/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8271 - loss: 0.4059 - val_accuracy: 0.8058 - val_loss: 0.4155\n",
      "Epoch 5/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.3533 - val_accuracy: 0.8530 - val_loss: 0.3868\n",
      "Epoch 6/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.3125 - val_accuracy: 0.8391 - val_loss: 0.3732\n",
      "Epoch 7/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8913 - loss: 0.2876 - val_accuracy: 0.8447 - val_loss: 0.3593\n",
      "Epoch 8/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.2695 - val_accuracy: 0.8613 - val_loss: 0.3511\n",
      "Epoch 9/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2451 - val_accuracy: 0.8488 - val_loss: 0.3529\n",
      "Epoch 10/10\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2292 - val_accuracy: 0.8571 - val_loss: 0.3480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc3c5255c90>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4fc1c",
   "metadata": {},
   "source": [
    "В этой модели векторные представления обучаются с нуля. Можно подставить в Embedding слой уже готовые вектора из word2vec/fastext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a1a4",
   "metadata": {},
   "source": [
    "Обучаем fastext. Можно обучать на размеченных данных, можно использовать другой более объемный корпус (например, вики, который мы использовали выше), а можно и на том и на другом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b664e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 8s, sys: 678 ms, total: 10min 9s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts + data['norm_text'].values.tolist(), window=10, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e45c8d",
   "metadata": {},
   "source": [
    "Теперь нам нужно сделать матрицу с векторами. Индексы строчек в этой матрице должны совпадать с индексами слов в словаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "098485ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((len(word2id), 100))\n",
    "\n",
    "for word, i in word2id.items():\n",
    "    # вектор паддинга оставим нулевым\n",
    "    if word == 'PAD':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        weights[i] = ft.wv[word]\n",
    "    \n",
    "    \n",
    "    except KeyError:\n",
    "        # для слов, которых нет в модели тоже возьмем какой-то  рандомный вектор\n",
    "        continue\n",
    "        weights[i] = ft.wv['опрагпллирао']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e703d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = keras.layers.Input(shape=(100,))\n",
    "\n",
    "# передаем матрицу в эмбединг слой\n",
    "# указываем параметр trainable=False, чтобы вектора не обучались\n",
    "# Пояснение: кажется, что обучение векторов отключать не стоит, так как модель должна взять готовые \n",
    "# эмбединги и подогнать их к нашей задаче. На практитке это однако не работает - эмбединги просто \n",
    "# # обучатся заново\n",
    "embeddings = keras.layers.Embedding(input_dim=len(word2id), output_dim=100, \n",
    "                                       trainable=False,\n",
    "                                       weights=[weights])(inputs, )\n",
    "mean = keras.layers.Lambda(lambda x: x.mean(axis=1))(embeddings)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8459b5",
   "metadata": {},
   "source": [
    "Так как слой с эмбедингами не обучается, вся модель обучается сильно быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0e7f4630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5633 - loss: 0.6813 - val_accuracy: 0.6616 - val_loss: 0.6027\n",
      "Epoch 2/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.5818 - val_accuracy: 0.6949 - val_loss: 0.5704\n",
      "Epoch 3/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6858 - loss: 0.5664 - val_accuracy: 0.7115 - val_loss: 0.5539\n",
      "Epoch 4/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7038 - loss: 0.5511 - val_accuracy: 0.7129 - val_loss: 0.5432\n",
      "Epoch 5/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.5375 - val_accuracy: 0.7212 - val_loss: 0.5354\n",
      "Epoch 6/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7246 - loss: 0.5287 - val_accuracy: 0.7240 - val_loss: 0.5280\n",
      "Epoch 7/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7342 - loss: 0.5211 - val_accuracy: 0.7198 - val_loss: 0.5231\n",
      "Epoch 8/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.5201 - val_accuracy: 0.7268 - val_loss: 0.5190\n",
      "Epoch 9/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7451 - loss: 0.5090 - val_accuracy: 0.7379 - val_loss: 0.5142\n",
      "Epoch 10/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.5074 - val_accuracy: 0.7337 - val_loss: 0.5113\n",
      "Epoch 11/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.5088 - val_accuracy: 0.7406 - val_loss: 0.5078\n",
      "Epoch 12/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.5003 - val_accuracy: 0.7462 - val_loss: 0.5050\n",
      "Epoch 13/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7540 - loss: 0.5030 - val_accuracy: 0.7420 - val_loss: 0.5036\n",
      "Epoch 14/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.5005 - val_accuracy: 0.7490 - val_loss: 0.5010\n",
      "Epoch 15/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 0.4890 - val_accuracy: 0.7503 - val_loss: 0.4985\n",
      "Epoch 16/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.4953 - val_accuracy: 0.7559 - val_loss: 0.4969\n",
      "Epoch 17/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7639 - loss: 0.4971 - val_accuracy: 0.7531 - val_loss: 0.4958\n",
      "Epoch 18/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.4893 - val_accuracy: 0.7573 - val_loss: 0.4943\n",
      "Epoch 19/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4886 - val_accuracy: 0.7559 - val_loss: 0.4929\n",
      "Epoch 20/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.4867 - val_accuracy: 0.7517 - val_loss: 0.4929\n",
      "Epoch 21/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7718 - loss: 0.4807 - val_accuracy: 0.7656 - val_loss: 0.4899\n",
      "Epoch 22/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7675 - loss: 0.4857 - val_accuracy: 0.7573 - val_loss: 0.4895\n",
      "Epoch 23/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.4811 - val_accuracy: 0.7684 - val_loss: 0.4877\n",
      "Epoch 24/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7723 - loss: 0.4800 - val_accuracy: 0.7614 - val_loss: 0.4868\n",
      "Epoch 25/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7658 - loss: 0.4824 - val_accuracy: 0.7642 - val_loss: 0.4858\n",
      "Epoch 26/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7707 - loss: 0.4787 - val_accuracy: 0.7587 - val_loss: 0.4852\n",
      "Epoch 27/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.4776 - val_accuracy: 0.7628 - val_loss: 0.4841\n",
      "Epoch 28/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7683 - loss: 0.4762 - val_accuracy: 0.7670 - val_loss: 0.4835\n",
      "Epoch 29/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7750 - loss: 0.4745 - val_accuracy: 0.7642 - val_loss: 0.4825\n",
      "Epoch 30/30\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 0.4832 - val_accuracy: 0.7642 - val_loss: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc299556500>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "         epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d9d51",
   "metadata": {},
   "source": [
    "Качество получается хуже, но скорее всего это из-за того, что обучающих данных слишком мало для fastext'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "afaaac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAHHCAYAAAC4BYz1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB22UlEQVR4nO3deVxU9f7H8dewbwICsogouO+aG5m2W1ZmamValkvbL7MyvXXVStu1utW17WZ1NatrapqWpVmmaWXmmrvivguCCMgOM+f3x5FRApVlYEDez8djHsyc+Z7v+Zy5c51P39ViGIaBiIiISA3j4uwARERERJxBSZCIiIjUSEqCREREpEZSEiQiIiI1kpIgERERqZGUBImIiEiNpCRIREREaiQlQSIiIlIjKQkSERGRGklJkIhUqgMHDmCxWJg+fXqpz12+fDkWi4Xly5c7PC4RqXmUBImIiEiNpCRIREREaiQlQSIiTpaRkeHsEERqJCVBIjXMCy+8gMViYdeuXdx7770EBARQp04dxo8fj2EYHD58mD59+uDv7094eDhvvfVWkTpOnDjBAw88QFhYGF5eXrRr147PPvusSLmUlBSGDh1KQEAAgYGBDBkyhJSUlGLj2rlzJ3feeSdBQUF4eXnRqVMnFixYUKZ7PHjwII8++ijNmjXD29ub4OBg+vfvz4EDB4qNcdSoUURHR+Pp6Um9evUYPHgwSUlJ9jLZ2dm88MILNG3aFC8vLyIiIrj99tvZu3cvcP6xSsWNfxo6dCh+fn7s3buXW265hVq1ajFo0CAAfvvtN/r370/9+vXx9PQkKiqKUaNGkZWVVeznddddd1GnTh28vb1p1qwZzz77LAC//PILFouF+fPnFznvyy+/xGKxsGrVqtJ+rCKXHDdnByAizjFgwABatGjBa6+9xsKFC3nllVcICgrio48+4rrrruP1119nxowZPPXUU3Tu3JmrrroKgKysLK655hr27NnDY489RkxMDHPmzGHo0KGkpKQwcuRIAAzDoE+fPvz+++888sgjtGjRgvnz5zNkyJAisWzbto1u3boRGRnJ2LFj8fX15auvvqJv3758/fXX9OvXr1T3tnbtWv744w8GDhxIvXr1OHDgAB9++CHXXHMN27dvx8fHB4D09HSuvPJKduzYwf3330+HDh1ISkpiwYIFHDlyhJCQEKxWK7feeitLly5l4MCBjBw5ktOnT7NkyRK2bt1Ko0aNSv3Z5+fn07NnT7p3786bb75pj2fOnDlkZmYyfPhwgoODWbNmDe+99x5Hjhxhzpw59vM3b97MlVdeibu7Ow8//DDR0dHs3buX7777jldffZVrrrmGqKgoZsyYUeSzmzFjBo0aNaJr166ljlvkkmOISI3y/PPPG4Dx8MMP24/l5+cb9erVMywWi/Haa6/Zj586dcrw9vY2hgwZYj82efJkAzD+97//2Y/l5uYaXbt2Nfz8/Iy0tDTDMAzjm2++MQDjjTfeKHSdK6+80gCMTz/91H78+uuvN9q0aWNkZ2fbj9lsNuOKK64wmjRpYj/2yy+/GIDxyy+/XPAeMzMzixxbtWqVARiff/65/diECRMMwJg3b16R8jabzTAMw5g2bZoBGG+//fZ5y5wvrv379xe51yFDhhiAMXbs2BLFPWnSJMNisRgHDx60H7vqqquMWrVqFTp2bjyGYRjjxo0zPD09jZSUFPuxEydOGG5ubsbzzz9f5DoiNZG6w0RqqAcffND+3NXVlU6dOmEYBg888ID9eGBgIM2aNWPfvn32Y4sWLSI8PJy7777bfszd3Z0nnniC9PR0VqxYYS/n5ubG8OHDC13n8ccfLxRHcnIyy5Yt46677uL06dMkJSWRlJTEyZMn6dmzJ7t37+bo0aOlujdvb2/787y8PE6ePEnjxo0JDAxkw4YN9ve+/vpr2rVrV2xLk8VisZcJCQkpEve5Zcri3M+luLgzMjJISkriiiuuwDAM/vrrLwASExP59ddfuf/++6lfv/554xk8eDA5OTnMnTvXfmz27Nnk5+dz7733ljlukUuJkiCRGurvP6ABAQF4eXkREhJS5PipU6fsrw8ePEiTJk1wcSn8z0eLFi3s7xf8jYiIwM/Pr1C5Zs2aFXq9Z88eDMNg/Pjx1KlTp9Dj+eefB8wxSKWRlZXFhAkTiIqKwtPTk5CQEOrUqUNKSgqpqan2cnv37qV169YXrGvv3r00a9YMNzfHjR5wc3OjXr16RY4fOnSIoUOHEhQUhJ+fH3Xq1OHqq68GsMddkJBeLO7mzZvTuXNnZsyYYT82Y8YMLr/8cho3buyoWxGp1jQmSKSGcnV1LdExMMf3VBSbzQbAU089Rc+ePYstU9of7ccff5xPP/2UJ598kq5duxIQEIDFYmHgwIH26znS+VqErFZrscc9PT2LJJFWq5UbbriB5ORkxowZQ/PmzfH19eXo0aMMHTq0THEPHjyYkSNHcuTIEXJycvjzzz95//33S12PyKVKSZCIlEqDBg3YvHkzNput0A/5zp077e8X/F26dCnp6emFWoPi4uIK1dewYUPA7FLr0aOHQ2KcO3cuQ4YMKTSzLTs7u8jMtEaNGrF169YL1tWoUSNWr15NXl4e7u7uxZapXbs2QJH6C1rFSmLLli3s2rWLzz77jMGDB9uPL1mypFC5gs/rYnEDDBw4kNGjRzNz5kyysrJwd3dnwIABJY5J5FKn7jARKZVbbrmF+Ph4Zs+ebT+Wn5/Pe++9h5+fn7375pZbbiE/P58PP/zQXs5qtfLee+8Vqi80NJRrrrmGjz76iOPHjxe5XmJiYqljdHV1LdJ69d577xVpmbnjjjvYtGlTsVPJC86/4447SEpKKrYFpaBMgwYNcHV15ddffy30/n/+859SxXxunQXP33nnnULl6tSpw1VXXcW0adM4dOhQsfEUCAkJ4eabb+Z///sfM2bM4KabbirS3SlSk6klSERK5eGHH+ajjz5i6NChrF+/nujoaObOncvKlSuZPHkytWrVAqB3795069aNsWPHcuDAAVq2bMm8efMKjckp8MEHH9C9e3fatGnDQw89RMOGDUlISGDVqlUcOXKETZs2lSrGW2+9lS+++IKAgABatmzJqlWr+PnnnwkODi5U7umnn2bu3Ln079+f+++/n44dO5KcnMyCBQuYMmUK7dq1Y/DgwXz++eeMHj2aNWvWcOWVV5KRkcHPP//Mo48+Sp8+fQgICKB///689957WCwWGjVqxPfff1+qsUzNmzenUaNGPPXUUxw9ehR/f3++/vrrQuOxCrz77rt0796dDh068PDDDxMTE8OBAwdYuHAhGzduLFR28ODB3HnnnQC8/PLLpfocRS55zpqWJiLOUTBFPjExsdDxIUOGGL6+vkXKX3311UarVq0KHUtISDCGDRtmhISEGB4eHkabNm0KTQMvcPLkSeO+++4z/P39jYCAAOO+++4z/vrrryLTxg3DMPbu3WsMHjzYCA8PN9zd3Y3IyEjj1ltvNebOnWsvU9Ip8qdOnbLH5+fnZ/Ts2dPYuXOn0aBBg0LT/QtifOyxx4zIyEjDw8PDqFevnjFkyBAjKSnJXiYzM9N49tlnjZiYGMPd3d0IDw837rzzTmPv3r32MomJicYdd9xh+Pj4GLVr1zb+7//+z9i6dWuxU+SL+5wNwzC2b99u9OjRw/Dz8zNCQkKMhx56yNi0aVOxn9fWrVuNfv36GYGBgYaXl5fRrFkzY/z48UXqzMnJMWrXrm0EBAQYWVlZF/zcRGoai2FU4IhHERFxqvz8fOrWrUvv3r2ZOnWqs8MRqVI0JkhE5BL2zTffkJiYWGiwtYiY1BIkInIJWr16NZs3b+bll18mJCSk0CKRImJSS5CIyCXoww8/ZPjw4YSGhvL55587OxyRKkktQSIiIlIjqSVIREREaiQlQSIiIlIjabHEYthsNo4dO0atWrXKtUu0iIiIVB7DMDh9+jR169Ytsj9fcZQEFePYsWNERUU5OwwREREpg8OHD1OvXr2LllMSVIyCZf8PHz6Mv7+/k6MRERGRkkhLSyMqKsr+O34xSoKKUdAF5u/vryRIRESkminpUBYNjBYREZEaSUmQiIiI1EhKgkRERKRG0pigcrBareTl5Tk7jGrJ3d0dV1dXZ4chIiI1mJKgMjAMg/j4eFJSUpwdSrUWGBhIeHi41mISERGnUBJUBgUJUGhoKD4+PvoRLyXDMMjMzOTEiRMAREREODkiERGpiZQElZLVarUnQMHBwc4Op9ry9vYG4MSJE4SGhqprTEREKp0GRpdSwRggHx8fJ0dS/RV8hhpXJSIizqAkqIzUBVZ++gxFRMSZlASJiIhIjaQkSMokOjqayZMnOzsMERGRMtPA6BrkmmuuoX379g5JXtauXYuvr2/5gxIREXESJUFiZxgGVqsVN7eLfy3q1KlTCRGJiEhVlJVrJTUrD083F7zcXfF0c8HFpfqN81QSVEMMHTqUFStWsGLFCt555x0APv30U4YNG8aiRYt47rnn2LJlCz/99BNRUVGMHj2aP//8k4yMDFq0aMGkSZPo0aOHvb7o6GiefPJJnnzyScAc5PzJJ5+wcOFCfvzxRyIjI3nrrbe47bbbnHG7IiLiQCmZuaw7cIq1B5JZvT+ZrUdTybcZhcp4uLnYkyIvdxe83FzxPPO34JhnwTF3V9rXC+SuzlFOuiOTkiAHMAyDrDxrpV/X2921xDOs3nnnHXbt2kXr1q156aWXANi2bRsAY8eO5c0336Rhw4bUrl2bw4cPc8stt/Dqq6/i6enJ559/Tu/evYmLi6N+/frnvcaLL77IG2+8wb/+9S/ee+89Bg0axMGDBwkKCir/zYqISKU5nprFmv3JrD2QzNr9p4hLOF2kjKuLBes5iVBuvo3cfBuns/NLdI307HwlQZeCrDwrLSf8WOnX3f5ST3w8SvY/YUBAAB4eHvj4+BAeHg7Azp07AXjppZe44YYb7GWDgoJo166d/fXLL7/M/PnzWbBgAY899th5rzF06FDuvvtuACZOnMi7777LmjVruOmmm0p9byIiUjkMw2BfUgZr9yez5kAya/Ync+RUVpFyDev40iU6iM7RQXSJCaJebW+sNoOcfBvZeVayz/zNybORnW+1P8/Jt5Kdd6ZMnvVMeRtNw/yccLeFKQkSOnXqVOh1eno6L7zwAgsXLuT48ePk5+eTlZXFoUOHLlhP27Zt7c99fX3x9/e3b40hIiJmt9KO46fZGZ/GjuNpHE3JItjXk4hALyIDvYkI8CYiwIu6gd7U9nF36HpqGTn5JJ7OISndfBw5lcW6A6dYdzCZpPTcQmVdLNCqbsCZhKc2naKDCPHzLFKnm6sFN1cXfD2rZzpRPaOuYrzdXdn+Uk+nXNcR/j7L66mnnmLJkiW8+eabNG7cGG9vb+68805yc3PPU4PJ3d290GuLxYLNZnNIjCIi1Um+1caBkxnsOH6aHcfT2Blv/j2eml3iOrzcXQolRXUDvIgIPPs6IsALF4ulUGKTmJ579vXpHBLTC57nXnDYhoebC+2jAs2WnpggOtQPpJaX+3nLXyqUBDmAxWIpcbeUM3l4eGC1Xnzs0sqVKxk6dCj9+vUDzJahAwcOVHB0IiLV099bd3bGnyYu/jQ5+cX/R2C92t40D/enZUQt6gf7cjI9h+Op2RxLyeJ4ajbHU7NISs8lO8/G/qQM9idlOCxWb3dX6tTyJMTPg9BaXrSNCqBLdBBt6gXg6Vbz9nCs+r/c4jDR0dGsXr2aAwcO4Ofnd95WmiZNmjBv3jx69+6NxWJh/PjxatEREcFs4dkZf5r1B0/ZH0dTio6fATPhaBZeixYR/rSIMP82C6+FfwlaWLLzrCSkZXMsxUyKjqdmczQli+NnEqVjKVmknRmA7O3uSkgtD+r4eRLi50lILU/zeS1P6vh5nEl6zEd17baqKPo0apCnnnqKIUOG0LJlS7Kysvj000+LLff2229z//33c8UVVxASEsKYMWNIS0ur5GhFRJwvNTOPDYdPseHgKdYdOMWmIylk5hZtUT+3dad5hD8tIvypH+SDaxnXzvFyd6VBsC8Ngs+/KG1GTj4G4KfEpswshmEYFy9Ws6SlpREQEEBqair+/v6F3svOzmb//v3ExMTg5eXlpAgvDfosRaTcTh2EGXdCdHe45S1wKftuUIZhsD8pg/UHT7HhkJn07D6RXqRcLU83LmtQm04NatOxQW1aRwYQ4H3pj5+pDi70+10cpY8iIlJ9/fgMJO0yHy5ucPMbUMIZVTn5VjYfSWXdgVP2xCc5o+gEkOhgHzo2CKLjmaSnSahftVwdWYpSEiQiItXTvuWw83uwuIBhgzUfg3cQXDuu2OLpOfmsP3jKvh7OxsMp5P5t8LKHmwttIwPoGF2bjvVr06FB7WKnhsulQUmQiIiUW1p2Hj7urri5lr07qlSs+bD4TLLT+SEIbgw/PA0rXgPv2nD5IySl59gTnrUHktl+LI2/7fRAsK8HnaJr0zk6iA4NatOqrn/NmCWVsB02zYRG10LDa0vcenapURIkIiIllme1sTcxnZ1n1r/ZcWb9m8TTObi5WIis7U39IB8aBPvQIMiX+sHm8/pBPo5dSmT9p3Biu5nwXDMWw7s2ackJBKx+ExaPYeLyeD5O6VzktHq1vekSE2RfD6dhiK9DFySs8vJz4Le34be3wJYHf7wLdZpDl4eh3UDwOP9A7EuRkiARESnWyfQc+yJ/24+nsfP4afacSCfXWvySGfk2g4MnMzl4MpPfdhd9v04tTxoE+VD/TFJkJke+NAj2IdjXg5x8Gxk5+WTmWsnMtZKRm09WrrXQsczcfPLTkxmy/iW8gbkBQ/hx7j62HEklPu0ynnfryTC3H/ln1jvscRnN0TpX0zmmtn2rh4gA74r90KqyI+vg28cgcYf5ul4XM5FM3AkLR8PSF6HDEOjyEASef5/IS4mSIBGRGq5gVtSWo6n2ZGfH8TROnM4ptryfpxvNz6x/0/zM+jdN3eJJ84zkYEoeh5IzzGQoOZNDJzM5eDKDtGxzy4bE0zmsO3iqSJ0WC5R0rvILbtPxdktjhy2KMQc6YiUBADcXFxaEP05nw0Lrk4uZ6vM+ln7XQXSbMn82l4TcDFj2Kvz5H8AA3zpwy7+gZV/ISYONX8Lqj+DUfrNlaNX70LwXxA6HBldc0l1lmiJfDE2Rrxz6LEWcIyvXyuYjKaw/ZK5/s/7gKU5l5hVbNjrYh+bh/vaEp2WEP5GB3oVnR+1cCLPugZir4d554Fr0v69TM/M4eCY5OpRsJkYFz/++lYSXuwu+Hm54e7ji6+GGj6crPh6u+Hi40cg4yNP7H8IVK3NafcDJ0K74eLjSuI4f7esHml1u1jyYfR/s+gE8/WHo9xDRrkhMNcLeX+C7kZBy0Hzd7m7oORF8ggqXs1lh9xJY/aE54LxAWBu4/BFofSe4V/1/p0s7RV5JUDGUBFUOfZYilSM+NfucFY6T2XYsjfy/jRD2dHOhdWQALc9p3WkWVuviKwwbBnx0FcRvNl93HwU9XihVfNl5VtKy8vDxdMPb3fX8CwwaBnzeB/avgBa9YcD/zl9pXhb87w44uNJs+bj/RwhuVKq4qrWsU/DTc/DXmc8oIApunQxNelz83BM7zJahTbMg/8xq2D7B0HEYdH4A/OtWWNjlpSTIAZQEVQ59liKOd+62DusOmi09xW3rEFrLk07Rte3r37SM8MfDrQwzu/b+Al/0BRd3c6AtwMCZ0PyW8t1IcQpanFw9YcRqCIq5cPnsVJh+q5mgBdSH+xdDQKTj46pqti+ARU9BegJgMcf4XD8BPGuVrp7MZPjrC1jzCaQeNo+5uEHLPmZXWVTRgefOpsUSpcJER0fz5JNP8uSTTzo7FJFLTmpWHn8dOkVCWja5VoO8fBt5VvORazXItxa8Nsi12s6+bztbNj0nn61H04rsFu5igRYR/vbF/jo2qE1koLdjZkWtnGz+7fwAYDG7U+Y/Av+3HIIalr/+Avk55sKIAFc8dvEECMArwOyem9YTkvfC/26HYT8U7Qoqi9xM2DLHTBLqNINb3gR3Jw+6Pp1gJj87Fpivg5tAn/eh/uVlq88nCLqNhMtHQNxCs3Xo4ErY+rX58Aszk9+yan6LOTbJiZQEiYhUMsMwOHAyk3UHktlwyOym2pVQdHuGsqrl5UaH+me3dWgXFVgxG2ce22iOH7G4QtcR4BcOxzbA4dXw1WB4YInjEoNVH8CpA+Y1uo8u+Xl+dWDwNzC1pzkLasadMPjb0reKFEg9Amv/C+unm11OAEfWQmIc3D0LfEPKVm95GIY5uPnHZyA7xfzfo/souOppx4zjcT3T+tOyDxzfZCZDW+acaWkqh8zk8sdWTkqCREQqWHaelS1HS7Y9Q8M6fni4uuDu5oK7q8V87uqC2znP3V1dcHczX7u5WM6UdcHTzYUWEf40rlNJ2zqsfMf82/qOs1Oq+0+HKVdC/BazVaLPB+W/Ttpx+PVN8/kNL4KnX+nOD6wP982HT2+Co+th1iAYNAfcSrgStGHAoT9h9RTY8R0Y1rP1trnLTIqOrIX/Xg/3zIE6TUsXX3mcOmgOfN73i/k6oh3c9j5EtK2Y60W0g77/gRtfOTvYuqy8Ah0SUnkoCaohPv74Y1544QWOHDmCyzkbDPbp04fg4GCeffZZRo8ezZ9//klGRgYtWrRg0qRJ9OhRgkF0IlLIibRs+5ic9QdPse1YKnnWwsMvPdxcaFcvgA4Nqun2DMn7Yfs35vNuI88e968Ld06FL/qZg3KjYqHD4PJda+lLkJcB9TqbSUdZhDaHQV/DZ73NgdVfP2gmbC4XWB06Pwe2zjO7+I5vOns8+kqIfQSa3Wye326g2cJ06gBMvQEGzjA3dK1INqs5Vqfgs3H1hGufga6PFTs7z+F8ghzTrehkSoIcwTAgL7Pyr+vuU+L1G/r378/jjz/OL7/8wvXXXw9AcnIyixcvZtGiRaSnp3PLLbfw6quv4unpyeeff07v3r2Ji4ujfv2asWiWSHFy8q2kZuWRlpVHSmYeqef+PXPcPJZLalYeCWk5xQ5ErlPL0949dUlsz7DqfXO/rsY9ILx14fcaXgPXPgvLXoaFT5mtB2Wdon5kPWz60nx+0+vl2iWeeh3h7i9hRn9z3Mx3I+G294r+O3o6HtZNMx8ZieYxNy9oexd0+b+i9xvSBB5cCjMHmi1Cn/c1W8DaDSh7rBdyYicseByOrDFfN+gGvd+FkMYVc71LmJIgR8jLhIlOmDL4zLESL3Feu3Ztbr75Zr788kt7EjR37lxCQkK49tprcXFxoV27s/9Ivfzyy8yfP58FCxbw2GOPVUj4IlVJdp6VZTtPsGDjMQ6czLAnO38fZFwSLhZoHl54IHK92g4aiFwVpCeenXrd7cniy3QfbSYEuxab44MeXm5ucVEaNhv88E/zebt7zCSmvBpeA3dMhTlDzEHNPkFww0vme0fWm11e2+afnelWqy50eRA6DAXf4PPX6xsCQ76DeQ+bCdb8h82Woav/6bjFBvNzzS7IX98Aay541DK7BzsOK19yWIMpCapBBg0axEMPPcR//vMfPD09mTFjBgMHDsTFxYX09HReeOEFFi5cyPHjx8nPzycrK4tDhw45O2yRCmMYBmsPnGL+X0f4fvNxTmfnF1vOYoEAb3cCvN0J9HbH39udQB8PArzdCPT2sL8X4ONOkK8HLSL88auIgchVxZqPIT8b6nY4f7ePiwv0mwIfXW0mA/OHw8AvS/djveUrOLoOPPygx/MOCR2AlrdB73fM1pSV70B2GiRsNZO2AlGXQ+z/mesRuZZwBpS7N/T/DH5+3lx5eflE8957vwNuHuWL+egGM96ErebrJj3h1rchoF756q3hqsT/Sz/44AP+9a9/ER8fT7t27Xjvvffo0qVLsWWvueYaVqxYUeT4LbfcwsKFC+2vd+zYwZgxY1ixYgX5+fm0bNmSr7/+umK6dtx9zFaZyubuU6rivXv3xjAMFi5cSOfOnfntt9/497//DcBTTz3FkiVLePPNN2ncuDHe3t7ceeed5OYWHbwpUt3tT8pg/oYjzN94lMPJZ7uu6gZ40eeySLo2DKa2j4c9sanl6VY5A42rg5x0MwkC6P7khVs5vGvDXZ/D1BvN1ZtXToYrSzizKycdlpxJfK78B9QKL0/URXUYDFkpsGS8uRkrgKuHOcg79v+g7mVlq9fFBW582ZzCv/Apsysv9bC5sKN3YOnry800k6lVH5jdj95BcPMb0ObOS3o7i8ri9CRo9uzZjB49milTphAbG8vkyZPp2bMncXFxhIaGFik/b968Qj/MJ0+epF27dvTv399+bO/evXTv3p0HHniAF198EX9/f7Zt21ZxC/JZLNVi510vLy9uv/12ZsyYwZ49e2jWrBkdOnQAYOXKlQwdOpR+/foBkJ6ezoEDB5wYrYhjncrI5fvNx/h6w1E2Hk6xH/f1cOWWNhH06xDJ5THBSnYu5q8vzGnYQY2g+a0XL1+3vbkWzHdPmGOEIjtCw6svft7vb0N6PNSOhssfLWfQ59HtCbNbafNX0Pp26HQ/+BX93SmTTvebqzTPGQoHfjMTwUFfmfdTUvt/hQVPmHt6AbTpDze95pxp+JcopydBb7/9Ng899BDDhg0DYMqUKSxcuJBp06YxduzYIuWDggqPRp81axY+Pj6FkqBnn32WW265hTfeeMN+rFGjGrRc+gUMGjSIW2+9lW3btnHvvffajzdp0oR58+bRu3dvLBYL48ePx2YrfqdokeoiJ9/Ksh0nmPfXUZbHnbDP0HJ1sXBlkxD6XRbJjS3D8faoxgOUK5M1z2yRALji8QvPrDpXh8FweA1s/B/MvR8e+e3CWy8k74c/3jef95xYsXtWXfWU+agITW4wV6mecRckxcF/e8Ddsy8+tik7FZZMMNciAnNc0q3/hmY3VUycNZhTR1Ll5uayfv36QtOwXVxc6NGjB6tWrSpRHVOnTmXgwIH4+potMTabjYULF9K0aVN69uxJaGgosbGxfPPNN+etIycnh7S0tEKPS9V1111HUFAQcXFx3HPPPfbjb7/9NrVr1+aKK66gd+/e9OzZ095KJFKdWG0G6w4k88z8LXR+5WeGz9jAku0J5FkNWkf6M/7Wlvw57nqmD+tCn/aRSoBKY+s8s2vHN9TciLOkLBbo9aa5GWdmktk6Yi1+w1bA7KKy5piDmJtVwPYblSm8DTz4s3nvGYkwvZe51tD57FwEH8SeTYA63Q8j/lQCVEGc2hKUlJSE1WolLCys0PGwsDB27tx50fPXrFnD1q1bmTp1qv3YiRMnSE9P57XXXuOVV17h9ddfZ/Hixdx+++388ssvXH110WbYSZMm8eKLL5b/hqoBFxcXjh0rOn4pOjqaZcuWFTo2YsSIQq/VPSZVUeLpHDYeTuGvQ6fYeDiFzUdSSc85O8A5IsCLPu0jub1DJE3DyrhKsJhLgRQsjnj5I6VvnXH3hgGfw0fXmCtKL5kAN00qWm7fCjNJsLhCz0mXxriXgEi4/weYMwz2LDF3uL/xFXOV7YL7S080Z8Jtm2e+DmoEt71b8esN1XBO7w4rj6lTp9KmTZtCg6gLunD69OnDqFGjAGjfvj1//PEHU6ZMKTYJGjduHKNHnx2sl5aWRlRUVAVHLyKllZ1nZduxVP46lMJfh1PYeCil2DV5/DzduKl1OLdfFklsw+Dz70ouJbfnZzixzZyp1en+stUR1BD6fWhugvrnfyCqC7Tqd/Z9az4sPjMMovMDENay/HFXFZ61zG01fnjaXH/op2fNsT43vW7uw7V4jLkNh8XV7Gq8Zqzz9yKrAZyaBIWEhODq6kpCQuH9RxISEggPv/BMgIyMDGbNmsVLL71UpE43Nzdatiz8f54WLVrw+++/F1uXp6cnnp7VaKVWkRrAMAz2J2Ww8XCK/bH9WBr5tsIrL1ss0DS0Fu2jAmlfP5DL6gfSJLSWEh9H+32y+bfj0NKv93Ou5r3MtYVWToZvH4PQVme3mVj/KZzYbtZ/zbjyxVsVubpBr7ehdozZ5bf2v2b31+kzrfNhbaDPe2WfmSal5tQkyMPDg44dO7J06VL69u0LmC05S5cuvegCfXPmzCEnJ6fQ4N6COjt37kxcXFyh47t27aJBgwYOjV9Eys9qMzh6Kov9JzPYn5jO/qQM9iVlsOVoKimZRceNhPh50j7KTHYuiwqkTb0AanmVYydrubgj6+Dg7+aO4Y6YqXXdeHMPrwO/wVf3mastW3Phl1fN96999pLYkqFYFos5Ky2wPsz/PzMBcvWAq8eY24+UdE0icQind4eNHj2aIUOG0KlTJ7p06cLkyZPJyMiwzxYbPHgwkZGRTJpUuO946tSp9O3bl+Dgoit4Pv300wwYMICrrrqKa6+9lsWLF/Pdd9+xfPnyyrglEfkbwzBITM9hf2IG+5My7InO/qQMDp3MJNda/ExEDzcX2kQGmK08ZxKfyMBLaOXl6mLlZPNv27vM8S3l5eoGd04zN1pN3AnfP2m2/mSdgtCW5grIl7pWfc1EaOvX0GFI5W66KnZOT4IGDBhAYmIiEyZMID4+nvbt27N48WL7YOlDhw4V2vATIC4ujt9//52ffvqp2Dr79evHlClTmDRpEk888QTNmjXj66+/pnt3xw0wMwzj4oXkgvQZXrri4k+zcMtx9idlcOBMsnPuYOW/83BzITrYh5gQX2JC/GgY4kvziFo0D/fHw60GbQdgGOasqfKuLuxISbthx/fm8yuecFy9fqHmBqbTe8GWOWeP3zSpcjYArQoiO5gPcRqLoV+iItLS0ggICCA1NRV/f/9C71mtVnbt2kVoaGixrVBScidPnuTEiRM0bdoUV1dNU74UpGXn8e8lu/jsjwP8begOLhaoV7sg0fGlYR1f+/OIAG+N4dm5EBY9bW7eGd4aIjtBvU7m3+DGztsbasETsOEzaHoz3DPL8fWv+gB+fMZ83vxWcwd2kTK60O93cWpIuu04rq6uBAYGcuLECQB8fHzUNF9KhmGQmZnJiRMnCAwMVAJ0CTAMg282HuXVhTtJSs8BoEeLULrEBBET4kdMiC9RQd7Ve9f0ipJ+4szU6Plnjx3fZD7WnVn+wyvAXGm5XuezyVFljJk5HQ+bZprPuz9ZMde4/FGzS2z/b9Dz1Yq5hsh5KAkqg4KZawWJkJRNYGDgRWcBStUXF3+a8d9uZc3+ZAAahvjyYp9WXNmkjpMjq+IMAzbPNqeEF0yN7vYEXHYfxG82ByMfWQfHN5orCO9dZj4KBDUs3FoU3sbx3Wirp5gDlqNiof7ljq27gMUCt71XMXWLXIS6w4pR0uY0q9VKXt4FVj2V83J3d1cLUDWXnpPP5CW7+PSPA1htBl7uLjx+XRMevDKm+rb45KTD0hfB4gKdHqi4waoph+C7J2HvUvN1eBvo8wFEtCta1poHCdvMHc6PrjcTo5O7i5Zz9TTPv/wRaHV7+RcZzE6Df7eGnFQYOBOaV/OVm6VGKG13mJKgYpT2QxSpSQzD4LvNx3l14XYS0syur56twhh/a0vq1fZxcnTlcDoevrzL7IYq0Og6iB0OjXs4ZkyOzWauDfPzC5CXYSYu14w1F8crzdTorFNnEqL1Z5KjdeaxAs1ugV5vXXh/rotZ+Y65qnNIM3j0T+eNSRIpBSVBDqAkSKR4uxNOM+HbbazadxKABsE+vHBbK65t5qCdt50lYZu5yWXaEfAJMcfe7FoMnPnnMagRxP4ftL/HXPm3LBJ3wYLH4fCf5uv6Xc1uoJAm5Y/fMCB5H2yaBb//G2x54OkPN75sTr8ubatQfg680w5OHzdbqC679+LniFQBSoIcQEmQSGEZOfm8u2w3U3/bT77NwNPNhRHXNubhqxri5V5Nu74K7FkKXw2B3NMQ3AQGzYGgGHMn87X/hQ1fmF1CAB61zIQg9mFzTE5JWPPMVpUVr5vjazz8oMcLZndbRbSuJGwzV2I+tsF8HX0l9H4HghuVvI4NX8CCx6BWBIzcBG5aUV+qByVBDqAkSMRkGAY/bI3n5e+3czw1G4AeLcJ4vndLooKqcddXgfWfwfejwLBCg24w4H9FZ13lpJszpFZ/dM5YHAs07Qmxj5g7nZ+vpeXYX/Dt45CwxXzd+Aa49d8QWMF7E9qs8OeHsOwVyM8CN2+47lmza+9ia/DYbPCfWEjaBTe8bA7WFqkmlAQ5gJIgEdibmM4LC7bx2+4kAKKCvHmhdyuubxHm5MgcwGaDZS/D72+br9sOMLumLtTiYbPBvmXw5xRzJ/ACdZqbXWVtB4LHmcQwLwuWT4I/3jcTLO8guOk1c8XlylxSI3kffDcS9v9qvq7bAfq8D2Gtzn/OzoXmBqeeATBqK3jp30CpPpQEOYCSIKlpTqRls+1YGluPppp/j6Vy5JS5O7uHmwvDr27E8GsaVf+uL4C8bPhmOGybZ76+eoy5WWdpkpOkPbDmI9j4JeSmm8e8AqHDYHNn9CXPQ/Je83jrO8ydwv2ctGSAYcBfX8CPz5ndei5u0H00XPVU8Unf1Bvh8GroPsrsthOpRpQEOYCSILlUGYbBkVNZbDuWytajaebfY2kkns4ptvz1zUOZ0LslDYJ9KznSCpJx0mzlOPynmQzc9p452LmsslPhrxlmQnTqQOH3akWYO4ZXlanlacdh0VOw88wWGCHNzFahqC5nyxxcBZ/eZG7o+eRWqHUJtPpJjaIkyAGUBMmlwGYz2JeUfjbZOfM3LbvoHl4uFmhYx4/Wdf1pVTeAVpH+tIoIIMDnEtrR+uRemHGn2UXkGQADvoCGVzumbpsVdv9kjsM58Dt0uA9ueMlc6bkqMQzY/q2ZDGUkAhZzXNN1z4GnH3w5wJwV12EI3Paus6MVKTUlQQ6gJEiqu6T0HB7+fB0bDqUUec/D1YWm4X60rhtAq7r+tKwbQIuIWvh4XMILyB9cZbYAZSWbO3cPmgt1mlXMtaz5VX8D0Mxk+PFZ2PSl+Tqwvrk56qKnAAs8tg5CGjs1RJGy0N5hIjXc3sR0hn66hsPJWXi6udAm0kx2Wp352yS0Vs3amX3LXHMMkDXXHBh8z2xzB/OKUtUTIDBnwPX7ENrcYa5cnXLoTAIEtLhVCZDUGNXg/60iUlJrDyTz0OfrSMnMo36QD9OHdaZhHT9nh+UchgG/vWXOAgNzh/LbPzk7g0vMlbAfXQVLX4Y1H5vHuo1ybkwilUhJkMglYuHm44z6aiO5+TbaRwXy3yGdCPGroYvcWfPM9X/++sJ83fUxc4yOyyUwu83RPGvBLW+YM9tyM6BeR2dHJFJplASJVHOGYfDf3/bz6qIdANzQMox3B16Gt0cN/MEv2D5i4T9g3y/mRqg3vwFdHnJ2ZFVfeGtnRyBS6ZQEiVRjVpvBS99t47NVBwEY0rUBE3q3wtWlEhfkc6ZzNxI9us7cYT0r2XzP3RfunAbNbnJujCJSZSkJEqmmsnKtPDHrL5ZsTwDguV4teKB7DJbKXJG4MlnzIGGrmegcXW/+tW9jcQ5XT6jXCXpOhLrtKz1MEak+lASJVENJ6Tk88Nk6Nh1OwcPNhX/f1Z5ebSOcHZbjGAakHjnbunNkHRzfCPnZRcsGNTR3fY/sZI5nCWsDbh6VHrKIVD9KgkSqmX2J6Qz9dC2HkjMJ9HHnk8Gd6BwddPETq4uTe801fRJ3Fn3PKxAiO5otPfU6m8//vuGpiEgJKQkSqUbWH0zmwc/WcSozj6ggb6YP60KjS2kKfNpx+KKvuW6NixuEtTYTnshO5t+gRuBSg9Y4EpEKpSRIpJr4YctxRs42p8C3qxfA1KGdL60p8JnJ8EU/MwGqHQP3L4Za4c6OSkQuYUqCRKqB//62j1cX7cAwoEeLMN69u/2ltc1FbgZ8eRck7jA3Hh38jRIgEalwl9C/oiKXHqvN4JWF2/l05QEABndtwPOX2hT4/ByYfS8cWWuO+bl3HtSOdnZUIlIDKAkSqaIOJ2fyysLt/LjNnAL/7C0tePDKS2wKvM0K8x6GvcvMdX0GzYWwls6OSkRqCCVBIlVIUnoOCzcf59uNR+07wHu4uvD2gHbc2rZu5QZz6gD4hYG7d8XUbxiwcDRs/wZc3GHg/yCqc8VcS0SkGEqCRJwsPSefn7bF883GY6zck4TVZgDgYoGujYIZfUMzOjaoXXkBGQYsnwQrXgf/enDrv6HpjY6/ztKXYP10wAJ3fAKNrnP8NURELkBJkIgT5ObbWB53gm83HePn7Qnk5Nvs77WrF0Cf9pHc2jaCUH+vyg0sPwcWPA6bZ5uv047Al/2h7QDoOQl8gx1znT/eg9/fNp/3ngyt+jmmXhGRUlASJFJJbDaD1fuTWbDpKIu2xJOalWd/r2GIL33aR3Jb+7rEhPg6J8DMZHOA8sGVYHE1dxZP3g9//sdMivYsNY+1uh3KMy7pr//BT8+Zz3u8AB2HOiJ6EZFSUxIkUoEMw2DbsTS+3XiU7zYdJz7t7LYPYf6e9G5blz7tI2kd6e/cAc/J+2DGXeZeXJ7+cNdnZ7unWvWDbx8zp6/PvR82z4Feb0FAZOmvs+M7s6UJ4IonoPsox92DiEgpWQzDMJwdRFWTlpZGQEAAqamp+Pv7OzscqabSc/J5+PN1/LH3pP2Yv5cbt7SJ4Lb2dYmNCa4aU90Pr4GZAyHzpDkGaNCcojO08nPN7qtf3wRbnpko3fASdBhS8hWc962AGXeCNRcuuw9ue698LUoiIn9T2t9vJUHFUBIk5ZWdZ2Xop2v4c18yHm4u9GgRSp/2kVzTrA6ebq7ODu+sbd/A/P8zNyaNaAf3fHXhRQpP7DBbhY6uM19HXwm934HgRhe+ztH18NltkJsOLXrDndPBVQ3RIuJYSoIcQEmQlEdOvpWHP1/Pil2J+Hm6MePBWNpFBTo7rMIMA/54F5ZMMF83vRnunAoeJRiPZLPC6o9g2cuQlwluXnDtM3D5iOITm8Q4mHYTZCVDzNVmS5PbJbTdh4hUGaX9/dZOhCIOlG+1MXLmRlbsSsTL3YVpQztXvQTImg/fjzqbAMU+AgNnlCwBAnBxha6PwvA/zKQmP9us67/XQ/yWwmVTDsHnfc0EqG4H8zpKgESkilASJOIgNpvBU3M2sXhbPB6uLnwyuBNdYoKcHVZhOadh5gBY/ylggZteg5tfNxOb0gqKgcHfwm3vg2cAHN8IH18Dy14xp9qnJ5oJ0OljENIM7v0aPGs59n5ERMpB3WHFUHeYlJZhGDwzfysz1xzCzcXCh/d25IaWYc4Oq7DUo/DlAEjYAm7eZvdX816Oqft0PCz8B+z83nwd0gxcPcxrBUTB/T+WbTaZiEgplPb3WyMTRcrJMAxe/n4HM9ccwmKBfw9oX/USoOObzV3aTx8H31C4ZzZEdnBc/bXCza6u7d/CwqcgKc487hMC932jBEhEqqQq0R32wQcfEB0djZeXF7GxsaxZs+a8Za+55hosFkuRR69exf8X7SOPPILFYmHy5MkVFL3UdG8v2cW0lfsBeP2OtvRuV8l7fF3Mrp/g05vNBKhOC3hoqWMToHO17AMjVkOHwRDWBu6bByGNK+ZaIiLl5PSWoNmzZzN69GimTJlCbGwskydPpmfPnsTFxREaGlqk/Lx588jNzbW/PnnyJO3ataN///5Fys6fP58///yTunWr2I+SXDL+s3wP7y3bA8BLfVpxV6coJ0f0N2v/C4ueBsNmDmK+63PwDqzYa/oEmWsAiYhUcU5vCXr77bd56KGHGDZsGC1btmTKlCn4+Pgwbdq0YssHBQURHh5ufyxZsgQfH58iSdDRo0d5/PHHmTFjBu7u7pVxK1LDTF+5nzcWm90+Y29uzuCu0c4N6FyGAT+/aI7TMWzQ/l4YNLfiEyARkWrEqUlQbm4u69evp0ePHvZjLi4u9OjRg1WrVpWojqlTpzJw4EB8fc9O77XZbNx33308/fTTtGrVyuFxi3y19jAvfLcdgCeua8wjV19kscDK9tubZzcove456PM+uHk4NyYRkSrGqd1hSUlJWK1WwsIKDyINCwtj586dFz1/zZo1bN26lalTpxY6/vrrr+Pm5sYTTzxRojhycnLIycmxv05LSyvReVIzfbvxKGPmbQbgwe4xjLqhqZMj+pu1/zWnqQP0nAhdRzg3HhGRKsrp3WHlMXXqVNq0aUOXLl3sx9avX88777zD9OnTS7wh5aRJkwgICLA/oqKq2LgOqTJ+2hbP6K82YRhwT2x9nu3Vwrkbn/7dlrnm7CyAq55WAiQicgFOTYJCQkJwdXUlISGh0PGEhATCwy+wfxGQkZHBrFmzeOCBBwod/+233zhx4gT169fHzc0NNzc3Dh48yD/+8Q+io6OLrWvcuHGkpqbaH4cPHy7XfcmlacWuRB778i+sNoPbL4vklT6tq1YCtPtncx8wDOj8IFz7rLMjEhGp0pyaBHl4eNCxY0eWLl1qP2az2Vi6dCldu3a94Llz5swhJyeHe++9t9Dx++67j82bN7Nx40b7o27dujz99NP8+OOPxdbl6emJv79/oYfIuVbvO8n/fbGOXKuNm1uH88adbXGpCjvAFzi0GmbfC7Z8aH0H3Pwv7dAuInIRTp8iP3r0aIYMGUKnTp3o0qULkydPJiMjg2HDhgEwePBgIiMjmTRpUqHzpk6dSt++fQkODi50PDg4uMgxd3d3wsPDadasWcXejFySNh5O4f7pa8nOs3Ftszq8M/Ay3FxL+N8PNitYXCo2IYnfCl/2h/wsaNwD+k4Bl2rd0y0iUimcngQNGDCAxMREJkyYQHx8PO3bt2fx4sX2wdKHDh3C5W//oMfFxfH777/z008/OSNkqUG2Hk1l8NTVZORauaJRMB/e2xEPtxImGNY8mH4rJO+FG16GdgMdnwwl74P/3Q7ZqRAVC3d9oVlgIiIlpL3DiqG9wwTgz30nefCzdaTn5NOhfiBfPBCLr2cp/rvhzw9h8dizrxtdD70nQ2B9xwR4Oh6m9YRTByC0FQxbCN61HVO3iEg1VNrfb7WZixRjyfYEBk9bQ3pOPrExQUy/v0vpEqCMJPjlTBdus17g6gl7l8IHl8Pqj8FmK1+AWafgi35mAlQ72tyeQgmQiEipKAkS+Zs56w7zyP/Wk5tv44aWYXx2fxf8vUq56vgvr0JOqrl/1oAvYPhKqH8F5GXAD0+be3kl7ipbgLkZMOMuOLEd/MLNDUprXXg2pYiIFKUkSOQcn/y6j6fnbsZqM7izYz0+HNQBL3fX0lUSvwXWTzef3/wauLhCSBMYuhB6vQUefnD4T5jSDX590xw7VFL5uTD7PjiyBrwCzBagoJjSxSciIoCSIBEADMPg9cU7eXXRDgAeujKGf93ZtuSzwM5WBD+MNffratkXoruffc/FxVy/59E/ofENYM2FZS/Dx9fCsb8uXrfNaq4DtHcpuPuYe4GFaVsYEZGyUhIkNZ7VZjBu3hY+XL4XgDE3NeeZW8q4EvT2b+Hg7+DmBTe+XHyZwCgYNAdu/wS8gyBhC3xyPSyZAHlZxZ9jGLDoKdg2D1zczS62qC7FlxURkRJREiQ1Wk6+lce+3MCstYdxscCk29sw/JpGZUuA8rLgp/Hm824jLzwLzGKBtnfBY2uh9Z1gWGHlO/BhNzjwe9Hyy16BddMAC9z+kbkekIiIlIuSIKmx0nPyuX/6Wn7YGo+Hqwsf3NOBu7uUY/r6H+9D6iHwjzSToJLwDYE7p8Lds6BWXXNNoem94PtRkH1mI99VH5i7wgPc+ra5IrSIiJSb0xdLFHGG5Ixchn66hs1HUvH1cOWTwZ24onFI2StMPQq/v20+v+El8PAt3fnNboYGV8CS52H9p2arz64fofXt8Md7ZpnrxkOn+8seo4iIFKKWIKlxjqZkceeUP9h8JJUgXw9mPnx5+RIggJ9fgLxMiLq87C01XgHmYopDvoeghpB29GwC1PUxuPIf5YtRREQKURIkNcqeE+nc+eEf7EvMoG6AF1/9X1fa1gssX6WHVsOWrwCLOSW+vFtjxFwJw/8wu9RcPaDTA3DjK9oQVUTEwdQdJjXGpsMpDP10Dacy82hUx5cvHoilbqB3+Sq12WDxGPP5ZYOg7mXlDxTA3dvsVrtuArjq/6YiIhVB/7pKjbByTxIPf76OjFwr7eoF8OmwLgT5OmCj0U1fmmv8eNSC658vf31/pwRIRKTC6F9YueT9sOU4I2dtJNdqo1vjYD66rxN+pdkH7Hyy0+DnF83nV/8T/ELLX6eIiFQaJUFySZu55hDPzt+CzYCbW4czeWB7PN1KuQ3G+fz2JmScgKBGEPuIY+oUEZFKoyRILkmGYfDhir28sTgOgLu7RPFK3za4ujhocPHJvbDqP+bznhPBzQFdayIiUqmUBMklx2YzmLhoB//9fT8AI65txFM3NivbKtDn89NzYMuDRtdD056Oq1dERCqNkiC5pORbbYz5egtfbzgCwHO9WvDglQ0de5E9SyFuEbi4wU2TNHVdRKSaUhIkl4zsPCuPffkXP+9IwNXFwht3tOWOjvUcexFrHvz4jPm8y8NQp5lj6xcRkUqjJEguCWnZeTz42TrW7E/G083cB6xHyzDHX2jtVEjcCT7B5owwERGptpQESbWXeDqHIdPWsP14GrU83fjvkE7ENgx2/IUyTsLyiebz654D79qOv4aIiFQaJUFSrR1OzuS+qas5cDKTED8Ppg/rQuvIgIq52C+vQnYqhLWGDkMq5hoiIlJplARJtRUXf5rB01aTkJZDvdrefPFALDEhpdy9vaTit5q7uwPc9Bq4OGitIRERcRolQVItrT94ivunryU1K49mYbX4/IEuhPl7VczFDAMWjwXDBi37mBuciohItackSKqd5XEnGP6/DWTlWelQP5BpQzsT6FOBixXu+A4O/AZuXnDDyxV3HRERqVRKgqRa+XbjUf7x1SbybQZXN63Dh/d2wMejAr/Gednw07Pm8yuegNoNKu5aIiJSqZQESbXx+aoDPL9gG4YBt7Wry5v92+Hh5lJxFzQM+HEcpByCWnWh+5MVdy0REal0SoKkyjMMg3eW7mbyz7sBGNy1AS/0boWLo/YBO59fJsK6aYAFer0FHhU06FpERJxCSZBUeVNW7LMnQCOvb8KTPZo4dh+w4qz6D/z6hvn81reh+S0Vez0REal0SoKkSttz4jT/XrILqKB9wIqzcabZDQZw3XjodH/FX1NERCpdBQ6oECkfm81g7NdbyLXauK55KA90j6n4i+5cBN+OMJ93fQyu/EfFX1NERJxCSZBUWTNWH2TdwVP4erjyct/WFd8Ftv83mDMUDCu0HwQ3vqId4kVELmFKgqRKOpaSxeuL4wB4vZtB5I5PIf1EBV7wL5h5N1hzoPmt0PtdJUAiIpc4jQmSKscwDJ6fv4kr81byeK2fablqm/nGitfNLSvaDXRsgpK0G/53B+Sehugr4Y6p4Kr/a4iIXOr0L71ULZnJ7Fj4Hi8c+IxIj5OQB7i4gX8kpByEbx6BLXOg92QIrF/+66Uegc/7QuZJiGgPA78E9wrafkNERKoUJUFSNSRsh9VTMDZ/Rcv8LLBAplsgPlc8ZM7O8q0Dq96HXybB3qXwweXQ4wXo/CC4lLFXN+MkfNEP0o5AcBO492vw8nfobYmISNVlMQzDcHYQVU1aWhoBAQGkpqbi768fxQpjs8KuH2H1h7D/V/vhbbYGLPLty8iRY/Hw8il8TtJuWPAEHPrDfB11Odz2HtRpWrpr55yGz3qbY4H868EDP0JAvXLekIiIOFNpf7/VEiSVLzsV/vofrPkYTh0wj1lcSKp3A8P3xLKOZswd2K1oAgQQ0gSGLoT102DJ83D4T5jSDa4eA91Ggqv7xa+fl20Ogj72F/gEw+BvlACJiNRASoKk8iTtgTUfwcYvITfdPOYVCB2HkNV+GP0+3c9hI4uhV0TTsUHt89fj4mJ2gzXpCd+Pgj1LYNnLsO0b6PMe1L3s/Oda8+HrB8xd4T1qmV1gIU0ceZciIlJNVIkp8h988AHR0dF4eXkRGxvLmjVrzlv2mmuuwWKxFHn06tULgLy8PMaMGUObNm3w9fWlbt26DB48mGPHjlXW7cjf5WXBV4Ph/Y5m609uOtRpDrf+G0Zvhxte4q3VWRxOziIy0JunejYrWb2BUTBoDtz+CXgHQcIW+OR6WDLBvObfGQZ8NxJ2fg+unnD3zAsnTCIicklzehI0e/ZsRo8ezfPPP8+GDRto164dPXv25MSJ4teEmTdvHsePH7c/tm7diqurK/379wcgMzOTDRs2MH78eDZs2MC8efOIi4vjtttuq8zbknMtegq2fwtYoOnNcN838Oif5oBnD182HU5h2sr9ALzSrzV+nqVooLRYoO1dMGINtL7DXOhw5TvwYTc48PvZcoYBPz0HG/8HFlfo/ynEXOnQ2xQRkerF6QOjY2Nj6dy5M++//z4ANpuNqKgoHn/8ccaOHXvR8ydPnsyECRM4fvw4vr7F7/K9du1aunTpwsGDB6lf/+LTqjUw2oE2fA4LHgeLi9n11Oi6Qm/nWW30fu93dsafpm/7ukweWM6WmZ2LYOFoOH3cfN3pfujxIqz9BJa+ZB7r+yG0v6d81xERkSqnWg2Mzs3NZf369YwbN85+zMXFhR49erBq1aoS1TF16lQGDhx43gQIIDU1FYvFQmBgYLHv5+TkkJOTY3+dlpZWshuQCzu2ERY+ZT6/9tkiCRDAx7/uY2f8aWr7uDP+1pblv2bzWyC6mzloev2nsG6a2QqVedJ8v+ckJUAiIgI4uTssKSkJq9VKWFhYoeNhYWHEx8df9Pw1a9awdetWHnzwwfOWyc7OZsyYMdx9993nzQonTZpEQECA/REVFVW6G5Gisk6Z44CsOdD0Jug+ukiRvYnpvLN0NwATerck2M/TMdf2CjAXUxzyPQQ1PJsAXfU0dH3UMdcQEZFqz+ljgspj6tSptGnThi5duhT7fl5eHnfddReGYfDhhx+et55x48aRmppqfxw+fLiiQq4ZbDaY/4i5wnNgfeg3pciChjabwbh5W8jNt3F10zr0bR/p+DhiroRHVsL1E+Cm183WKBERkTOc2h0WEhKCq6srCQkJhY4nJCQQHh5+wXMzMjKYNWsWL730UrHvFyRABw8eZNmyZRfsG/T09MTT00GtEAIr/w27FpszsO76AryLTneftfYwa/Yn4+Phyqv9KnCHeA8fuPIfFVO3iIhUa05tCfLw8KBjx44sXbrUfsxms7F06VK6du16wXPnzJlDTk4O9957b5H3ChKg3bt38/PPPxMcHOzw2OU89i2HZa+Yz2/5F9RtX6RIfGo2kxbtAOCpG5tRr3YxiyKKiIhUMKcvljh69GiGDBlCp06d6NKlC5MnTyYjI4Nhw4YBMHjwYCIjI5k0aVKh86ZOnUrfvn2LJDh5eXnceeedbNiwge+//x6r1WofXxQUFISHh0fl3FhNlHYM5j4Ahg3a3wsdBhcpYhgG47/dyumcfNpHBTLkiujKj1NERIQqkAQNGDCAxMREJkyYQHx8PO3bt2fx4sX2wdKHDh3C5W/jSeLi4vj999/56aefitR39OhRFixYAED79u0LvffLL79wzTXXVMh91Hj5ufDVEMhMgrA20OtNcw2fv1m8NZ4l2xNwc7Hw+h1tcXWpoG4wERGRi3D6OkFVkdYJKoMfxpoboXoGwP8tN2dl/U1qZh49/r2CxNM5PHFdY0bfWMKVoUVEREqgtL/f1Xp2mFQRW+eZCRBAvw+LTYAAJi7aQeLpHBrV8WXEdY0rMUAREZGilARJ+STuMleEBuj2JDTvVWyxP/YkMXudufTA63e0xdPNtZICFBERKZ6SICm7nHT46j5zQ9ToK+G68cUWy8q1Mm7+FgDuu7wBnaKDKjNKERGRYikJkrIp2JE9cSf4hcOd08C1+HH2//55FwdPZhLu78U/b9I4IBERqRqUBEnZrPkEts49syP7dPALLbbYpsMp/Pe3fQBMvL01tbzcKzFIERGR81MSJKV3eC38+Iz5/MaXoUHxC1vm5tv459zN2Azo274u1zUPK7aciIiIMygJktLJSII5Q8CWBy37wOXn35D0P8v3EJdwmmBfDyb0blWJQYqIiFxcmZKgX375xdFxSHVgs8LXD0LaUQhuDLe9X+yCiABx8af54Jc9ALxwWyuCfLVSt4iIVC1lSoJuuukmGjVqxCuvvKId12uS5a/Bvl/A3cfcGNWr+IWo8q02/jl3E3lWgxtahnFr24hKDlREROTiypQEHT16lMcee4y5c+fSsGFDevbsyVdffUVubq6j4xNny06Fvctg6Uvw6xvmsd7vQFjL854ybeV+Nh1JpZaXG6/0rcAd4kVERMqh3NtmbNiwgU8//ZSZM2cCcM899/DAAw/Qrl07hwToDDV22wxrPpzYDkfXwZEzj6RdwDlfkc4PQq+3zlvFgaQMek7+lZx8G2/c0Za7OkdVfNwiIiKU/ve73BuodujQgfDwcIKDg3nttdeYNm0a//nPf+jatStTpkyhVSsNiK2y0o7BkbVmsnN0PRz7C/Iyi5YLbAD1OpkLIl5273mrs9kMxny9mZx8G90bh9C/U70KDF5ERKR8ypwE5eXl8e233zJt2jSWLFlCp06deP/997n77rtJTEzkueeeo3///mzfvt2R8Up5HNsI+1ecbeU5faxoGU9/iOwAkZ2gXmeI7Ah+dUpU/ZdrDrF6fzLe7q5Mur2NusFERKRKK1MS9PjjjzNz5kwMw+C+++7jjTfeoHXr1vb3fX19efPNN6lbt67DApVyOroBPrm28DGLC4S1OpPwdDL/hjQFl9IPFTuWksVrP+wE4J83NSMqyMcRUYuIiFSYMiVB27dv57333uP222/H09Oz2DIhISGaSl+VrJtm/g1rA237mwlP3fbg4Vvuqg3D4Nn5W0jPyadD/UAGd40ud50iIiIVrUxJ0NKlSy9esZsbV199dVmqF0fLSYdt883nN78O0d0cWv03G4/yS1wiHq4uvHFnW1xd1A0mIiJVX5mmyE+aNIlp06YVOT5t2jRef/31cgclDrb9G3On96BG0OAKh1adeDqHF78zx32N7NGExqG1HFq/iIhIRSlTEvTRRx/RvHnzIsdbtWrFlClTyh2UONiGL8y/l9173hWey+qF77aRkplHywh/Hr6qoUPrFhERqUhlSoLi4+OJiCi6CnCdOnU4fvx4uYMSB0rcBYf/NAdBt7vboVX/uC2ehZuP4+pi4Y072+Luqq3oRESk+ijTr1ZUVBQrV64scnzlypWaEVbV/HWmFajJjeDvuO0rUjPzeO6brQD831UNaR0Z4LC6RUREKkOZBkY/9NBDPPnkk+Tl5XHdddcB5mDpf/7zn/zjH/9waIBSDtY82GSu5M1l9zm06lcWbifxdA6N6vjyxPVNHFq3iIhIZShTEvT0009z8uRJHn30Uft+YV5eXowZM4Zx48Y5NEAph90/QUYi+NaBpj0dVu1vuxOZs/4IFgu8fkdbvNxdHVa3iIhIZSlTEmSxWHj99dcZP348O3bswNvbmyZNmpx3zSBxkoIB0e0Ggqu7Q6rMyMln7NdbABjSNZpO0UEOqVdERKSylWvvMD8/Pzp37uyoWMSRTsebLUEAlw12WLX/+jGOoylZ1KvtzdM9mzmsXhERkcpW5iRo3bp1fPXVVxw6dMjeJVZg3rx55Q5Mymnjl2BYISoW6jR1SJXrDiTz2aoDAEy6vQ2+nuXef1dERMRpyjQ7bNasWVxxxRXs2LGD+fPnk5eXx7Zt21i2bBkBAZol5HSGAX/9z3zuoAHR2XlW/vn1ZgwD+nesx5VNSrapqoiISFVVpiRo4sSJ/Pvf/+a7777Dw8ODd955h507d3LXXXdRv359R8copXVoFSTvBXdfaNXPIVX+55c97EvMoE4tT57r1dIhdYqIiDhTmZKgvXv30qtXLwA8PDzIyMjAYrEwatQoPv74Y4cGKGVQMCC6dT/w9Ct3dSfTc/jv7/sBePG2VgT4OGaQtYiIiDOVKQmqXbs2p0+fBiAyMpKtW81F81JSUsjMzHRcdFJ62WnmXmHgsAHRn/y2n8xcK20iA7i5dbhD6hQREXG2Mo1sveqqq1iyZAlt2rShf//+jBw5kmXLlrFkyRKuv/56R8copbH1a8jLhJCmENWl3NWdTM/h8zODoZ/s0QSLg/ceExERcZYyJUHvv/8+2dnZADz77LO4u7vzxx9/cMcdd/Dcc885NEAppYJtMi67zyGbpZ7bCnRd89By1yciIlJVlDoJys/P5/vvv6dnT3MFYhcXF8aOHevwwKQMErbD0fXg4mYukFhOyRm59lagkderFUhERC4tpR4T5ObmxiOPPGJvCZIqpGBafNObwK/8rTaf/LaPzFwrrSP9ub6FWoFEROTSUqaB0V26dGHjxo0ODkXKJT8XNs8ynztgbaDkjFw+++MAAE9e31StQCIicskp05igRx99lNGjR3P48GE6duyIr69voffbtm3rkOCkFOIWQeZJ8AuHxj3KXZ1agURE5FJXpiRo4EBzvMkTTzxhP2axWDAMA4vFgtVqdUx0UnIFA6Lb3w2u5dvOQq1AIiJSE5Tp13L//v2OjkPKI/UI7FlqPndAV5hagUREpCYo05igBg0aXPBRWh988AHR0dF4eXkRGxvLmjVrzlv2mmuuwWKxFHkUrGANYBgGEyZMICIiAm9vb3r06MHu3bvLcqvVw8aZgAENukFwo3JVpVYgERGpKcrUEvT5559f8P3Bg0u+UvHs2bMZPXo0U6ZMITY2lsmTJ9OzZ0/i4uIIDS3aCjFv3rxCu9afPHmSdu3a0b9/f/uxN954g3fffZfPPvuMmJgYxo8fT8+ePdm+fTteXl4ljq1asNkKrw1UTmoFEhGRmsJiGIZR2pNq165d6HVeXh6ZmZl4eHjg4+NDcnJyieuKjY2lc+fOvP/++wDYbDaioqJ4/PHHS7T+0OTJk5kwYQLHjx/H19cXwzCoW7cu//jHP3jqqacASE1NJSwsjOnTp9vHM11IWloaAQEBpKam4u/vX+J7cYp9K+Dz28CjFjy1Czx8ylxVckYu3V9fRmaulU8Gd+KGlmEODFRERKRilfb3u0zdYadOnSr0SE9PJy4uju7duzNz5swS15Obm8v69evp0ePsbCYXFxd69OjBqlWrSlTH1KlTGThwoH2G2v79+4mPjy9UZ0BAALGxsSWus1opWBuozR3lSoAA/numFahVXX96qBVIREQucWVKgorTpEkTXnvtNUaOHFnic5KSkrBarYSFFW5xCAsLIz4+/qLnr1mzhq1bt/Lggw/ajxWcV5o6c3JySEtLK/SoFrJSYMcC83k5N0stNBaoh8YCiYjIpc9hSRCYq0kfO3bMkVVe0NSpU2nTpg1dupRvo9BJkyYREBBgf0RFRTkowgq2ZQ7kZ0NoS4jsUK6q/vvbPjLUCiQiIjVImQZGL1iwoNBrwzA4fvw477//Pt26dStxPSEhIbi6upKQkFDoeEJCAuHh4Rc8NyMjg1mzZvHSSy8VOl5wXkJCAhEREYXqbN++fbF1jRs3jtGjR9tfp6WlVY9EyEGbpaoVSEREaqIyJUF9+/Yt9NpisVCnTh2uu+463nrrrRLX4+HhQceOHVm6dKm9TpvNxtKlS3nssccueO6cOXPIycnh3nvvLXQ8JiaG8PBwli5dak960tLSWL16NcOHDy+2Lk9PTzw9PUscd5VwfDMc3wQu7tB2QLmqUiuQiIjURGVKgmw2m8MCGD16NEOGDKFTp0506dKFyZMnk5GRwbBhwwBzun1kZCSTJk0qdN7UqVPp27cvwcHBhY5bLBaefPJJXnnlFZo0aWKfIl+3bt0iyVu1VjAguvkt4Bt84bIXoFYgERGpqcq3v4IDDBgwgMTERCZMmEB8fDzt27dn8eLF9oHNhw4dwsWl8NCluLg4fv/9d3766adi6/znP/9JRkYGDz/8MCkpKXTv3p3FixdfOmsE5WXD5tnm83IOiFYrkIiI1FRlWifojjvuoEuXLowZM6bQ8TfeeIO1a9cyZ84chwXoDFV+naAtc+HrB8C/Hjy5GVxcy1RNckYuV76+jIxcKx/f15EbW114HJaIiEhVVinrBP3666/ccsstRY7ffPPN/Prrr2WpUkrDvlnqPWVOgOBsK1DLCH8tjCgiIjVOmZKg9PR0PDw8ihx3d3evPmvsVFenDsK+5ebz9veUvZpCY4GaaCyQiIjUOGVKgtq0acPs2bOLHJ81axYtW7Ysd1ByARu/NP/GXAVBMWWu5r+/qxVIRERqtjINjB4/fjy33347e/fu5brrrgNg6dKlzJw5s9qPB6rSbFbYOMN8Xo4B0acycpm+8gCgViAREam5ypQE9e7dm2+++YaJEycyd+5cvL29adu2LT///DNXX321o2OUAvuWQ+ph8AqAFreWuRq1AomIiJRjinyvXr3o1auXI2ORiyloBWrTH9y9y1SFWoFERERMZRoTtHbtWlavXl3k+OrVq1m3bl25g5LzOPC7+bf1HWWuQq1AIiIipjIlQSNGjODw4cNFjh89epQRI0aUOygpxul4SE8ALBDRrkxVnNsKNFKtQCIiUsOVKQnavn07HToU3bX8sssuY/v27eUOSopxfLP5N6QpePiWqYpzW4FuVCuQiIjUcGVKgjw9PYvs/A5w/Phx3NycvhPHpSl+k/k3om2ZTk/JVCuQiIjIucqUBN14442MGzeO1NRU+7GUlBSeeeYZbrjhBocFJ+c4fiYJCi9bEjRzzWEycq00D6+lViARERHKODvszTff5KqrrqJBgwZcdtllAGzcuJGwsDC++OILhwYoZxR0h5VhPFC+1cYXqw4A8ED3GLUCiYiIUMYkKDIyks2bNzNjxgw2bdqEt7c3w4YN4+6778bd3d3RMUrWKUg5aD4Pb1Pq05dsT+BYajZBvh70blfXwcGJiIhUT2UewOPr60v37t2pX78+ubm5APzwww8A3HbbbY6JTkzxW8y/gfXBJ6jUp396Zo+we7rUx8u97BuuioiIXErKlATt27ePfv36sWXLFiwWC4ZhFOpisVqtDgtQONsVVobxQNuPpbFmfzKuLhbuvbyBgwMTERGpvso0MHrkyJHExMRw4sQJfHx82Lp1KytWrKBTp04sX77cwSGKfVB0GcYDFewUf3PrcMIDvBwYlIiISPVWppagVatWsWzZMkJCQnBxccHV1ZXu3bszadIknnjiCf766y9Hx1mzxZdtUHRyRi7fbDwKwNAroh0clIiISPVWppYgq9VKrVq1AAgJCeHYsWMANGjQgLi4OMdFJ5CbCUm7zOel7A6btfYQOfk2Wkf607FB7QoITkREpPoqU0tQ69at2bRpEzExMcTGxvLGG2/g4eHBxx9/TMOGDR0dY82WsA0MG/jWgVrhJT7NnBZvzigbeoWmxYuIiPxdmZKg5557joyMDABeeuklbr31Vq688kqCg4OZPXu2QwOs8eLPGQ9UikTmp+0JHE/NJtjXg1vbRlRQcCIiItVXmZKgnj172p83btyYnTt3kpycTO3atdXi4GhlXCl6esG0+FhNixcRESmOwzb6Cgoq/fo1UgJlWCl627FU1uxPxs3FwqBYTYsXEREpTpkGRkslsebBie3m81JsnFowLf4mTYsXERE5LyVBVVniTrDmgqc/BEaX6BRzWrw5W29Yt5KdIyIiUhMpCarKzl0p2qVk/1PNXHOI3HwbbSID6FBf0+JFRETOR0lQVWZfKbpkXWH5Vhv/+7NgWny0BqmLiIhcgJKgqqyUK0UXTIsP8fPg1naaFi8iInIhSoKqKpvt7O7xJZweP33lAQDu7lIfTzdNixcREbkQJUFVVfI+yE0HNy8IaXrR4luPprLmgKbFi4iIlJSSoKqqYKXosFbgevHlnOy7xbeJ0LR4ERGRElASVFWVYqXo5Ixcvt1kTovXbvEiIiIloySoqirFStEF0+Lb1gugQ/3Aio1LRETkEqEkqCoyjHNmhl24JSjvnGnxQ7pqWryIiEhJKQmqitKOQuZJsLhCaKsLFv1pm6bFi4iIlIWSoKqooCusTnNwv/Ag5+l/7AfgHk2LFxERKRUlQVVRCVeK3no0lbUHTpnT4i/XtHgREZHSUBJUFZVwpeiCafG3tIkgzF/T4kVEREpDSVBVdO7GqedxMj3HPi1+iKbFi4iIlJrTk6APPviA6OhovLy8iI2NZc2aNRcsn5KSwogRI4iIiMDT05OmTZuyaNEi+/tWq5Xx48cTExODt7c3jRo14uWXX8YwjIq+FcfIOAlpR8zn4W3OW2zW2sOaFi8iIlIOF1+KuALNnj2b0aNHM2XKFGJjY5k8eTI9e/YkLi6O0NDQIuVzc3O54YYbCA0NZe7cuURGRnLw4EECAwPtZV5//XU+/PBDPvvsM1q1asW6desYNmwYAQEBPPHEE5V4d2VUsFJ0UEPw8i+2SJ7VxhertFu8iIhIeTg1CXr77bd56KGHGDZsGABTpkxh4cKFTJs2jbFjxxYpP23aNJKTk/njjz9wd3cHIDo6ulCZP/74gz59+tCrVy/7+zNnzrxoC1OVUYKVon/alkB8mjktvldbTYsXEREpC6d1h+Xm5rJ+/Xp69OhxNhgXF3r06MGqVauKPWfBggV07dqVESNGEBYWRuvWrZk4cSJWq9Ve5oorrmDp0qXs2rULgE2bNvH7779z8803nzeWnJwc0tLSCj2cpgQrRdunxcc20LR4ERGRMnJaS1BSUhJWq5WwsLBCx8PCwti5c2ex5+zbt49ly5YxaNAgFi1axJ49e3j00UfJy8vj+eefB2Ds2LGkpaXRvHlzXF1dsVqtvPrqqwwaNOi8sUyaNIkXX3zRcTdXHhdZKfrcafH3xtavxMBEREQuLU4fGF0aNpuN0NBQPv74Yzp27MiAAQN49tlnmTJlir3MV199xYwZM/jyyy/ZsGEDn332GW+++SafffbZeesdN24cqamp9sfhw4cr43aKyjkNJ/eYz8OLbwmafs60+FBNixcRESkzp7UEhYSE4OrqSkJCQqHjCQkJhIeHF3tOREQE7u7uuLqe7QJq0aIF8fHx5Obm4uHhwdNPP83YsWMZOHAgAG3atOHgwYNMmjSJIUOGFFuvp6cnnp6eDrqzcojfav6tVRf86hR5Oyk9hwUbz+wW3y26EgMTERG59DitJcjDw4OOHTuydOlS+zGbzcbSpUvp2rVrsed069aNPXv2YLPZ7Md27dpFREQEHh4eAGRmZuLiUvi2XF1dC51TZV1kpehZaw6Ra7XRrl4Al0UFVl5cIiIilyCndoeNHj2aTz75hM8++4wdO3YwfPhwMjIy7LPFBg8ezLhx4+zlhw8fTnJyMiNHjmTXrl0sXLiQiRMnMmLECHuZ3r178+qrr7Jw4UIOHDjA/Pnzefvtt+nXr1+l31+pXWSl6EVb4gG4T7vFi4iIlJtTp8gPGDCAxMREJkyYQHx8PO3bt2fx4sX2wdKHDh0q1KoTFRXFjz/+yKhRo2jbti2RkZGMHDmSMWPG2Mu89957jB8/nkcffZQTJ05Qt25d/u///o8JEyZU+v2V2gVWijYMgwMnMwC0OKKIiIgDWIxqs5Ry5UlLSyMgIIDU1FT8/YtfsNDh8nNgYl2w5cOTWyCw8MyvE2nZdJm4FBcL7Hz5ZjzcqtWYdhERkQpX2t9v/ZJWFSe2mwmQd20IiCry9v4ksxWoXm0fJUAiIiIOoF/TquLcrrBixvscPJkJQINgn8qMSkRE5JKlJKiqsM8MK35QdMF4oOhg38qKSERE5JKmJKiquMjMMHsSFKIkSERExBGUBFUFNuvZhRLPs3HqgSSzOyxa3WEiIiIOoSSoKkjaDflZ4O4LwY2KvG0YBgfPtAQ1UHeYiIiIQygJqgoKusLCW4NL0V3hE9NzyMi14mKBqCDvSg5ORETk0qQkqCq4yKDogplhdQO98XQrmiSJiIhI6SkJqgoKkqDzjgcyu8JiNChaRETEYZQEOZthnDMz7DxJkH08kAZFi4iIOIqSIGdLOQjZqeDiDnVaFFvkwMmCmWFqCRIREXEUJUHOVrBSdGgLcPMotkhBd5iSIBEREcdREuRsFxkUbU6PP9MSFKLuMBEREUdREuRsF1kp+mRGLuk5+Vgs5uapIiIi4hhKgpythDPD6gZ44+Wu6fEiIiKOoiTImU4nQHoCYDEXSizGAXWFiYiIVAglQc5U0BUW0gQ8ih/0rO0yREREKoaSIGc6vtH8e57xQAD7CxZKVBIkIiLiUEqCnKlgevx5xgPB2S0ztFCiiIiIYykJcib79PjikyDDMOyrRUdrywwRERGHUhLkLFkp5mrRcN6WoOSMXE5nm9Pj6wepJUhERMSRlAQ5S/wW829AffAJKrZIwcywCH8vTY8XERFxMCVBznKRrjA4Z7sMdYWJiIg4nJIgZ7nIStGg6fEiIiIVSUmQs5RgZtjZ3eM1HkhERMTRlAQ5Q24mJMWZzy/QEqSZYSIiIhVHSZAznNgOhg1860Ct8GKLGIZhXygxWt1hIiIiDqckyBnOXSnaYim2SEpmHqez8wFNjxcREakISoKcoQTjgfaf6QqLCPDC20PT40VERBxNSZAz2GeGXWi7jIKZYWoFEhERqQhKgiqbNQ8StpnPLzQoOqlgZpjGA4mIiFQEJUGVLTEOrLng6Q+B0ectpplhIiIiFUtJUGUrWCk6vA24nP/j1xpBIiIiFUtJUGUrwUrRoC0zREREKpqSoMpWgplhKZm5pGblAZoeLyIiUlGUBFUmm61ELUEFXWFh/p74eLhVRmQiIiI1jpKgynRqP+Smg5sXhDQ9b7EDWilaRESkwjk9Cfrggw+Ijo7Gy8uL2NhY1qxZc8HyKSkpjBgxgoiICDw9PWnatCmLFi0qVObo0aPce++9BAcH4+3tTZs2bVi3bl1F3kbJFKwUHdoSXM/fwmOfGaYkSEREpMI4ta9l9uzZjB49milTphAbG8vkyZPp2bMncXFxhIaGFimfm5vLDTfcQGhoKHPnziUyMpKDBw8SGBhoL3Pq1Cm6devGtddeyw8//ECdOnXYvXs3tWvXrsQ7Ow/fOtDiNghtccFiB890hzUI0XggERGRiuLUJOjtt9/moYceYtiwYQBMmTKFhQsXMm3aNMaOHVuk/LRp00hOTuaPP/7A3d0dgOjo6EJlXn/9daKiovj000/tx2JiYiruJkoj5irzcREFG6fGqCVIRESkwjitOyw3N5f169fTo0ePs8G4uNCjRw9WrVpV7DkLFiyga9eujBgxgrCwMFq3bs3EiROxWq2FynTq1In+/fsTGhrKZZddxieffHLBWHJyckhLSyv0cKazW2YoCRIREakoTkuCkpKSsFqthIWFFToeFhZGfHx8sefs27ePuXPnYrVaWbRoEePHj+ett97ilVdeKVTmww8/pEmTJvz4448MHz6cJ554gs8+++y8sUyaNImAgAD7IyoqyjE3WQapmXmcyjSnx2vfMBERkYpTreZf22w2QkND+fjjj3F1daVjx44cPXqUf/3rXzz//PP2Mp06dWLixIkAXHbZZWzdupUpU6YwZMiQYusdN24co0ePtr9OS0tzWiJUMCg6tJYnvp7V6n8eERGRasVpv7IhISG4urqSkJBQ6HhCQgLh4eHFnhMREYG7uzuurq72Yy1atCA+Pp7c3Fw8PDyIiIigZcuWhc5r0aIFX3/99Xlj8fT0xNPTsxx34ziaGSYiIlI5nNYd5uHhQceOHVm6dKn9mM1mY+nSpXTt2rXYc7p168aePXuw2Wz2Y7t27SIiIgIPDw97mbi4uELn7dq1iwYNGlTAXTieffd4zQwTERGpUE5dJ2j06NF88sknfPbZZ+zYsYPhw4eTkZFhny02ePBgxo0bZy8/fPhwkpOTGTlyJLt27WLhwoVMnDiRESNG2MuMGjWKP//8k4kTJ7Jnzx6+/PJLPv7440JlqjINihYREakcTh10MmDAABITE5kwYQLx8fG0b9+exYsX2wdLHzp0CJdzdlqPiorixx9/ZNSoUbRt25bIyEhGjhzJmDFj7GU6d+7M/PnzGTduHC+99BIxMTFMnjyZQYMGVfr9lYW6w0RERCqHxTAMw9lBVDVpaWkEBASQmpqKv79/pV67w8tLSM7IZeET3WlVN6BSry0iIlKdlfb32+nbZshZqVl5JGfkAuoOExERqWhKgqqQQ2e2ywjx88RP0+NFREQqlJKgKmT/mfFAMZoZJiIiUuGUBFUhB5M0M0xERKSyKAmqQg6c6Q6L1nYZIiIiFU5JUBVinx4fopYgERGRiqYkqAo5qDWCREREKo2SoCridHYeSekF0+PVHSYiIlLRlARVEQft0+M9qOXl7uRoRERELn1KgqqIA9ozTEREpFIpCaoiDiRpPJCIiEhlUhJURWh6vIiISOVSElRFFMwMa6Dp8SIiIpVCSVAVsT/JbAmKUXeYiIhIpVASVAWk5+STlJ4DQH11h4mIiFQKJUFVQEFXWJCvBwHemh4vIiJSGZQEVQEHkjQoWkREpLIpCaoCDmi7DBERkUqnJKgKsK8RpJlhIiIilUZJUBVQsGWG9gwTERGpPEqCqgB1h4mIiFQ+JUFOlpGTz4nT5vR4JUEiIiKVR0mQkxV0hdX2cSfAR9PjRUREKouSICc7qN3jRUREnEJJkJPtP5MExWhmmIiISKVSEuRkB5M0M0xERMQZlAQ5mWaGiYiIOIeSICezJ0HqDhMREalUSoKcKDM3n4S0gunx6g4TERGpTEqCnKhgenygjzuBPh5OjkZERKRmURLkRJoeLyIi4jxKgpzowJmWIHWFiYiIVD4lQU5k3z1eLUEiIiKVTkmQE52dGaaWIBERkcqmJMiJCgZGa0yQiIhI5VMS5CRZuVaOp2YDEKMkSEREpNIpCXKSQ8lmK5C/lxuB2j1eRESk0ikJcpJzV4q2WCxOjkZERKTmqRJJ0AcffEB0dDReXl7ExsayZs2aC5ZPSUlhxIgRRERE4OnpSdOmTVm0aFGxZV977TUsFgtPPvlkBURedpoZJiIi4lxuzg5g9uzZjB49milTphAbG8vkyZPp2bMncXFxhIaGFimfm5vLDTfcQGhoKHPnziUyMpKDBw8SGBhYpOzatWv56KOPaNu2bSXcSelojSARERHncnpL0Ntvv81DDz3EsGHDaNmyJVOmTMHHx4dp06YVW37atGkkJyfzzTff0K1bN6Kjo7n66qtp165doXLp6ekMGjSITz75hNq1a1fGrZSKvSVIG6eKiIg4hVOToNzcXNavX0+PHj3sx1xcXOjRowerVq0q9pwFCxbQtWtXRowYQVhYGK1bt2bixIlYrdZC5UaMGEGvXr0K1X0+OTk5pKWlFXpUNG2ZISIi4lxO7Q5LSkrCarUSFhZW6HhYWBg7d+4s9px9+/axbNkyBg0axKJFi9izZw+PPvooeXl5PP/88wDMmjWLDRs2sHbt2hLFMWnSJF588cXy3UwpZOdZOXZmery6w0RERJzD6d1hpWWz2QgNDeXjjz+mY8eODBgwgGeffZYpU6YAcPjwYUaOHMmMGTPw8vIqUZ3jxo0jNTXV/jh8+HBF3oJ9enwtLzeCfLV7vIiIiDM4tSUoJCQEV1dXEhISCh1PSEggPDy82HMiIiJwd3fH1dXVfqxFixbEx8fbu9dOnDhBhw4d7O9brVZ+/fVX3n//fXJycgqdC+Dp6Ymnp6cD7+zCzp0ZpunxIiIizuHUliAPDw86duzI0qVL7cdsNhtLly6la9euxZ7TrVs39uzZg81msx/btWsXEREReHh4cP3117NlyxY2btxof3Tq1IlBgwaxcePGIgmQM5zdLkNdYSIiIs7i9Cnyo0ePZsiQIXTq1IkuXbowefJkMjIyGDZsGACDBw8mMjKSSZMmATB8+HDef/99Ro4cyeOPP87u3buZOHEiTzzxBAC1atWidevWha7h6+tLcHBwkePOsv/MoOgYzQwTERFxGqcnQQMGDCAxMZEJEyYQHx9P+/btWbx4sX2w9KFDh3BxOdtgFRUVxY8//sioUaNo27YtkZGRjBw5kjFjxjjrFkpNM8NEREScz2IYhuHsIKqatLQ0AgICSE1Nxd/f3+H1d3ttGUdTspj7SFc6RQc5vH4REZGaqLS/39Vudlh1Z06PzwK0UKKIiIgzKQmqZEdOZWIY4OfpRrCmx4uIiDiNkqBKtj/pzJ5hIT6aHi8iIuJESoIqmQZFi4iIVA1KgirZgZMFCyVqjSARERFnUhJUyQ4UdIepJUhERMSplARVMntLkGaGiYiIOJWSoEqUk2/lWIo5PV5bZoiIiDiXkqBKdDg5C5sBvh6u1PGrvA1bRUREpCglQZXo3Jlhmh4vIiLiXEqCKlFadh6+Hq5Eh6grTERExNmcvoFqTdLvsnr0bR9JTr7N2aGIiIjUeGoJqmQWiwUvd1dnhyEiIlLjKQkSERGRGklJkIiIiNRISoJERESkRlISJCIiIjWSkiARERGpkZQEiYiISI2kJEhERERqJCVBIiIiUiMpCRIREZEaSUmQiIiI1EhKgkRERKRGUhIkIiIiNZKSIBEREamR3JwdQFVkGAYAaWlpTo5ERERESqrgd7vgd/xilAQV4/Tp0wBERUU5ORIREREprdOnTxMQEHDRchajpOlSDWKz2Th27Bi1atXCYrE4tO60tDSioqI4fPgw/v7+Dq37UqXPrGz0uZWNPrey0edWevrMyuZCn5thGJw+fZq6devi4nLxET9qCSqGi4sL9erVq9Br+Pv760tfSvrMykafW9nocysbfW6lp8+sbM73uZWkBaiABkaLiIhIjaQkSERERGokJUGVzNPTk+effx5PT09nh1Jt6DMrG31uZaPPrWz0uZWePrOyceTnpoHRIiIiUiOpJUhERERqJCVBIiIiUiMpCRIREZEaSUmQiIiI1EhKgirRBx98QHR0NF5eXsTGxrJmzRpnh1SlvfDCC1gslkKP5s2bOzusKufXX3+ld+/e1K1bF4vFwjfffFPofcMwmDBhAhEREXh7e9OjRw92797tnGCrkIt9bkOHDi3y/bvpppucE2wVMWnSJDp37kytWrUIDQ2lb9++xMXFFSqTnZ3NiBEjCA4Oxs/PjzvuuIOEhAQnRVw1lORzu+aaa4p83x555BEnRex8H374IW3btrUviNi1a1d++OEH+/uO+p4pCaoks2fPZvTo0Tz//PNs2LCBdu3a0bNnT06cOOHs0Kq0Vq1acfz4cfvj999/d3ZIVU5GRgbt2rXjgw8+KPb9N954g3fffZcpU6awevVqfH196dmzJ9nZ2ZUcadVysc8N4Kabbir0/Zs5c2YlRlj1rFixghEjRvDnn3+yZMkS8vLyuPHGG8nIyLCXGTVqFN999x1z5sxhxYoVHDt2jNtvv92JUTtfST43gIceeqjQ9+2NN95wUsTOV69ePV577TXWr1/PunXruO666+jTpw/btm0DHPg9M6RSdOnSxRgxYoT9tdVqNerWrWtMmjTJiVFVbc8//7zRrl07Z4dRrQDG/Pnz7a9tNpsRHh5u/Otf/7IfS0lJMTw9PY2ZM2c6IcKq6e+fm2EYxpAhQ4w+ffo4JZ7q4sSJEwZgrFixwjAM87vl7u5uzJkzx15mx44dBmCsWrXKWWFWOX//3AzDMK6++mpj5MiRzguqGqhdu7bx3//+16HfM7UEVYLc3FzWr19Pjx497MdcXFzo0aMHq1atcmJkVd/u3bupW7cuDRs2ZNCgQRw6dMjZIVUr+/fvJz4+vtB3LyAggNjYWH33SmD58uWEhobSrFkzhg8fzsmTJ50dUpWSmpoKQFBQEADr168nLy+v0PetefPm1K9fX9+3c/z9cyswY8YMQkJCaN26NePGjSMzM9MZ4VU5VquVWbNmkZGRQdeuXR36PdMGqpUgKSkJq9VKWFhYoeNhYWHs3LnTSVFVfbGxsUyfPp1mzZpx/PhxXnzxRa688kq2bt1KrVq1nB1etRAfHw9Q7Hev4D0p3k033cTtt99OTEwMe/fu5ZlnnuHmm29m1apVuLq6Ojs8p7PZbDz55JN069aN1q1bA+b3zcPDg8DAwEJl9X07q7jPDeCee+6hQYMG1K1bl82bNzNmzBji4uKYN2+eE6N1ri1bttC1a1eys7Px8/Nj/vz5tGzZko0bNzrse6YkSKqsm2++2f68bdu2xMbG0qBBA7766iseeOABJ0YmNcHAgQPtz9u0aUPbtm1p1KgRy5cv5/rrr3diZFXDiBEj2Lp1q8bpldL5PreHH37Y/rxNmzZERERw/fXXs3fvXho1alTZYVYJzZo1Y+PGjaSmpjJ37lyGDBnCihUrHHoNdYdVgpCQEFxdXYuMXE9ISCA8PNxJUVU/gYGBNG3alD179jg7lGqj4Pul7175NWzYkJCQEH3/gMcee4zvv/+eX375hXr16tmPh4eHk5ubS0pKSqHy+r6Zzve5FSc2NhagRn/fPDw8aNy4MR07dmTSpEm0a9eOd955x6HfMyVBlcDDw4OOHTuydOlS+zGbzcbSpUvp2rWrEyOrXtLT09m7dy8RERHODqXaiImJITw8vNB3Ly0tjdWrV+u7V0pHjhzh5MmTNfr7ZxgGjz32GPPnz2fZsmXExMQUer9jx464u7sX+r7FxcVx6NChGv19u9jnVpyNGzcC1Ojv29/ZbDZycnIc+z1z7NhtOZ9Zs2YZnp6exvTp043t27cbDz/8sBEYGGjEx8c7O7Qq6x//+IexfPlyY//+/cbKlSuNHj16GCEhIcaJEyecHVqVcvr0aeOvv/4y/vrrLwMw3n77beOvv/4yDh48aBiGYbz22mtGYGCg8e233xqbN282+vTpY8TExBhZWVlOjty5LvS5nT592njqqaeMVatWGfv37zd+/vlno0OHDkaTJk2M7OxsZ4fuNMOHDzcCAgKM5cuXG8ePH7c/MjMz7WUeeeQRo379+sayZcuMdevWGV27djW6du3qxKid72Kf2549e4yXXnrJWLdunbF//37j22+/NRo2bGhcddVVTo7cecaOHWusWLHC2L9/v7F582Zj7NixhsViMX766SfDMBz3PVMSVInee+89o379+oaHh4fRpUsX488//3R2SFXagAEDjIiICMPDw8OIjIw0BgwYYOzZs8fZYVU5v/zyiwEUeQwZMsQwDHOa/Pjx442wsDDD09PTuP766424uDjnBl0FXOhzy8zMNG688UajTp06hru7u9GgQQPjoYceqvH/0VLc5wUYn376qb1MVlaW8eijjxq1a9c2fHx8jH79+hnHjx93XtBVwMU+t0OHDhlXXXWVERQUZHh6ehqNGzc2nn76aSM1NdW5gTvR/fffbzRo0MDw8PAw6tSpY1x//fX2BMgwHPc9sxiGYZSxZUpERESk2tKYIBEREamRlASJiIhIjaQkSERERGokJUEiIiJSIykJEhERkRpJSZCIiIjUSEqCREREpEZSEiQiUgLLly/HYrEU2a9IRKovJUEiIiJSIykJEhERkRpJSZCIVAs2m41JkyYRExODt7c37dq1Y+7cucDZrqqFCxfStm1bvLy8uPzyy9m6dWuhOr7++mtatWqFp6cn0dHRvPXWW4Xez8nJYcyYMURFReHp6Unjxo2ZOnVqoTLr16+nU6dO+Pj4cMUVVxAXF1exNy4iFUZJkIhUC5MmTeLzzz9nypQpbNu2jVGjRnHvvfeyYsUKe5mnn36at956i7Vr11KnTh169+5NXl4eYCYvd911FwMHDmTLli288MILjB8/nunTp9vPHzx4MDNnzuTdd99lx44dfPTRR/j5+RWK49lnn+Wtt95i3bp1uLm5cf/991fK/YuI42kDVRGp8nJycggKCuLnn3+ma9eu9uMPPvggmZmZPPzww1x77bXMmjWLAQMGAJCcnEy9evWYPn06d911F4MGDSIxMZGffvrJfv4///lPFi5cyLZt29i1axfNmjVjyZIl9OjRo0gMy5cv59prr+Xnn3/m+uuvB2DRokX06tWLrKwsvLy8KvhTEBFHU0uQiFR5e/bsITMzkxtuuAE/Pz/74/PPP2fv3r32cucmSEFBQTRr1owdO3YAsGPHDrp161ao3m7durF7926sVisbN27E1dWVq6+++oKxtG3b1v48IiICgBMnTpT7HkWk8rk5OwARkYtJT08HYOHChURGRhZ6z9PTs1AiVFbe3t4lKufu7m5/brFYAHO8kohUP2oJEpEqr2XLlnh6enLo0CEaN25c6BEVFWUv9+eff9qfnzp1il27dtGiRQsAWrRowcqVKwvVu3LlSpo2bYqrqytt2rTBZrMVGmMkIpc2tQSJSJVXq1YtnnrqKUaNGoXNZqN79+6kpqaycuVK/P39adCgAQAvvfQSwcHBhIWF8eyzzxISEkLfvn0B+Mc//kHnzp15+eWXGTBgAKtWreL999/nP//5DwDR0dEMGTKE+++/n3fffZd27dpx8OBBTpw4wV133eWsWxeRCqQkSESqhZdffpk6deowadIk9u3bR2BgIB06dOCZZ56xd0e99tprjBw5kt27d9O+fXu+++47PDw8AOjQoQNfffUVEyZM4OWXXyYiIoKXXnqJoUOH2q/x4Ycf8swzz/Doo49y8uRJ6tevzzPPPOOM2xWRSqDZYSJS7RXM3Dp16hSBgYHODkdEqgmNCRIREZEaSUmQiIiI1EjqDhMREZEaSS1BIiIiUiMpCRIREZEaSUmQiIiI1EhKgkRERKRGUhIkIiIiNZKSIBEREamRlASJiIhIjaQkSERERGokJUEiIiJSI/0/6d92mx3UuvkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d437814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b5876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fbc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
