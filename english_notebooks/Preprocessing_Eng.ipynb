{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter what kind of NLP you want to do - classify a text, extract named entities, disambiguate a word sense - you most curtainly need to do some preprocessing first. \n",
    "\n",
    "In this notebook we will go through basic preprocessing steps such as sentence segmentation, tokenization, lemmatization and look at one of more advanced approaches (bpe). We will also discuss existing text preprocessing tools for russian and english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to install this libraries to work with russian\n",
    "# in Colab specifying pymystem3 version is important, you can drop it on your machine\n",
    "# if pymorphy2[fast] does not install (it won't on windows) drop the [fast] part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pymystem3==0.1.10\n",
    "!pip install pymorphy2[fast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you only want to work with english spacy is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you don't have nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "import string\n",
    "from gensim.utils import tokenize\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re, os, json\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "mystem = Mystem()\n",
    "morph = MorphAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textual data is often not just text. There can be tags, links, timestamps and other garbage that you'll probably want to get rid off. Regular expression is the tool that can help you with that.\n",
    "\n",
    "**Re** is main python module for regular expressions. Look through the documentation if you never worked with it - https://docs.python.org/3/library/re.html\n",
    "But don't try to read it all of it. The best way to learn it is practice. Let's get to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some text. (It's in russian but for now it's ok that you don't understand it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — <a href=\"http://www.crazyegg.com\" title=\"Сумасшедшие яйца\">CrazyEgg</a>. Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично!<br><br><img src=\"http://img172.imageshack.us/img172/8434/18274658kc4.png\" alt=\"Сумасшедшее яйцо\"><br><br><blockquote><h3>Что это такое?</h3><br>\n",
    "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.<br>\n",
    "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/7c7/298/33c/7c729833cd942cc493e68833e3e0f12d.jpg\" alt=\"Тепловое отслеживание популярности\"><br></blockquote><br><br><a name=\"habracut\"></a><br><br><blockquote><h3>Для кого это?</h3><br>\n",
    "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/0b0/0a0/b16/0b00a0b16b1eda28e35f39487dcd2545.jpg\" alt=\"Отслеживание ссылок\"></blockquote><br><blockquote><img src=\"https://habrastorage.org/getpro/habr/post_images/0b5/433/892/0b54338921665ffb5a90930147296f5b.jpg\" alt=\"Список по популярности\"><br><br>\n",
    "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса).</blockquote><br><blockquote><h3>Зачем это?</h3><br>\n",
    "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет <a href=\"http://ttp://www.crazyegg.com\" title=\"Сумасшедшие яйца\">Сумасшедшее яйцо</a>.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/38c/af8/e75/38caf8e753782a01dc6419d3902edd57.jpg\" alt=\"Добавление проекта\"></blockquote><br><blockquote>Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/0dd/3fb/b34/0dd3fbb34709e77f3fbcd6523c7eac77.jpg\" alt=\"еще полезности\"></blockquote><br><blockquote><h3>Как это работает?</h3><br>\n",
    "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере <a href=\"http://www.crazyegg.com\" title=\"Сумасшедшие яйца\">CrazyEgg</a>, поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/a90/e4e/e67/a90e4ee6760978463e6306a2f5982e24.jpg\" alt=\"управление популярностью\"></blockquote><br><blockquote><h3>Сколько это стоит?</h3><br>\n",
    "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации.</blockquote><br><blockquote>1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте.<br><br>\n",
    "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции.<br><br>\n",
    "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора.<br><br>\n",
    "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются.<br><br>\n",
    "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/f73/fb2/62d/f73fb262da4618a8dde67690cfd191ea.jpg\" alt=\"Отслеживание статистики\"></blockquote><br><blockquote><h3>Есть и аналоги</h3><br>\n",
    "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле.</blockquote><br><blockquote> 1. <a href=\"https://www.google.com/analytics/home/?hl=en\" title=\"Шикарный сбор и анализ статистики\">Google Analytics</a> — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога.<br><br>\n",
    "2. <a href=\"http://www.mapsurface.com/\" title=\"Сервис для отслеживания популярности блоков на сайте\">MapSurface</a> — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты.</blockquote><br><blockquote><h3>Вывод</h3><br>\n",
    "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом — <a href=\"http://ttp://www.crazyegg.com\">полезная вещь</a> для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги.<br><br><img src=\"http://img241.imageshack.us/img241/2346/confettitnml5.jpg\" alt=\"Интересная идея визуализации популярности - конфети\"></blockquote><br><br>\n",
    "Автор: <a href=\"http://www.birzool.com/\" title=\"Я пишу о юзабилити веб интерфейсов\">Ярослав Бирзул</a> (DezmASter).<br>\n",
    "Источник: <a href=\"http://www.birzool.com/crazyegg/\" title=\"Сумасшедшие яйца, первоисточник\">Блог о юзабилити веб интерфейсов</a>.<br><br>\n",
    "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are html tags in this text. Let's try to remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Html tags are simple - they start with < and end with >.  We can write a simple regexp to match everything that is inside the tag.  \n",
    "**re.sub** - is a function to replace what we match with something (or, in this case, nothing)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags_1(text):\n",
    "    return re.sub(r'<[^>]+>', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg. Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично!Что это такое?\n",
      "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.\n",
      "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).Для кого это?\n",
      "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями.\n",
      "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса).Зачем это?\n",
      "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет Сумасшедшее яйцо.Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей.Как это работает?\n",
      "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере CrazyEgg, поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая.Сколько это стоит?\n",
      "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации.1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте.\n",
      "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции.\n",
      "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора.\n",
      "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются.\n",
      "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц.Есть и аналоги\n",
      "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле. 1. Google Analytics — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога.\n",
      "2. MapSurface — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты.Вывод\n",
      "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом — полезная вещь для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги.\n",
      "Автор: Ярослав Бирзул (DezmASter).\n",
      "Источник: Блог о юзабилити веб интерфейсов.\n",
      "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_tags_1(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems fine, but if we look closer we'll notice that there's no space between some sentences. Let's try to replace tags with space then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags_2(text):\n",
    "    return re.sub(r'<[^>]+>', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя —  CrazyEgg . Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично!       Что это такое?  \n",
      "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов. \n",
      "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).             Для кого это?  \n",
      "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями.         \n",
      "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса).    Зачем это?  \n",
      "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет  Сумасшедшее яйцо .      Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей.       Как это работает?  \n",
      "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере  CrazyEgg , поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая.       Сколько это стоит?  \n",
      "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации.   1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте.  \n",
      "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции.  \n",
      "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора.  \n",
      "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются.  \n",
      "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц.       Есть и аналоги  \n",
      "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле.    1.  Google Analytics  — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога.  \n",
      "2.  MapSurface  — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты.    Вывод  \n",
      "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом —  полезная вещь  для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги.      \n",
      "Автор:  Ярослав Бирзул  (DezmASter). \n",
      "Источник:  Блог о юзабилити веб интерфейсов .  \n",
      "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_tags_2(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there's too much spaces between sentences. But we can easily fix that with another regexp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags_3(text):\n",
    "    no_tags_text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    no_space_sequences_text = re.sub('  +', ' ', no_tags_text) # replace all space sequences with only 1 space\n",
    "    return no_space_sequences_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg . Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично! Что это такое? \n",
      "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов. \n",
      "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые). Для кого это? \n",
      "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями. \n",
      "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса). Зачем это? \n",
      "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет Сумасшедшее яйцо . Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей. Как это работает? \n",
      "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере CrazyEgg , поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая. Сколько это стоит? \n",
      "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации. 1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте. \n",
      "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции. \n",
      "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора. \n",
      "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются. \n",
      "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц. Есть и аналоги \n",
      "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле. 1. Google Analytics — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога. \n",
      "2. MapSurface — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты. Вывод \n",
      "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом — полезная вещь для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги. \n",
      "Автор: Ярослав Бирзул (DezmASter). \n",
      "Источник: Блог о юзабилити веб интерфейсов . \n",
      "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_tags_3(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = remove_tags_3(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regular expressions we can also split the text into sentences. However, the regular expression is a bit more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**re.split** - is a function to split text using a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences usually end with .!? and there's space and uppercase letter after. So we can try something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nСегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg ',\n",
       " ' не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо',\n",
       " 'апоминается',\n",
       " 'тлично',\n",
       " 'то это такое? \\nКак уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов. \\nСервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые)',\n",
       " 'ля кого это? \\nРазумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад',\n",
       " 'тносительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную',\n",
       " 'абы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями. \\nДа-да, сервис не бесплатен',\n",
       " 'очнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса)',\n",
       " 'ачем это? \\nС помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('[!?\\.] [А-Я]', text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that this regexp also removes the .!? and first uppercase letters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve it using __look ahead__ и __look behind__ (regex features).  \n",
    "Here's the syntax:  \n",
    "**(?<=pattern)** positive look-behind  \n",
    "**(?<!pattern)** negative look-behind условие  \n",
    "**(?=pattern)** positive look-ahead условие  \n",
    "**(?!pattern)** negative look-ahead условие  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about it here: https://www.regular-expressions.info/lookaround.html  \n",
    "Or here (more general) - https://www.rexegg.com/regex-disambiguation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, Look behind and look ahead turn the pattern into a condition that should be met before of after. Everything that is inside the condition is not matched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's wrap the left and the right part of out regexp and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?',\n",
       " 'Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.',\n",
       " 'Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).',\n",
       " 'Для кого это?',\n",
       " 'Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад.',\n",
       " 'Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную.']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('(?<=[\\.?!]) +(?=[А-ЯЁ])', text.replace('\\n', ' '))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to write something yourself, you can use **sent_tokenize** from *nltk* or **split_sentences** from *gensim*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nСегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?',\n",
       " 'Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.',\n",
       " 'Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).',\n",
       " 'Для кого это?',\n",
       " 'Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад.',\n",
       " 'Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text, 'russian')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it return a generator so we wrap it in a list\n",
    "list(split_sentences(text))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may want to split our text into words. It sounds simple but in fact it's not. What we see in texts are not words, it's wordforms (for example, do, does, did are wordforms of one word). Besides, texts may contain other things (i.e. numbers, punctuation).  \n",
    "We call such separate meaningful units of a text that are not words, nor necessarily wordforms **tokens**. And the process of splitting the text into tokens is called tokenization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to tokenize a text is __str.split__ method. It tokenizes a text on space sequences (1 or more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '—',\n",
       " 'CrazyEgg',\n",
       " '.',\n",
       " 'Я',\n",
       " 'не',\n",
       " 'знаю',\n",
       " 'кому',\n",
       " 'обязан',\n",
       " 'сервис',\n",
       " 'таким',\n",
       " 'говорящим',\n",
       " 'именем,']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: str.split(' ') is not the same as str.split(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But str.split() does not separate punctuation. Most of time, punctuation is not needed at all so we can throw it away using str.strip() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#common punctuation signs can be found in string.punctuation\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to work with russian we may quotation marks and three dots\n",
    "string.punctuation += '«»—…“”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '',\n",
       " 'CrazyEgg']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word.strip(string.punctuation) for word in text.split()][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "str.strip does not remove punctuation inside tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'как-нибудь'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'как-нибудь'.strip(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"don't\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"don't\".strip(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions can also help us tokenize the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', 'Сегодняшняя', ' ', 'заметка', ' ', 'будет', ' ', 'о', ' ', 'сервисе']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we need punctuation\n",
    "re.findall('\\w+|\\W', text)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " 'CrazyEgg',\n",
       " 'Я']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we don't\n",
    "re.findall('\\w+', text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nltk has ready-to-use tokenizers.\n",
    "\n",
    "For example, **wordpunct_tokenizer** which uses this regexp - *'\\w+|[^\\w\\s]+'* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be used for russian and english because both languages use spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '—',\n",
       " 'CrazyEgg']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(text)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', \"'\", 's', 'an', 'example', '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(\"That's an example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another nltk tokenizer is **word_tokenize**. It also uses regular expressions but more sophisticated ones.\n",
    "And they are crafted for english specifically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', \"'s\", 'an', 'example', '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"That's an example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim also has tokenize function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', 's', 'an', 'example']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenize(\"That's an example.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing non-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only need wordforms, we can use built-in **.isalpha()** and **len()** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " 'CrazyEgg',\n",
       " 'Я',\n",
       " 'не',\n",
       " 'знаю',\n",
       " 'кому',\n",
       " 'обязан',\n",
       " 'сервис',\n",
       " 'таким',\n",
       " 'говорящим',\n",
       " 'именем',\n",
       " 'но',\n",
       " 'оно']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in word_tokenize(text) if word.isalpha() and len(word) < 30][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "str.isalpha() won't work on wordforms with - or ' inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"don't\".isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They can be splitted before filtering or you can use regular expression [a-z\\\\-'] instead if str.isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To group wordforms of one word together we need to do normalization. There are two ways of doing it: lemmatization or stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is basically removing common endings (-s, -ed etc.) It is based on the assumption that words have roots (=stems) that do not change between wordforms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most famous stemmer is Porter stemmer (or Snowball stemmer). \n",
    "You can read about it here - <https://medium.com/@eigenein/стеммер-портера-для-русского-языка-d41c38b2d340>  \n",
    "Or here - <http://snowball.tartarus.org/algorithms/russian/stemmer.html>  \n",
    "\n",
    "Here's a comment from Porter on why it is called Snoball:\n",
    "\n",
    "`Since it effectively provides a ‘suffix STRIPPER GRAMmar’, I had toyed with the idea of calling it ‘strippergram’, but good sense has prevailed, and so it is ‘Snowball’ named as a tribute to SNOBOL, the excellent string handling language of Messrs Farber, Griswold, Poage and Polonsky from the 1960s.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The setting was a symposium between Buddhist monk-scholars and Western scientists in a Tibetan monastery in Southern India, fostering a dialogue in physics, biology, and brain science.\n",
    "\n",
    "Buddhism has philosophical traditions reaching back to the fifth century B.C. It defines life as possessing heat (i.e., a metabolism) and sentience, that is, the ability to sense, to experience, and to act. According to its teachings, consciousness is accorded to all animals, large and small—human adults and fetuses, monkeys, dogs, fish, and even lowly cockroaches and mosquitoes. All of them can suffer; all their lives are precious.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowball stemmer is part of the nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'the'),\n",
       " ('setting', 'set'),\n",
       " ('was', 'was'),\n",
       " ('a', 'a'),\n",
       " ('symposium', 'symposium'),\n",
       " ('between', 'between'),\n",
       " ('Buddhist', 'buddhist'),\n",
       " ('monk-scholars', 'monk-scholar'),\n",
       " ('and', 'and'),\n",
       " ('Western', 'western'),\n",
       " ('scientists', 'scientist'),\n",
       " ('in', 'in'),\n",
       " ('a', 'a'),\n",
       " ('Tibetan', 'tibetan'),\n",
       " ('monastery', 'monasteri'),\n",
       " ('in', 'in'),\n",
       " ('Southern', 'southern'),\n",
       " ('India,', 'india'),\n",
       " ('fostering', 'foster'),\n",
       " ('a', 'a'),\n",
       " ('dialogue', 'dialogu'),\n",
       " ('in', 'in'),\n",
       " ('physics,', 'physic'),\n",
       " ('biology,', 'biolog'),\n",
       " ('and', 'and'),\n",
       " ('brain', 'brain'),\n",
       " ('science.', 'scienc'),\n",
       " ('Buddhism', 'buddhism'),\n",
       " ('has', 'has'),\n",
       " ('philosophical', 'philosoph'),\n",
       " ('traditions', 'tradit'),\n",
       " ('reaching', 'reach'),\n",
       " ('back', 'back'),\n",
       " ('to', 'to'),\n",
       " ('the', 'the'),\n",
       " ('fifth', 'fifth'),\n",
       " ('century', 'centuri'),\n",
       " ('B.C.', 'b.c'),\n",
       " ('It', 'it'),\n",
       " ('defines', 'defin'),\n",
       " ('life', 'life'),\n",
       " ('as', 'as'),\n",
       " ('possessing', 'possess'),\n",
       " ('heat', 'heat'),\n",
       " ('(i.e.,', 'i.e'),\n",
       " ('a', 'a'),\n",
       " ('metabolism)', 'metabol'),\n",
       " ('and', 'and'),\n",
       " ('sentience,', 'sentienc'),\n",
       " ('that', 'that'),\n",
       " ('is,', 'is'),\n",
       " ('the', 'the'),\n",
       " ('ability', 'abil'),\n",
       " ('to', 'to'),\n",
       " ('sense,', 'sens'),\n",
       " ('to', 'to'),\n",
       " ('experience,', 'experi'),\n",
       " ('and', 'and'),\n",
       " ('to', 'to'),\n",
       " ('act.', 'act'),\n",
       " ('According', 'accord'),\n",
       " ('to', 'to'),\n",
       " ('its', 'it'),\n",
       " ('teachings,', 'teach'),\n",
       " ('consciousness', 'conscious'),\n",
       " ('is', 'is'),\n",
       " ('accorded', 'accord'),\n",
       " ('to', 'to'),\n",
       " ('all', 'all'),\n",
       " ('animals,', 'anim'),\n",
       " ('large', 'larg'),\n",
       " ('and', 'and'),\n",
       " ('small—human', 'small—human'),\n",
       " ('adults', 'adult'),\n",
       " ('and', 'and'),\n",
       " ('fetuses,', 'fetus'),\n",
       " ('monkeys,', 'monkey'),\n",
       " ('dogs,', 'dog'),\n",
       " ('fish,', 'fish'),\n",
       " ('and', 'and'),\n",
       " ('even', 'even'),\n",
       " ('lowly', 'lowli'),\n",
       " ('cockroaches', 'cockroach'),\n",
       " ('and', 'and'),\n",
       " ('mosquitoes.', 'mosquito'),\n",
       " ('All', 'all'),\n",
       " ('of', 'of'),\n",
       " ('them', 'them'),\n",
       " ('can', 'can'),\n",
       " ('suffer;', 'suffer'),\n",
       " ('all', 'all'),\n",
       " ('their', 'their'),\n",
       " ('lives', 'live'),\n",
       " ('are', 'are'),\n",
       " ('precious.', 'precious')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word, stemmer.stem(word.strip(string.punctuation))) for word in text.split()][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"ending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'close'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the languages are more complex than just adding endings to stems. Suppletive forms are common both in english and russian. So lemmatization is preferred most of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is replacing wordforms of one word with a standard form (lemma). For example, for verbs a standard form is an infinitive (but the choice of lemma is arbitrary, so it doesn't have to be an infinitive).   \n",
    "\n",
    "Lemmatization requires a dictionary of all wordforms, for new words the lemma is inferred in a way similar to stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Russian Mystem and Pymorphy are best lemmatizers.\n",
    "\n",
    "\n",
    "### Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Mystem is a bit better and can tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg. Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сегодняшний', ' ', 'заметка', ' ', 'быть', ' ', 'о', ' ', 'сервис', ' ']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem.lemmatize(t)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целевом файле теперь лежит разобранный текст в jsonlines (json на каждой строчке)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pymorphy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pymorphy only works with tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сегодняшний',\n",
       " 'заметка',\n",
       " 'быть',\n",
       " 'о',\n",
       " 'сервис',\n",
       " 'отслеживание',\n",
       " 'активность',\n",
       " 'пользователь',\n",
       " '—',\n",
       " 'crazyegg',\n",
       " '.',\n",
       " 'я',\n",
       " 'не',\n",
       " 'знать',\n",
       " 'кома',\n",
       " 'обязать',\n",
       " 'сервис',\n",
       " 'такой',\n",
       " 'говорящий',\n",
       " 'имя',\n",
       " ',',\n",
       " 'но',\n",
       " 'оно',\n",
       " 'работать',\n",
       " ',',\n",
       " 'и',\n",
       " 'хорошо',\n",
       " '.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# основная функция - pymorphy.parse\n",
    "[morph.parse(token)[0].normal_form for token in word_tokenize(t)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For English the best option is spacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for sent in doc.sents:\n",
    "    for word in sent:\n",
    "        lemmas.append(word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'setting',\n",
       " 'be',\n",
       " 'a',\n",
       " 'symposium',\n",
       " 'between',\n",
       " 'Buddhist',\n",
       " 'monk',\n",
       " '-',\n",
       " 'scholar']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy does sentence segmentation, tokenization, lemmatization and many other usefult things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often common words are not useful or can even worsen the quality of a model. Such words are called stop-words. The term comes from information retrieval (first mentioned by [Peter Luhn](https://en.wikipedia.org/wiki/Hans_Peter_Luhn) in 1959). Back in the day, stopwords were removed from the indecies to reduce memory consumption and improve search quality. After memory became cheap and IDF was invented people stopped doing that. But stopwords can still be useful in nlp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# nltk has stopwords lists for different languages\n",
    "stops = stopwords.words('english')\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subword tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of state-of-the-art nlp models use different tokenization methods. One of the most common algorithm is byte-pair encoding. It was first developed as a compression algorithm, only in 2016 it was succesfully applied to machine translation - https://www.aclweb.org/anthology/P16-1162\n",
    "\n",
    "The main advantage of BPE is that it can be applied to any language. It doesn't assume that words are separated with spaces (or at all), it just learns tokenization rules directly from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also it is simple. Here's how it works:  \n",
    "***\n",
    "1) a given text is treated as a sequence of characters  \n",
    "2) coocurrence statistics is collected  \n",
    "3) most frequetly occuring characters are merged  \n",
    "4) 2 and 3 steps are repeated N times\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N is the only parameter of the algorith that has to be tuned. The mode N is, the longer character sequences will get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest implementation is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re, collections\n",
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3, 'st r an g e r </w>': 2, 'and</w>': 10, 'st and</w>': 7}\n"
     ]
    }
   ],
   "source": [
    "vocab = {'l o w </w>' : 5, 'l o w e r </w>' : 2,\n",
    "         'n e w e s t </w>':6, 'w i d e s t </w>':3, \n",
    "         's t r a n g e r </w>':2, 'a n d </w>':10,\n",
    "         's t a n d </w>':7\n",
    "        }\n",
    "num_merges = 5\n",
    "\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    if not pairs:\n",
    "        print(i)\n",
    "        break\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it is not very efficient. If you need to perform BPE on large text you can use existing libraries like YouTokenToMe or SentencePiece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a medium post about YouTokenToMe - https://medium.com/@vktech/youtokentome-a-tool-for-quick-text-tokenization-from-the-vk-team-aa6341215c5a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a github repo of SentencePiece - https://github.com/google/sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we get to neural networks, we'll try BPE on a real task and see how good it is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
